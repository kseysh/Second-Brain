10개의 학과만 선정하였음
## crawl_course_info
개선 전
58.24043 sec

## crawl_course_vacancy
개선 전
1240.11201 sec 
문제점 1, 4 해결 후
86.35317 sec

문제점 3 해결 후
71.14256 sec

문제점 2 해결 실패
비동기 프로그램을 짰지만, 여석 확인 페이지는 한 계정당 한 번만 들어갈 수 있도록 설계해두어서 비동기가 아닌 순차 프로그래밍을 할 수 밖에 없었다.
비동기를 지원하는 프로그램인 playwright를 활용하였고 await를 활용하여 비동기 IO를 진행하였다.

```python
from asgiref.sync import sync_to_async
from playwright.async_api import async_playwright
import time
import asyncio

async def crawl_course_vacancy(request):
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        page = await browser.new_page()

        start = time.time()

        try:
            target_url = 'https://sugang.inha.ac.kr/sugang/SU_51001/Lec_Time_Search.aspx?callPage=Sugang_SaveAB'
            await page.goto(target_url)
            cookies = [
                {
                    "name": "ITISSugang",
                    "value": "value",
                    "url": target_url 
                },
                {
                    "name": "ITISSugangHome",
                    "value": "value",
                    "url": target_url 
                }
            ]

            await page.context.add_cookies(cookies=cookies)

            code_prefixes = set()

            for major in test_majors:
                await page.select_option('#ddlDept', major["value"])
                await page.click("#ibtnSearch1")
                await page.wait_for_selector('#dgList > tbody > tr')

                rows = await page.query_selector_all("#dgList > tbody > tr")
                course_list = []
                new_courses = []

                for row in rows:
                    code_prefix_element = await row.query_selector("td:nth-child(1)")
                    code_prefix_text = (await code_prefix_element.text_content()).strip().split('-')[0]

                    if code_prefix_text in code_prefixes:
                        continue
                    code_prefixes.add(code_prefix_text)

                    # 세마포어를 사용하여 동시에 실행되는 작업 수를 제한합니다.
                    async with semaphore:
                        await browser.goto("https://sugang.inha.ac.kr/sugang/SU_53005/Remain_Search.aspx?gb=open&gubun=1&haksu=" + code_prefix_text)
                        await browser.context.add_cookies(cookies=cookies)

                        detail_page = browser.contexts[0].pages[-1]
                        await detail_page.wait_for_selector('#dgList > tbody > tr')

                        rows2 = await detail_page.query_selector_all("#dgList > tbody > tr")
                        for row2 in rows2:
                            code_element = await row2.query_selector("td:nth-child(3)")
                            code = (await code_element.text_content()).strip()
                            course, course_is_created = await sync_to_async(Course.objects.get_or_create)(code=code)
                            vacancy_element = await row2.query_selector("td:nth-child(8)")
                            course.vacancy = (await vacancy_element.text_content()).strip()

                            if course_is_created:
                                name_element = await row2.query_selector("td:nth-child(4)")
                                professor_element = await row2.query_selector("td:nth-child(6)")
                                course.name = (await name_element.text_content()).strip()
                                course.professor = (await professor_element.text_content()).strip()

                                new_courses.append(course)
                            else:
                                course_list.append(course)

                        await detail_page.close()

                # Django ORM 호출을 비동기로 처리
                await sync_to_async(Course.objects.bulk_update)(course_list, ['vacancy'])
                await sync_to_async(Course.objects.bulk_update)(new_courses, ['name', 'professor', 'vacancy'])

                print(f"\n-----------\n{major['name']} is OK\n-----------\n")

        except Exception as e:
            print(f"Error occurred: {e}")
        finally:
            await browser.close()

        end = time.time()
        print(f"Execute time: {end - start:.5f} sec")
        return HttpResponse(content="success!")
```
#### 1
한 과목을 들어가면 그 과목의 모든 수업 정보 n개가 나오는데, 그러면 n개의 수업 정보를 모두 들어가서 n개의 수업 정보를 모두 크롤링하므로 n<sup>n</sup>개의 수업을 크롤링해야해서 시간이 오래걸리게 된다.
=> 크롤링 한 번당 학수번호 앞자리가 같은 수업은 한 번만 들어가서 크롤링하면된다.
=> 그렇다면, map을 사용해 크롤링할 때 학수번호 앞자리를 저장하고, 저장되지 않았을 때만 크롤링하면 어떨까?
#### 2
순차적으로 크롤링해서 cpu를 제대로 활용하지 않는 것 같다
=> 비동기 프로그래밍을 사용한다.
#### 3
화면을 밖으로 표현하는데에도 시간이 걸릴 것 같다
###### 해결 방법
- Headless option : 이 옵션은 Browser를 HeadLess Mode로 실행하도록 지정하는 것입니다. 즉, GUI 없이 Background에서 실행됩니다. 이 옵션을 사용하면 Browser를 화면에 표시하지 않고도 WebDriver를 사용할 수 있습니다.
- No-sandbox : 이 옵션은 Browser가 보안 취약점에 노출될 가능성을 최소화하기 위해 사용되는 Sandbox 보호 기능을 해제하는 것입니다. Web Driver를 사용할 때, 해당 옵션을 사용해 Sandbox 기능을 OFF로 돌렸습니다. 이유는 보안이 목적이 아닌 가능한 빠르게 Application을 실행하는 것이 목표이기 때문입니다.
#### 4
한 개씩 저장/업데이트 하던 것을 학과별로 bulk update하게 변경 (데이터 유실의 가능성때문에 학과별로 하기로 결정)
#### 5
`driver.implicitly_wait(1)`를 하던 것을 `wait.until(ec.presence_of_element_located((By.CSS_SELECTOR, '#dgList > tbody > tr')))`처럼 바꾸어 Selenium의 명시적 대기를 활용할 수 있게 하였다.
