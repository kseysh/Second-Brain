###### 모니터를 사용하는 이유
세마포어가 구조화 되지 않은 저수준의 방식이라 경쟁 조건에 취약함
따라서 프로세스 동기화를 위해 편리하고 효과적인 메커니즘을 제공하는 고수준 추상화가 필요하기 때문
=> 세마포어가 경쟁 조건에 취약한 저수준의 방식이라 프로세스 동기화를 위해 고수준 추상화가 된 모니터를 사용함
###### 모니터가 캡슐화 하는 것
공유 데이터 구조
공유 데이터를 조작하는 프로시저들
해당 프로시저를 호출하는 동시 스레드 간의 동기화
###### 모니터 내 큐
Entry Queue: 모니터에 진입을 기다리는 모든 thread가 대기하는 큐
Condition Variable Queue: wait()을 호출한 스레드가 특정 조건이 만족될 때 까지 대기하는 큐
signal lock queue: signal을 날리고 대기하는 큐
###### 프로세스 P가 x.signal()을 호출하고, 프로세스 Q가 x.wait()으로 중단되어 있는 경우 다음에 어떤 일이 일어나야 하는가?
Signal and wait : P는 sig_lock_queue에서 대기, Q는 실행
Signal and continue : P가 계속 실행, Q는 sig_lock_queue에서 대기
Concurrent Pascal 언어: P는 exit(), Q는 실행
###### signal wait 방식의 모니터 wait 구현
```cpp
x_count++; // 현재 스레드가 x를 기다리므로 대기자 수 증가
if (sig_lock_count > 0) // 이미 누군가 x.signal()을 호출한 상태라면,
	signal(sig_lock); // signal을 기다리던 스레드 하나를 깨움
else
	signal(monitor_lock); // 그렇지 않으면 monitor_lock을 넘겨줌
wait(x_sem); // x.signal()이 호출될 때까지 대기
x_count--; // 일어나서 다 기다렸으니 나갈거라서 x_count를 감소
```
x_count++, 다음 프로세스 호출, wait(x_sem), x_count--
###### signal wait 방식의 모니터 signal 구현
```cpp
if (x_count > 0) { // 조건 변수 x를 기다리는 스레드가 있다면
	sig_lock_count++; // signal을 기다리는 스레드 수 증가
	signal(x_sem); // 기다리던 스레드 하나를 깨움
	wait(sig_lock); // signal한 스레드는 sig_lock에서 잠시 대기 (깨운 스레드가 모니터를 먼저 갖고 실행을 계속하게 하기 위함)
	sig_lock_count--; // signal 대기 스레드 수 감소
}
```
sig_lock_count++, signal(s_xem), wait(sig_lock_count), sig_lock_count--
###### Bounded-Buffer Problem에서 mutex, full, empty 세마포어의 초기 값과 역할
•	세마포어 mutex는 1로 초기화됨 (buffer 접근에 대한 mutual exclusion 보장하는 semaphore)
•	세마포어 full은 0으로 초기화됨  (n개 중에 몇 개가 사용되고 있는지)
•	세마포어 empty는 n으로 초기화됨 (n개 중에 비어있는 buffer의 수)
###### Bounded-Buffer Problem에서 생산자 프로세스 구조 (do while 안에서 wait, signal 순서)
```cpp
do {
  …
  /* next_produced에 항목을 생성 */
  …
  wait(empty); // 접근 가능한 빈 semaphore가 있는지 check
  wait(mutex); // buffer는 공유객체이므로 잠그고 들어감
  …
  /* next_produced를 버퍼에 추가 */
  …
  signal(mutex);  
  signal(full);  
} while (true);
```
###### Bounded-Buffer Problem에서 소비자 프로세스 구조 (do while 안에서 wait, signal 순서)
```cpp
do {
  wait(full); // buffer에 유효한 data가 채워졌는지 check
  wait(mutex); // buffer는 공유객체이므로 잠그고 들어감
  …
  /* 버퍼에서 항목을 제거하여 next_consumed에 저장 */
  …
  signal(mutex); // 
  signal(empty); // 
  …
  /* next_consumed에 있는 항목을 소비 */
  …
} while (true);
```
###### Readers-Writers Problem이란?
•	하나의 데이터 집합을 여러 동시 실행 프로세스가 공유함
	•	Reader(읽기 전용): 데이터를 읽기만 하고 갱신하지 않음
	•	Writer(쓰기 가능): 데이터를 읽고 쓸 수 있음
•	문제: 여러 Reader가 동시에 읽을 수 있도록 허용하되, Writer는 단독으로 접근해야 함 (Write 중 다른 Reader가 읽어도 안 됨)
###### Readers-Writers Problem에서 rw_mutex, mutex, read_count 초기 값
•	세마포어 rw_mutex = 1 (하나의 writer만 접근하도록 하는 mutex)
•	세마포어 mutex = 1 (read_count 접근 통제용 mutex)
•	정수 read_count = 0
###### Readers-Writers Problem에서 Writer 프로세스 구조
```cpp
do {
  wait(rw_mutex);
  /* 쓰기 작업 수행 */
  signal(rw_mutex);
} while (true);
```
###### Readers-Writers Problem에서 Reader 프로세스 구조
```cpp
do {
  wait(mutex);
  read_count++;
  if (read_count == 1)
    wait(rw_mutex); // 최초로 진입하는 reader만 이 과정 수행
  signal(mutex); // 들어왔으니 read_count에 대한 접근 권한을 해제해줌

  /* 읽기 작업 수행 */

  wait(mutex);
  read_count--;
  if (read_count == 0)
    signal(rw_mutex); // 남은 Reader가 아무도 없으면 Writer가 들어올 수 있도록 signal(rw_mutex)를 날려줌
  signal(mutex);
} while (true);
```
읽기 전 read count++, 읽고 나서 read count--
read count 변경 시에는 앞뒤로 wait(mutex), signal(mutex)
###### Readers-Writers Problem - Writer preference에서 초기값
semaphore rw_mutex = 1;
semaphore mutex = 1;
int read_count = 0;
semaphore queue = 1;  (Writer가 수행 중일 때 새 Reader를 차단)
###### Readers-Writers Problem - Writer preference에서 Writer 프로세스 구조
```cpp
do {
	wait (queue);
	wait (rw_mutex);
	
	/* writing is performed */
	
	signal(rw_mutex);
	signal(queue);
} while (true);
```
###### Readers-Writers Problem - Writer preference Reader 프로세스 구조
```cpp
do{
	wait(queue);
	// 2. signal(queue) 이건 유효함
	wait(mutex);
	
	read_count++;
	if (read_count == 1)
		wait(rw_mutex);
		
	signal(mutex);
	signal(queue);

	/ * reading is performed */
	
	wait(mutex);
		
	read_count--;
	if (read_count == 0)
		signal(rw_mutex);
		
	signal(mutex);
	
} while (true);
```
###### 위에서 wait(queue)와 wait(mutex)가 바뀌었을 때의 문제
1번에서 deadlock이 발생하는 상황: 1번 Reader가 reading 중이고, 2번 Reader가 wait(mutex) 통과 Writer는 wait(rw_mutex) 대기 중이라면, 
1번 Reader는 rw_mutex를 가지고 mutex를 기다리고
2번 Reader는 mutex를 가지고 queue를 기다리고
Writer는 queue를 가지고 rw_mutex를 가지는 데드락 상황이 발생함
###### Readers-Writers Problem 문제
기아 문제 발생할 수 있음
###### 식사하는 철학자 문제에서 세마포어 사용이 해법이 될 수 없는 이유
데드락 발생 가능하기 때문
###### 식사하는 철학자 문제에서 데드락을 피하는 방법 3가지
1.	동시에 식탁에 앉을 수 있는 철학자를 최대 4명으로 제한
2.	두 젓가락이 모두 있을 때만 집을 수 있게 함 (임계 구역 사용)
3.	비대칭 해법 사용:
	•	홀수 번호 철학자는 왼쪽 먼저, 그다음 오른쪽
	•	짝수 번호 철학자는 오른쪽 먼저, 그다음 왼쪽
###### 식사하는 철학자 문제에서의 모니터 솔루션
```cpp
monitor DiningPhilosophers {
	enum {THINKING, HUNGRY, EATING} state[5];
	condition self[5];
	
	initialization_code() {
		for (int i=0; i<5; i++)
			state[i] = THINKING;
	}

	void test(int i) {
		if ((state[(i+4)%5] != EATING && // 왼쪽 이웃이 식사 중이 아니고
		(state[i] == HUNGRY) && // 내가 배고플 때
		(state[(i+1)%5] != EATING)) { // 오른쪽 이웃이 식사 중이 아니고
			state[i] = EATING; // 위 조건을 충족해야 먹을 수 있음
			self[i].signal(); // 철학자 i에게 식사해도 된다고 알림
		}
	}

	void pickup(int i) {
		state[i] = HUNGRY;
		test(i);
		if (state[i] != EATING) self[i].wait; // state[i] == HUNGRY 라면 (철학자 i가 식사할 수 없으면 대기)
	}
	
	void putdown(int i) {
		state[i] = THINKING;
		test((i+4)%5);
		test((i+1)%5);
	}
}
```

```cpp
DiningPhilosophers.pickup(i);
/* 식사 */
DiningPhilosophers.putdown(i);
```
###### 생각하는 철학자 문제의 문제
데드락 없음, 그러나 기아 발생 가능 (오른쪽 왼쪽 사람만 계속 먹을 수도 있기 때문)
###### Deadlock 정의
•	하나의 프로세스 집합 내에서 각 프로세스가 다른 프로세스가 가진 어떤 것을 기다리고 있는 상황
•	모두가 기다리고 있으므로, 아무도 기다리는 자원을 제공할 수 없음
###### Deadlock 4가지 조건
•	상호 배제 (Mutual exclusion)
	•	한 번에 하나의 프로세스만 자원을 사용할 수 있음
•	비선점 (No preemption)
	•	한 번 할당된 자원은 강제로 빼앗을 수 없음
•	보유와 대기 (Hold and wait)
	•	하나 이상의 자원을 보유한 프로세스가 다른 자원을 요청하며 대기 중
•	순환 대기 (Circular wait)
	•	자원을 가진 프로세스들이 서로가 가진 자원을 기다리는 원형의 대기 관계 존재
###### Allocation Graph에서 순환고리가 만들어졌다면
무조건 데드락이 걸리는 것은 아님
###### Resource-Allocation Graph 그리기
![[Pasted image 20250508173439.png|150]]
![[Pasted image 20250508173742.png|300]]
###### Deadlock 두 가지 해결책
•	교착 상태 예방/회피
	•	시스템을 구성할 때 교착 상태가 절대 발생하지 않도록 설계
	•	자원 효율성이 낮아질 수 있음
•	교착 상태 탐지 및 복구
	•	시스템이 교착 상태인지 판단하고, 심각한 조치를 취함
	•	하나 이상의 프로세스를 종료하여 자원을 회수해야 할 수 있음
###### 교착 상태 예방법
•	네 가지 조건 중 하나를 피하는 방식:
	•	*No mutual exclusion*
		•	공유 자원에 대한 배타적 접근을 허용하지 않음
		•	많은 애플리케이션에서 비현실적
	•	*Preemption*
		•	자원을 보유한 프로세스가 새로운 자원을 요청했을 때 즉시 할당할 수 없다면, 기존 자원 모두를 반납시킴
		•	요청 실패 시 기존 자원 반납
		•	해당 프로세스는 모든 자원을 다시 얻을 수 있을 때까지 재시작되지 않음
	•	*No hold and wait*
		•	프로세스가 자원을 요청할 때, 다른 자원을 보유하고 있지 않아야 함을 보장해야 함
			•	예) 프로세스가 필요한 모든 자원을 한 번에 요청하게 만듦
		•	필요한 자원을 전부 다 얻거나, 아니면 전부 다 얻을 때까지 대기
		•	처음부터 모든 자원을 한 번에 요청
	•	*No circular wait*
		•	자원 요청에 순서를 부여함
			•	예: 먼저 S 자원들, 그 다음 T 자원들을 요청
		•	모든 프로세스가 같은 순서를 따르도록 강제함
###### no hold and wait 단점
•	프로세스 입장에서는 불편함
	•	필요한 자원을 미리 예측하기 어려워, 자원을 매우 비효율적으로 사용할 수 있음
	•	낮은 자원 활용률 또는 기아 상태가 발생할 수 있음
###### safe state & unsafe state
*safe state*: 프로세스에 최대 자원을 할당해도 교착 상태가 발생하지 않는 순서가 존재하는 상태
unsafe state: 교착 상태로 이어질 수 있음
###### Banker's Algorithm이 현실적이지 못한 이유
- Max를 알기 어렵다
- 자원 할당 wait이 길어질 수 있음
- 너무 보수적 -> resource utilization이 낮은 방법
###### 교착 상태 처리 매커니즘의 한계
교착 상태 예방 및 방지가 비용이 많이 든다. 교착 상태를 탐지하더라도 복구가 어렵다.
###### 단일 인스턴스의 경우 Deadlock Detection
•	Wait-for 그래프를 유지하여 주기적으로 그래프 내의 사이클을 탐색하는 알고리즘을 호출하고 사이클이 존재하면 교착 상태가 존재
•	그래프 내 사이클을 탐지하는 알고리즘의 시간 복잡도: O(n²), n = 정점 수
###### Multiple Instance의 경우 Deadlock Detection
Request를 Need로 가정한 Banker's Algorithm을 풀어 감지한다.
###### Multiple Instance의 경우 Deadlock Detection이 Banker's Algorithm과 다른 점
MAX값을 모른다
###### 교착 상태 복구 방법
•	모든 교착 상태의 프로세스를 종료
•	교착 상태의 사이클이 제거될 때까지 하나씩 종료
- Resource Preemption
###### Resource-Allocation Graph vs. Corresponding wait-for graph
![[Pasted image 20250513174344.png|300]]
###### Resource Preemption시 고려해야 할 사항
•	희생자 선택 – 비용 최소화
•	롤백 – 안전 상태로 되돌아가 그 상태부터 재시작
•	기아 – 동일한 프로세스가 항상 희생자가 되는 상황을 방지해야 하며, 롤백 횟수를 비용에 포함
#### 한 사이클 (Monitor / Deadlock)
###### CPU가 직접 접근할 수 있는 저장 장치
Main memory, register
###### source code, compiled code, linker에서의 주소
• source code address는 일반적으로 symbolic임
• Compiled code addresses는 relocatable address에 바인딩됨
	• 예: “이 모듈의 시작점에서 14바이트 떨어진 위치”
• linker나 loader는 relocatable address를 절대 주소로 바인딩함
######  Logical, physical address
• *Logical address* - CPU가 생성한 주소, *가상 주소*라고도 함 (Program에 명시된 주소)
• *Physical address* - 메모리 장치가 보는 주소
###### MMU란?
Memory-Management Unit으로 HW
• 실행 시간에 logical address를 physical address로 매핑하는 하드웨어 장치
###### relocation register를 사용하는 MMU
physical address = logical address + relocation address의 값
![[Pasted image 20250520165929.png|300]]
###### Contiguous Memory Allocation에서 메모리 관리 방법
초기의 메모리 관리 방법 중 하나
• 메인 메모리는 보통 두 개의 파티션으로 나뉨:
	• 상주 운영체제는 일반적으로 인터럽트 벡터와 함께 저주소 영역에 위치
	• 사용자 프로세스는 고주소 영역에 위치
	• 각 프로세스는 메모리의 하나의 연속된 구간에 포함됨
###### Contiguous Memory Allocation에서 user process를 관리하기 위한 base, limit 레지스터 관리
•	사용자 프로세스를 서로 또는 OS 코드와 데이터로부터 보호하기 위해 relocation register 사용
	• base register는 가장 작은 물리 주소 값을 가짐
	• 리미트 레지스터는 logical address의 범위를 가짐
	• MMU는 논리 주소를 실행 중에 동적으로 매핑함
![[Pasted image 20250520170458.png|300]]
###### Multiple partition allocation의 OS에서 저장하는 정보
• (a) 할당된 파티션
• (b) 사용 가능한 파티션(hole)
###### Contiguous Allocation 단점
- **단편화(Fragmentation)**
• 외부 단편화(External fragmentation)
	• 요청을 만족시킬 수 있는 전체 메모리 공간은 있으나 연속되지 않아서 사용할 수 없음
• 내부 단편화(Internal fragmentation)
	• 할당된 메모리가 요청보다 조금 더 클 수 있으며, 이 크기 차이는 파티션 내부에서 사용되지 않아서 사용할 수 없음
- **50% 규칙**
• First-fit 분석 결과, N개의 블록이 할당되면 절반의 블록이 단편화로 손실됨
	• 1/3 정도가 사용 불가능할 수 있음
###### Contiguous Allocation 단점 극복 방법
압축(Compaction)은 외부 단편화를 줄임
	• 메모리 내용을 재배열하여 모든 빈 메모리를 하나의 큰 블록으로 만듦
	• 압축은 주소 재배치가 동적이며 실행 시간 중에 가능한 경우에만 수행 가능
	• I/O 문제
		• I/O 작업 중인 job은 메모리에 유지해야 함
###### Swapping
- 프로세스를 메모리에서 임시로 백업 저장소로 스왑 아웃한 뒤, 이후에 다시 메모리로 불러와 실행을 계속할 수 있음
	- 프로세스들의 총 물리 메모리 공간이 실제 물리 메모리보다 클 수 있음
- 스와핑 시간의 대부분은 전송 시간이며, 총 전송 시간은 스왑되는 메모리 양에 비례
- 시스템은 디스크에 메모리 이미지를 가진 실행 준비 상태의 프로세스 목록(*ready queue*)을 유지함
###### Backing store
- 모든 사용자들의 메모리 이미지를 저장할 수 있을 만큼 충분히 큰 빠른 디스크
	- 이러한 메모리 이미지에 직접 접근할 수 있어야 함
###### Roll out, Roll in
- 롤 아웃, 롤 인(*Roll out, roll in*) – 우선순위 기반 스케줄링 알고리즘에서 사용되는 스와핑 방식
	- 낮은 우선순위의 프로세스를 스왑 아웃하고 높은 우선순위 프로세스를 로드하여 실행 
	- = swap out, swap in
###### swapping으로 인해 context switching 시간이 길어지는 사례
• CPU에 올릴 다음 프로세스가 메모리에 없다면, 다른 프로세스를 swap out하고 대상 프로세스를 swap in해야 함
	• 이 경우 컨텍스트 스위치 시간이 매우 길어질 수 있음
• 예: 100MB 프로세스를 하드디스크에 스왑(전송 속도 50MB/sec)
	• swap out에 2000ms 소요
	• 동일한 크기의 프로세스를 swap in하는 데 추가로 시간 소요
	• 총 컨텍스트 스위치의 스와핑 시간 구성 요소는 4000ms (4초)
###### swapping 시간을 줄이는 방법
프로세스의 모든 메모리를 OS에 올리는 것이 아닌, 정확히 필요한 메모리만 OS에 알려주어 swap할 데이터의 크기를 줄인다.
• request_memory(), release_memory()와 같은 시스템 호출로 운영체제에 메모리 사용 정보를 전달 가능
###### 일부 OS에서 swap 개념을 사용하지 않는 이유
• 플래시 메모리 기반 (USB, SSD, Smart phone)
	• *제한된 쓰기 횟수*
	• 작은 저장 용량
	• 모바일 플랫폼에서는 플래시 메모리와 CPU 간의 처리량이 낮음
###### segment에 저장되는 정보
process에 저장되는 정보라고 보면 될 듯
• 메인 프로그램
• 함수
• 객체
• 지역 변수, 전역 변수
• 스택
• 심볼 테이블
• 배열
###### segmentation이란?
메모리의 유저 뷰를 지원하는 메모리 관리 스키마
• 프로세스가 여러 메모리 영역에 나뉘어 존재하는 것을 허용
• 각 세그먼트에 대해 개별적인 base, limit register 쌍을 사용하며, two protection bits(읽기 및 쓰기)도 추가
###### segmentation에서 메모리 참조의 세 가지 방식
각 메모리 참조는 세 가지 방식 중 하나 이상으로 세그먼트와 오프셋을 지정

• 주소의 상위 비트는 세그먼트를 선택하고, 하위 비트는 오프셋을 나타냄 (4가지로 나누려면 상위 두 비트만 8가지로 나누려면 상위 세 비트 이런 식으로 1/n하는 것)
• 명령어에 의해 암시적으로 세그먼트가 선택됨
	• 예시: 코드 vs. 데이터, 스택 vs. 데이터
• 세그먼트 테이블은 프로세스의 모든 세그먼트에 대한 base와 limit를 저장
contiguous: process마다 base와 limit
segmentation: segment마다 base와 limit
###### segmentation에서의 논리 주소
• 논리 주소는 두 개의 튜플로 구성됨
	• <segment-number, offset>
	![[Pasted image 20250522165318.png|200]]
###### segment table에서 저장하는 값
• 세그먼트 테이블은 이차원 물리 주소를 매핑함
	• base - 세그먼트가 메모리 내에 위치하는 시작 물리 주소
	• limit - 세그먼트의 길이
###### STBR, STLR
• 세그먼트 테이블 베이스 레지스터(STBR): 세그먼트 테이블의 물리 메모리 내 위치(시작 주소)를 가리킴
• 세그먼트 테이블 길이 레지스터(STLR): 세그먼트 테이블에 포함된 세그먼트 개수 (즉, segment number의 유효 범위)
	• segment number는 STLR보다 작을 때 유효함
###### segmentation 방식에서 physical address를 얻는 방법
1. STBR에서 segment table의 physical memory 내 위치를 찾는다
2. segment number (s)가 STLR보다 작은지 검사
	- 그렇지 않으면 trap 발생
3. segment number를 이용해 segment table에서 base와 limit 값을 가져옴
4. offset (d)이 limit보다 작은지 검사
	- 그렇지 않으면 trap 발생
5. base + offset을 계산해 physical address 구함
###### 내부 단편화 일어나는 이유
고정 크기 블록을 사용해 프로세스가 블록 전체를 다 쓰지 않고 일부만 사용하기 때문
###### segmentation에서 contiguous Allocation의 내부 단편화 해결 방법
- segment는 가변 크기이므로 내부 단편화 해결
	- 각 segment는 프로그램에 논리적 구조에 맞춰 정확히 필요한 크기만큼만 메모리를 할당받음
###### segmentation의 문제점
- 여러 크기의 segment가 메모리에 들어갔다 나가면 중간중간 작은 holes가 생기게 되어 외부 단편화 발생
#### 한 사이클 (Memory 관리)
###### paging의 목적
• 고정 크기 메모리 블록을 사용해 할당 및 스와핑을 더 쉽게 수행
• 메모리 단편화를 줄이기 위함
###### frame, pages
• 물리 메모리를 고정 크기의 블록으로 나누며 이를 프레임(*frame*)이라 함 (physical page)
	• 크기는 2의 거듭제곱, 512바이트 ~ 16MB 범위 (4KB)
• 논리 메모리도 동일 크기의 블록으로 나누며 이를 페이지(*pages*)라 함 (logical page)
###### paging
• N개의 *페이지*로 구성된 프로그램을 실행하기 위해 *N개의 빈 프레임*을 찾아 프로그램을 로드
• 여전히 내부 단편화 발생 가능
###### page table
논리 주소를 물리 주소로 변환하는 것으로 page마다 어떤 frame에 매핑되었는지를 확인해준다.
###### Paging 방식에서 CPU가 물리 메모리 주소를 계산하는 방법
• 페이지 번호(p): 해당 논리 페이지가 물리 메모리의 어느 프레임에 있는지 찾는 데 사용됨 (page table의 인덱스라고 생각)
• 페이지 오프셋(d): 기본 주소와 결합되어 실제 물리 주소를 결정

• 논리 주소 공간이 2<sup>m</sup>이고 페이지 크기가 2<sup>n</sup>일 때 page number, page offset
![[Pasted image 20250522171227.png|200]]
m이 32, n이 12인 것을 가정

전체 메모리 4GB는 32bit 주소 표현
page size 4KB (=frame)
frame 갯수 = 4GB/4KB = 2<sup>20</sup>개
p = 20 bit (2<sup>m</sup>/2<sup>n</sup>개여야 하므로)
d = 12 bit
###### paging 과정
![[Pasted image 20250522171911.png|300]]
1. CPU가 page number(p)를 이용하여 page table에서 frame 주소을 가져온다
2. frame과 page offset(d)를 이용하여 physical address를 계산한다.
##### 내부 단편화 계산
• page size = 2048바이트
• process size = 72,766byte = 2048 x 35 + 1086 
###### Q
• 내부 단편화 = 2048 - 1086 = 962바이트
###### 최악의 경우 / 평균적 단편화
• 최악의 경우 단편화 = page size - 1byte
• 평균적으로 단편화 = ½ page size
###### Paging에서 작은 page size가 항상 좋은가?
작은 페이지 크기는 page table entry를 증가시킴
	• 페이지 크기는 시간이 지남에 따라 증가 추세 (4KB, 2MB, 1GB 등)
###### 32비트 주소 공간에 4KB 페이지 사용 시 페이지 테이블 크기
• 예: 32비트 주소 공간에 4KB 페이지 사용 시 페이지 테이블 크기 = 2<sup>(32−12)</sup> entries \* 20bit = 2.5MB
	2<sup>20</sup>개 page가 있고 각 page마다 할당된 frame 번호(20bit)
###### Free Frames 관리
![[Pasted image 20250522172822.png|400]]
Free Frame을 관리하며 메모리가 필요할 때마다 free frame list에서 빼서 할당해준다.
###### PTBR, PTLR
• *Page-table base register (PTBR)* 는 페이지 테이블 위치를 가리킴
• *Page-table length register (PTLR)* 는 페이지 테이블의 크기를 나타냄
###### page table의 단점과 해결 방법
단점: 이 방식에서는 데이터/명령어 접근마다 두 번의 메모리 접근이 필요함
(logical 주소를 physical 주소로 변환하기 위해서는 page table을 먼저 읽어와서 page table을 이용해서 physical address를 찾아야 한다.)
• 한 번은 페이지 테이블, 한 번은 실제 데이터/명령어

해결 방법:
• 이 문제는 *Translation Look-Aside Buffer(TLB)* 라는 고속 하드웨어 캐시를 사용하여 해결
• 일부 TLB는 address-space identifiers(ASID)를 각 항목에 저장 (어떤 process 정보인지)
	• 프로세스를 고유하게 식별하여 주소 공간 보호 제공
	• 그렇지 않으면 컨텍스트 스위치마다 TLB를 비워야 함
• TLB는 일반적으로 작음 (64 ~ 1,024 entries)
• TLB 미스 발생 시, 해당 항목을 TLB에 적재해 이후 접근을 빠르게 함 (page table entry를 읽어옴으로서)
###### Paging Hardware with TLB
1. CPU가 page number(p)를 이용하여 TLB에서 frame 주소를 가져온다.
	1. 없다면, page table에서 frame 주소를 가져오고 주소를 TLB에 반영한다.
2. frame과 page offset(d)를 이용하여 physical address를 계산한다.
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
