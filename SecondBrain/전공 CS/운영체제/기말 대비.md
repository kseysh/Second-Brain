###### 모니터를 사용하는 이유
=> 세마포어가 *경쟁 조건에 취약한 저수준*의 방식이라 프로세스 동기화를 위해 고수준 추상화가 된 모니터를 사용함
###### 모니터 내 큐
Entry Queue: 모니터에 진입을 기다리는 모든 thread가 대기하는 큐
Condition Variable Queue: wait()을 호출한 스레드가 특정 조건이 만족될 때 까지 대기하는 큐
signal lock queue: signal을 날리고 대기하는 큐
###### 모니터에서 x_sem의 수
0 -> wait() 이후에 signal을 호출할 수 있도록 하기 위함
###### 프로세스 P가 x.signal()을 호출하고, 프로세스 Q가 x.wait()으로 중단되어 있는 경우 다음에 어떤 일이 일어나야 하는가?
Signal and wait : P는 sig_lock_queue에서 대기, Q는 실행
Signal and continue : P가 계속 실행, Q는 sig_lock_queue에서 대기
Concurrent Pascal 언어: P는 exit(), Q는 실행
###### signal wait 방식의 모니터 wait 구현
```cpp
x_count++; // 현재 스레드가 x를 기다리므로 대기자 수 증가
if (sig_lock_count > 0) // 이미 누군가 x.signal()을 호출한 상태라면,
	signal(sig_lock); // signal을 기다리던 스레드 하나를 깨움
else
	signal(monitor_lock); // 그렇지 않으면 monitor_lock을 넘겨줌
wait(x_sem); // x.signal()이 호출될 때까지 대기
x_count--; // 일어나서 다 기다렸으니 나갈거라서 x_count를 감소
```
x_count++, 다음 프로세스 호출, wait(x_sem), x_count--
###### signal wait 방식의 모니터 signal 구현
```cpp
if (x_count > 0) { // 조건 변수 x를 기다리는 스레드가 있다면
	sig_lock_count++; // signal을 기다리는 스레드 수 증가
	signal(x_sem); // 기다리던 스레드 하나를 깨움
	wait(sig_lock); // signal한 스레드는 sig_lock에서 잠시 대기 (깨운 스레드가 모니터를 먼저 갖고 실행을 계속하게 하기 위함)
	sig_lock_count--; // signal 대기 스레드 수 감소
}
```
sig_lock_count++, signal(s_xem), wait(sig_lock_count), sig_lock_count--
###### Bounded-Buffer Problem에서 mutex, full, empty 세마포어의 초기 값과 역할
•	세마포어 mutex는 1로 초기화됨 (buffer 접근에 대한 mutual exclusion 보장하는 semaphore)
•	세마포어 full은 0으로 초기화됨  (n개 중에 몇 개가 사용되고 있는지)
•	세마포어 empty는 n으로 초기화됨 (n개 중에 비어있는 buffer의 수)
###### Bounded-Buffer Problem에서 생산자 프로세스 구조 (do while 안에서 wait, signal 순서)
```cpp
do {
  …
  /* next_produced에 항목을 생성 */
  …
  wait(empty); // 접근 가능한 빈 semaphore가 있는지 check
  wait(mutex); // buffer는 공유객체이므로 잠그고 들어감
  …
  /* next_produced를 버퍼에 추가 */
  …
  signal(mutex);  
  signal(full);  
} while (true);
```
###### Bounded-Buffer Problem에서 소비자 프로세스 구조 (do while 안에서 wait, signal 순서)
```cpp
do {
  wait(full); // buffer에 유효한 data가 채워졌는지 check
  wait(mutex); // buffer는 공유객체이므로 잠그고 들어감
  …
  /* 버퍼에서 항목을 제거하여 next_consumed에 저장 */
  …
  signal(mutex); // 
  signal(empty); // 
  …
  /* next_consumed에 있는 항목을 소비 */
  …
} while (true);
```
###### Readers-Writers Problem이란?
•	하나의 데이터 집합을 여러 동시 실행 프로세스가 공유함
	•	Reader(읽기 전용): 데이터를 읽기만 하고 갱신하지 않음
	•	Writer(쓰기 가능): 데이터를 읽고 쓸 수 있음
•	문제: 여러 Reader가 동시에 읽을 수 있도록 허용하되, Writer는 단독으로 접근해야 함 (Write 중 다른 Reader가 읽어도 안 됨)
###### Readers-Writers Problem에서 rw_mutex, mutex, read_count 초기 값
•	세마포어 rw_mutex = 1 (하나의 writer만 접근하도록 하는 mutex)
•	세마포어 mutex = 1 (read_count 접근 통제용 mutex)
•	정수 read_count = 0
###### Readers-Writers Problem에서 Writer 프로세스 구조
```cpp
do {
  wait(rw_mutex);
  /* 쓰기 작업 수행 */
  signal(rw_mutex);
} while (true);
```
###### Readers-Writers Problem에서 Reader 프로세스 구조
```cpp
do {
  wait(mutex);
  read_count++;
  if (read_count == 1)
    wait(rw_mutex); // 최초로 진입하는 reader만 이 과정 수행
  signal(mutex); // 들어왔으니 read_count에 대한 접근 권한을 해제해줌

  /* 읽기 작업 수행 */

  wait(mutex);
  read_count--;
  if (read_count == 0)
    signal(rw_mutex); // 남은 Reader가 아무도 없으면 Writer가 들어올 수 있도록 signal(rw_mutex)를 날려줌
  signal(mutex);
} while (true);
```
읽기 전 read count++, 읽고 나서 read count--
read count 변경 시에는 앞뒤로 wait(mutex), signal(mutex)
###### Readers-Writers Problem - Writer preference에서 초기값
semaphore rw_mutex = 1;
semaphore mutex = 1;
int read_count = 0;
semaphore queue = 1;  (Writer가 수행 중일 때 새 Reader를 차단)
###### Readers-Writers Problem - Writer preference에서 Writer 프로세스 구조
```cpp
do {
	wait (queue);
	wait (rw_mutex);
	
	/* writing is performed */
	
	signal(rw_mutex);
	signal(queue);
} while (true);
```
###### Readers-Writers Problem - Writer preference Reader 프로세스 구조
```cpp
do{
	wait(queue);
	// 2. signal(queue) 이건 유효함
	wait(mutex);
	
	read_count++;
	if (read_count == 1)
		wait(rw_mutex);
		
	signal(mutex);
	signal(queue);

	/ * reading is performed */
	
	wait(mutex);
		
	read_count--;
	if (read_count == 0)
		signal(rw_mutex);
		
	signal(mutex);
	
} while (true);
```
###### 위에서 wait(queue)와 wait(mutex)가 바뀌었을 때의 문제
1번에서 deadlock이 발생하는 상황: 1번 Reader가 reading 중이고, 2번 Reader가 wait(mutex) 통과 Writer는 wait(rw_mutex) 대기 중이라면, 
1번 Reader는 rw_mutex를 가지고 mutex를 기다리고
2번 Reader는 mutex를 가지고 queue를 기다리고
Writer는 queue를 가지고 rw_mutex를 가지는 데드락 상황이 발생함
###### Readers-Writers Problem 문제
기아 문제 발생할 수 있음
###### 식사하는 철학자 문제에서 세마포어 사용이 해법이 될 수 없는 이유
데드락 발생 가능하기 때문
###### 식사하는 철학자 문제에서 데드락을 피하는 방법 3가지
1.	동시에 식탁에 앉을 수 있는 철학자를 최대 4명으로 제한
2.	두 젓가락이 모두 있을 때만 집을 수 있게 함 (임계 구역 사용)
3.	비대칭 해법 사용:
	•	홀수 번호 철학자는 왼쪽 먼저, 그다음 오른쪽
	•	짝수 번호 철학자는 오른쪽 먼저, 그다음 왼쪽
###### 식사하는 철학자 문제에서의 모니터 솔루션
```cpp
monitor DiningPhilosophers {
	enum {THINKING, HUNGRY, EATING} state[5];
	condition self[5];
	
	initialization_code() {
		for (int i=0; i<5; i++)
			state[i] = THINKING;
	}

	void test(int i) {
		if ((state[(i+4)%5] != EATING && // 왼쪽 이웃이 식사 중이 아니고
		(state[i] == HUNGRY) && // 내가 배고플 때
		(state[(i+1)%5] != EATING)) { // 오른쪽 이웃이 식사 중이 아니고
			state[i] = EATING; // 위 조건을 충족해야 먹을 수 있음
			self[i].signal(); // 철학자 i에게 식사해도 된다고 알림
		}
	}

	void pickup(int i) {
		state[i] = HUNGRY;
		test(i);
		if (state[i] != EATING) self[i].wait; // state[i] == HUNGRY 라면 (철학자 i가 식사할 수 없으면 대기)
	}
	
	void putdown(int i) {
		state[i] = THINKING;
		test((i+4)%5);
		test((i+1)%5);
	}
}
```

```cpp
DiningPhilosophers.pickup(i);
/* 식사 */
DiningPhilosophers.putdown(i);
```
###### 생각하는 철학자 문제의 문제
데드락 없음, 그러나 기아 발생 가능 (오른쪽 왼쪽 사람만 계속 먹을 수도 있기 때문)
###### Deadlock 정의
•	하나의 프로세스 집합 내에서 각 프로세스가 다른 프로세스가 가진 어떤 것을 기다리고 있는 상황
•	모두가 기다리고 있으므로, 아무도 기다리는 자원을 제공할 수 없음
###### Deadlock 4가지 조건
•	상호 배제 (Mutual exclusion)
	•	한 번에 하나의 프로세스만 자원을 사용할 수 있음
•	비선점 (No preemption)
	•	한 번 할당된 자원은 강제로 빼앗을 수 없음
•	보유와 대기 (Hold and wait)
	•	하나 이상의 자원을 보유한 프로세스가 다른 자원을 요청하며 대기 중
•	순환 대기 (Circular wait)
	•	자원을 가진 프로세스들이 서로가 가진 자원을 기다리는 원형의 대기 관계 존재
###### Allocation Graph에서 순환고리가 만들어졌다면
무조건 데드락이 걸리는 것은 아님
###### Resource-Allocation Graph 그리기
![[Pasted image 20250508173439.png|150]]
![[Pasted image 20250508173742.png|300]]
###### Deadlock 두 가지 해결책
•	교착 상태 예방/회피
	•	시스템을 구성할 때 교착 상태가 절대 발생하지 않도록 설계
	•	자원 효율성이 낮아질 수 있음
•	교착 상태 탐지 및 복구
	•	시스템이 교착 상태인지 판단하고, 심각한 조치를 취함
	•	하나 이상의 프로세스를 종료하여 자원을 회수해야 할 수 있음
###### 교착 상태 예방법
•	네 가지 조건 중 하나를 피하는 방식:
	•	*No mutual exclusion*
		•	공유 자원에 대한 배타적 접근을 허용하지 않음
		•	많은 애플리케이션에서 비현실적
	•	*Preemption*
		•	자원을 보유한 프로세스가 새로운 자원을 요청했을 때 즉시 할당할 수 없다면, 기존 자원 모두를 반납시킴
		•	요청 실패 시 기존 자원 반납
		•	해당 프로세스는 모든 자원을 다시 얻을 수 있을 때까지 재시작되지 않음
	•	*No hold and wait*
		•	프로세스가 자원을 요청할 때, 다른 자원을 보유하고 있지 않아야 함을 보장해야 함
			•	예) 프로세스가 필요한 모든 자원을 한 번에 요청하게 만듦
		•	필요한 자원을 전부 다 얻거나, 아니면 전부 다 얻을 때까지 대기
		•	처음부터 모든 자원을 한 번에 요청
	•	*No circular wait*
		•	자원 요청에 순서를 부여함
			•	예: 먼저 S 자원들, 그 다음 T 자원들을 요청
		•	모든 프로세스가 같은 순서를 따르도록 강제함
###### no hold and wait 단점
•	프로세스 입장에서는 불편함
	•	필요한 자원을 미리 예측하기 어려워, 자원을 매우 비효율적으로 사용할 수 있음
	•	낮은 자원 활용률 또는 기아 상태가 발생할 수 있음
###### safe state & unsafe state
*safe state*: 프로세스에 최대 자원을 할당해도 교착 상태가 발생하지 않는 순서가 존재하는 상태
unsafe state: 교착 상태로 이어질 수 있음
###### Banker's Algorithm이 현실적이지 못한 이유
- Max를 알기 어렵다
- 자원 할당 wait이 길어질 수 있음
- 너무 보수적 -> resource utilization이 낮은 방법
###### 교착 상태 처리 매커니즘의 한계
교착 상태 예방 및 방지가 비용이 많이 든다. 교착 상태를 탐지하더라도 복구가 어렵다.
###### 단일 인스턴스의 경우 Deadlock Detection
•	Wait-for 그래프를 유지하여 주기적으로 그래프 내의 사이클을 탐색하는 알고리즘을 호출하고 사이클이 존재하면 교착 상태가 존재
•	그래프 내 사이클을 탐지하는 알고리즘의 시간 복잡도: O(n²), n = 정점 수
###### Multiple Instance의 경우 Deadlock Detection
Request를 Need로 가정한 Banker's Algorithm을 풀어 감지한다.
###### Multiple Instance의 경우 Deadlock Detection이 Banker's Algorithm과 다른 점
MAX값을 모른다
###### 교착 상태 복구 방법
•	모든 교착 상태의 프로세스를 종료
•	교착 상태의 사이클이 제거될 때까지 하나씩 종료
- Resource Preemption
###### Resource-Allocation Graph vs. Corresponding wait-for graph
![[Pasted image 20250513174344.png|300]]
#### 한 사이클 (Monitor / Deadlock)
###### CPU가 직접 접근할 수 있는 저장 장치
Main memory, register
######  Logical, physical address
• *Logical address* - CPU가 생성한 주소, *가상 주소*라고도 함 (Program에 명시된 주소)
• *Physical address* - 메모리 장치가 보는 주소
###### MMU란?
Memory-Management Unit으로 HW
• 실행 시간에 logical address를 physical address로 매핑하는 하드웨어 장치
###### relocation register를 사용하는 MMU
physical address = logical address + relocation address의 값
![[Pasted image 20250520165929.png|300]]
###### Contiguous Memory Allocation에서 메모리 관리 방법
초기의 메모리 관리 방법 중 하나
• 메인 메모리는 보통 두 개의 파티션으로 나뉨:
	• 상주 운영체제는 일반적으로 인터럽트 벡터와 함께 저주소 영역에 위치
	• 사용자 프로세스는 고주소 영역에 위치
	• 각 프로세스는 메모리의 하나의 연속된 구간에 포함됨
###### Contiguous Memory Allocation에서 user process를 관리하기 위한 base, limit 레지스터 관리
•	사용자 프로세스를 서로 또는 OS 코드와 데이터로부터 보호하기 위해 relocation register 사용
	• base register는 가장 작은 물리 주소 값을 가짐
	• 리미트 레지스터는 logical address의 범위를 가짐
	• MMU는 논리 주소를 실행 중에 동적으로 매핑함
![[Pasted image 20250520170458.png|300]]
###### Multiple partition allocation의 OS에서 저장하는 정보
• (a) 할당된 파티션
• (b) 사용 가능한 파티션(hole)
###### Contiguous Allocation 단점
- **단편화(Fragmentation)**
• 외부 단편화(External fragmentation)
	• *요청을 만족시킬 수 있는 전체 메모리 공간은 있으나 연속되지 않아서 사용할 수 없음*
• 내부 단편화(Internal fragmentation)
	• 할당된 메모리가 요청보다 조금 더 클 수 있으며, 이 크기 차이는 파티션 내부에서 사용되지 않아서 사용할 수 없음
- **50% 규칙**
• First-fit 분석 결과, N개의 블록이 할당되면 절반의 블록이 단편화로 손실됨
	• 1/3 정도가 사용 불가능할 수 있음
###### Contiguous Allocation 단점 극복 방법
압축(Compaction)은 외부 단편화를 줄임
	• 메모리 내용을 재배열하여 모든 빈 메모리를 하나의 큰 블록으로 만듦
	• 압축은 **주소 재배치가 동적이며 실행 시간 중에 가능한 경우에만 수행 가능**
	• I/O 문제
		• I/O 작업 중인 job은 메모리에 유지해야 함
###### Swapping
- 프로세스를 메모리에서 임시로 backing store로 스왑 아웃한 뒤, 이후에 다시 메모리로 불러와 실행을 계속할 수 있음
	- 프로세스들의 총 물리 메모리 공간이 실제 물리 메모리보다 클 수 있음
- 스와핑 시간의 대부분은 전송 시간이며, 총 전송 시간은 스왑되는 메모리 양에 비례
- 시스템은 디스크에 메모리 이미지를 가진 실행 준비 상태의 프로세스 목록(*ready queue*)을 유지함
###### Backing store
- 모든 사용자들의 *메모리 이미지*를 저장할 수 있을 만큼 충분히 큰 빠른 디스크
	- 이러한 메모리 이미지에 직접 접근할 수 있어야 함
###### Roll out, Roll in
- 롤 아웃, 롤 인(*Roll out, roll in*) – 우선순위 기반 스케줄링 알고리즘에서 사용되는 스와핑 방식
	- 낮은 우선순위의 프로세스를 스왑 아웃하고 높은 우선순위 프로세스를 로드하여 실행 
	- = swap out, swap in
###### swapping 시간을 줄이는 방법
프로세스의 모든 메모리를 OS에 올리는 것이 아닌, 정확히 필요한 메모리만 OS에 알려주어 swap할 데이터의 크기를 줄인다.
• request_memory(), release_memory()와 같은 시스템 호출로 운영체제에 메모리 사용 정보를 전달 가능
###### 일부 OS에서 swap 개념을 사용하지 않는 이유
• 플래시 메모리 기반 (USB, SSD, Smart phone)
	• *제한된 쓰기 횟수*
	• 작은 저장 용량
	• 모바일 플랫폼에서는 플래시 메모리와 CPU 간의 처리량이 낮음
###### segment에 저장되는 정보
process에 저장되는 정보라고 보면 될 듯
• 메인 프로그램
• 함수
• 객체
• 지역 변수, 전역 변수
• 스택
• 심볼 테이블
• 배열
###### segmentation이란?
프로세스의 주소 공간을 논리적인 단위인 segment로 나누는 메모리 관리 기법
• 각 세그먼트에 대해 개별적인 base, limit register 쌍을 사용하며, two protection bits(읽기 및 쓰기)도 추가
###### segmentation에서 메모리 참조의 세 가지 방식
각 메모리 참조는 세 가지 방식 중 하나 이상으로 세그먼트와 오프셋을 지정

1) 주소의 상위 비트로 세그먼트 선택, 하위 비트로 오프셋 지정
	•	예: 110000101011 → 앞 4비트: 세그먼트, 뒤 8비트: offset
2) 명령어 자체가 암묵적으로 어떤 세그먼트를 사용할지 정함
	•	예: push는 스택 세그먼트, jmp는 코드 세그먼트
3) 세그먼트 테이블 사용
	•	테이블에 각 세그먼트의 base, limit 값 저장해두고 사용
	•	프로세스마다 자기만의 세그먼트 테이블 가짐
###### segmentation에서의 논리 주소
• 논리 주소는 두 개의 튜플로 구성됨
	• <segment-number, offset>
	![[Pasted image 20250522165318.png|200]]
###### segment table에서 저장하는 값
• 세그먼트 테이블은 이차원 물리 주소를 매핑함
	• base - 세그먼트가 메모리 내에 위치하는 시작 물리 주소
	• limit - 세그먼트의 길이
###### STBR, STLR
• 세그먼트 테이블 베이스 레지스터(STBR): 세그먼트 테이블의 물리 메모리 내 위치(시작 주소)를 가리킴
• 세그먼트 테이블 길이 레지스터(STLR): 세그먼트 테이블에 포함된 세그먼트 개수 (즉, segment number의 유효 범위)
	• segment number는 STLR보다 작을 때 유효함
###### segmentation 방식에서 physical address를 얻는 방법
1. STBR에서 segment table의 physical memory 내 위치를 찾는다
2. segment number (s)가 STLR보다 작은지 검사
	- 그렇지 않으면 trap 발생
3. segment number를 이용해 segment table에서 base와 limit 값을 가져옴
4. offset (d)이 limit보다 작은지 검사
	- 그렇지 않으면 trap 발생
5. base + offset을 계산해 physical address 구함
###### 내부 단편화 일어나는 이유
고정 크기 블록을 사용해 프로세스가 블록 전체를 다 쓰지 않고 일부만 사용하기 때문
###### segmentation에서 contiguous Allocation의 내부 단편화 해결 방법
- segment는 가변 크기이므로 정확히 필요한 크기만큼만 메모리를 할당받기 때문에 내부 단편화 해결
###### segmentation의 문제점
- 여러 크기의 segment가 메모리에 들어갔다 나가면 중간중간 작은 holes가 생기게 되어 외부 단편화 발생
###### paging의 목적
• 고정 크기 메모리 블록을 사용해 할당 및 스와핑을 더 쉽게 수행
• 메모리 단편화를 줄이기 위함
###### frame, pages
• 물리 메모리를 고정 크기의 블록으로 나누며 이를 프레임(*frame*)이라 함 (physical page)
	• 크기는 2의 거듭제곱, 512바이트 ~ 16MB 범위 (4KB)
• 논리 메모리도 동일 크기의 블록으로 나누며 이를 페이지(*pages*)라 함 (logical page)
###### page table
논리 주소를 물리 주소로 변환하는 것으로 page마다 어떤 frame에 매핑되었는지를 확인해준다.
###### Paging 방식에서 CPU가 물리 메모리 주소를 계산하는 방법
• 페이지 번호(p): 해당 논리 페이지가 물리 메모리의 어느 프레임에 있는지 찾는 데 사용됨 (page table의 인덱스라고 생각)
• 페이지 오프셋(d): 기본 주소와 결합되어 실제 물리 주소를 결정
###### 논리 주소 공간이 2<sup>m</sup>이고 페이지 크기가 2<sup>n</sup>일 때 page number, page offset
![[Pasted image 20250522171227.png|200]]
m이 32, n이 12인 것을 가정
전체 메모리 4GB는 32bit 주소 표현
frame 갯수 = 4GB/4KB = 2<sup>20</sup>개
p = 20 bit (2<sup>m</sup>/2<sup>n</sup>개여야 하므로)
d = 12 bit
##### 내부 단편화 계산
• page size = 2048바이트
• process size = 72,766byte = 2048 x 35 + 1086 
###### Q
• 내부 단편화 = 2048 - 1086 = 962바이트
###### 최악의 경우 / 평균적 단편화
• 최악의 경우 단편화 = page size - 1byte
• 평균적으로 단편화 = ½ page size
###### Paging에서 작은 page size가 항상 좋은가?
작은 페이지 크기를 사용하면 같은 크기의 주소 공간을 더 많은 페이지로 나눠야 함.
•	이로 인해 페이지 테이블 엔트리 수가 증가하고, 전체 페이지 테이블의 크기도 커짐.
•	페이지 테이블이 너무 커지면 메모리 공간을 많이 차지하고, TLB 미스 시 페이지 테이블 접근 시간이 증가
###### 32비트 주소 공간에 4KB 페이지 사용 시 페이지 테이블 크기
• 예: 32비트 주소 공간에 4KB 페이지 사용 시 페이지 테이블 크기 = 2<sup>(32−12)</sup> entries \* 20bit = 2.5MB
	2<sup>20</sup>개 page가 있고 각 page마다 할당된 frame 번호(20bit)
###### Free Frames 관리
![[Pasted image 20250522172822.png|400]]
Free Frame list를 관리하며 메모리가 필요할 때마다 free frame list에서 빼서 할당해준다.
###### PTBR, PTLR
• *Page-table base register (PTBR)* 는 페이지 테이블 위치를 가리킴
• *Page-table length register (PTLR)* 는 페이지 테이블의 크기를 나타냄
###### page table의 단점과 해결 방법
단점: 이 방식에서는 데이터/명령어 접근마다 두 번의 메모리 접근이 필요함
(logical 주소를 physical 주소로 변환하기 위해서는 page table을 먼저 읽어와서 page table을 이용해서 physical address를 찾아야 한다.)
• 한 번은 페이지 테이블, 한 번은 실제 데이터/명령어

해결 방법:
• 이 문제는 *Translation Look-Aside Buffer(TLB)* 라는 고속 하드웨어 캐시를 사용하여 해결
• TLB는 일반적으로 작음 (64 ~ 1,024 entries)
• TLB 미스 발생 시, 해당 항목을 TLB에 적재해 이후 접근을 빠르게 함 (page table entry를 읽어옴으로서)
###### ASID가 필요한 이유
• 일부 TLB는 address-space identifiers(ASID)를 각 항목에 저장 (어떤 process 정보인지)

ASID가 없다면, 다른 프로세스가 실행될 때, 가상 주소 공간도 바뀌므로 기존 TLB 항목이 잘못된 것이 될 수 있어 컨텍스트 스위치마다 TLB를 비워야 하기 때문에 프로세스를 고유하게 식별하여 주소공간을 보호할 수 있도록 한다.
###### Paging Hardware with TLB
1. CPU가 page number(p)를 이용하여 TLB에서 frame 주소를 가져온다.
	1. 없다면, page table에서 frame 주소를 가져오고 주소를 TLB에 반영한다.
2. frame과 page offset(d)를 이용하여 physical address를 계산한다.
###### EAT 계산식
Effective Access Time
![[Pasted image 20250602014642.png|150]]
• 𝑡<sub>𝑇</sub>: TLB 접근 시간
• 𝑡<sub>𝑀</sub>: 메모리 접근 시간
• 𝛼: TLB 적중률 (0 ≤ 𝛼 ≤ 1)
**TLB hit라도, frame에 한 번 접근해야 한다는 사실 꼭 기억!**
###### 페이지 테이블 항목에 있는 추가 비트
• 각 프레임에 보호 비트를 부여하여 메모리 보호 구현
	• read-only 또는 read-write access 여부 표시
	• excute-only 등의 추가 비트를 지정할 수도 있음
• 페이지 테이블의 각 항목에는 valid/invalid bit 포함
	• valid(1): 해당 페이지가 프로세스의 논리 주소 공간 내에 있음
	• invalid(0): 해당 페이지가 프로세스의 논리 주소 공간에 없음
###### shared page
라이브러리 코드같은 경우는 다들 읽기만 할것이므로 공유해서 사용할 수 있다
• read only(재진입 가능한) 코드의 하나의 복사본을 여러 프로세스가 공유
• 다중 스레드가 같은 프로세스 공간을 공유하는 것과 유사
• read-write 공유가 허용되면 inter-process communication에도 유용
###### 계층적 페이지 테이블
![[Pasted image 20250527171741.png|200]]
• 논리 주소 공간을 여러 페이지 테이블로 분할
• 간단한 방식은 2단계 페이지 테이블(two-level page table) 사용
outer page table: inner page table들이 어떤 frame에 저장되었는지
###### 계층적 페이지 테이블이 필요한 이유
단일 프로세스가 너무 많은 페이지 테이블을 관리해야 하므로 이를 계층적으로 분해하여 공간을 절약하기 위함
##### Q
어떤 페이지 테이블 구조인지?
![[Pasted image 20250527174038.png|400]]
###### A
4KB짜리 페이지를 최대 2²⁰개 매핑할 수 있는 페이지 테이블 구조
###### 가상 메모리의 동기
코드와 데이터를 실행하려면 메모리에 있어야 하지만, 전체 프로그램이 항상 사용되는 것은 아니다
•	오류 처리 코드, 특이한 루틴, 큰 데이터 구조 등은 드물게 사용됨
partially-loaded program을 실행할 수 있다면  프로그램이 물리적 메모리 용량의 제약을 받지 않게 되어 실행 중인 각 프로그램이 적은 메모리를 차지함 → 동시에 더 많은 프로그램 실행 가능
프로그램을 메모리에 적재하거나 교체(swap)하는 데 필요한 I/O가 줄어듦(필요한 것만 가져다 두기 때문) → 사용자 프로그램이 더 빠르게 실행됨
###### 가상 메모리에서 사용자 논리 메모리와 물리 메모리를 분리한 이유
•	실행을 위해 프로그램의 일부만 메모리에 존재하면 됨
•	논리 주소 공간이 물리 주소 공간보다 훨씬 클 수 있음
•	여러 프로세스가 주소 공간을 공유 가능 (프로그램마다 주소에 똑같은 규칙을 적용해도 되기 때문)
	•	프로세스 생성이 더 효율적임
	•	더 많은 프로그램을 동시에 실행 가능
	•	프로세스를 적재하거나 교체하는 데 필요한 I/O 감소
###### 가상 주소 공간
프로세스가 메모리에 저장된 방식에 대한 논리적 관점
•	일반적으로 주소 0부터 시작해서 연속된 주소를 가짐
•	물리 메모리는 페이지 프레임 단위로 구성됨
•	MMU가 논리 주소를 물리 주소로 매핑해야 함
###### 가상 주소 공간 사용 예
•	시스템 라이브러리는 가상 주소 공간에 매핑하여 공유됨
•	페이지를 읽기-쓰기 형태로 가상 주소 공간에 매핑하여 공유 메모리 구현 가능
•	fork() 시 페이지 공유를 통해 프로세스 생성 속도 향상
![[Pasted image 20250529165445.png|200]]
###### Demand paging이란
페이지가 실제로 필요할 때만 메모리에 로딩하는 페이징 기법 (시점에 관한 개념)
###### Demand paging의 장점
•	필요한 페이지만 메모리에 불러옴
	•	불필요한 I/O 없음 → 더 적은 I/O
	•	더 적은 메모리 사용
	•	응답 시간 단축 (거대한 데이터를 가져오지 않아도 되니까)
	•	더 많은 사용자 수용 (메모리 공간이 줄어드니까)
###### Lazy Swapper
•	Lazy Swapper: 실제로 필요한 페이지만 메모리에 적재하는 방식 (데이터의 양에 대한 개념)
	•	페이지를 다루는 swapper는 pager라고 함
###### Demand Paging을 구현하기 위한 MMU의 새로운 기능
•	필요한 페이지가 이미 메모리에 있다면
	•	일반 페이징과 차이 없음
•	필요한 페이지가 메모리에 없다면
	•	저장 장치에서 해당 페이지를 감지하고 불러와야 함
###### MMU가 주소 변환 시 해당 비트가 i이면 
→ 페이지 폴트 발생
###### page fault시 발생하는 일
•	페이지 참조가 발생하면, 해당 페이지에 대한 첫 참조 시 운영체제로 trap 발생 (page fault)
1.	운영체제가 다른 테이블을 확인함
	•	잘못된 참조 → 중단
	•	단지 메모리에 없을 경우 다음 step
2.	빈 프레임 찾기
3.	disk operation을 통해 해당 페이지를 프레임에 swap in
4.	페이지가 메모리에 있다고 테이블 갱신, valid-invalid bit를 v로 세팅
5.	페이지 폴트를 유발한 명령어를 재시작
![[Pasted image 20250529171418.png|400]]
###### pure demand paging
•	*pure demand paging*: 처음에는 아무 페이지도 메모리에 없이 프로세스 시작
	•	OS는 프로세스의 첫 명령어 위치로  instruction pointer를 설정 → 메모리에 없음 → 페이지 폴트
	•	다른 모든 페이지들도 처음 접근 시 페이지 폴트
###### multiple page faults
실제로는 하나의 명령어가 여러 페이지를 접근할 수도 있음 → multiple page faults
•	예시: 메모리에서 두 수를 더하고 결과를 저장하는 명령어의 fetch/decode 과정
•	지역성(locality of reference) 때문에 이러한 비용이 완화됨
###### Demand Paging을 위한 하드웨어 지원
1.	페이지 테이블: 각 페이지의 존재 여부, 프레임 번호, 수정 여부 등
2.	MMU (메모리 관리 장치): 주소 변환 수행
3.	TLB (Translation Lookaside Buffer): 주소 변환 캐시
4.	페이지 폴트 처리 인터럽트 지원

###### 메모리 관련 오류 두 가지
•	TLB Miss (메모리에 있는지 없는지는 모르겠고, 최근 힌트를 적어놓은 TLB에 번역결과가 없다는 뜻)
	•	가상 주소를 물리 주소로 변환하는 정보가 TLB에 없음
•	page fault
	•	해당 가상 페이지의 내용이 초기화되지 않았거나 메모리에 없음
###### page fault 직후 Demand paging의 단계
1.	운영체제로 trap 발생
2.	사용자 레지스터와 프로세스 상태 저장 (context switching 진행)
3.	인터럽트가 페이지 폴트인지 확인
4.	참조된 페이지가 합법적인지 검사하고, 디스크 상의 위치를 결정
5.	디스크에서 빈 프레임으로 페이지를 읽기 위한 요청 실행 (swap in)
6.	대기하는 동안 CPU를 다른 사용자(프로세스)에게 할당
7.	디스크 I/O 하위 시스템에서 인터럽트 수신 (I/O 완료)
8.	다른 사용자(프로세스)의 레지스터와 상태 저장
9.	인터럽트가 디스크에서 발생했음을 확인
10. 페이지가 이제 메모리에 있음을 나타내도록 페이지 테이블 및 기타 테이블 갱신
	1. ready queue에 page fault를 야기한 process를 넣어준다
11. 이 프로세스에 다시 CPU가 할당될 때까지 대기
12. 사용자 레지스터, 프로세스 상태, 갱신된 페이지 테이블 복원 후 중단된 명령어 재시작
###### Prepaging
• 참조되기 전에 페이지를 미리 메모리에 불러옴
• 한 페이지가 참조되면, 혹시 몰라 다음 페이지도 불러옴
• 예측 능력자 없이 효과적으로 하기 어려움
• 가끔 효과적임: 순차적 읽기 예측(read-ahead)
###### Request paging과 문제점
• 사용자가 필요한 페이지를 직접 지정
• 이 방식의 문제점은?
	• 사용자가 항상 최선의 선택을 하는 것은 아님
	• 사용자가 객관적이지 않음 (필요 이상으로 과대 평가)
###### Copy on Write
부모와 자식 프로세스가 처음에는 동일한 페이지를 메모리에서 공유하도록 허용함
	• 둘 중 어느 쪽이 공유된 페이지를 수정하면, 그때 비로소 해당 페이지를 복사함
• 일반적으로, 빈 페이지는 ‘요청 시 0으로 채워지는(zero-fill-on-demand)’ 페이지 풀에서 할당됨
	• 빠른 Demand paging 처리를 위해 이 풀에는 항상 여유 프레임이 있어야 함
		• 페이지 폴트 발생 시 프레임을 해제하고 다른 처리를 동시에 하지 않도록 하기 위함
###### COW 장점
• COW는 수정된 페이지만 복사하므로 프로세스를 보다 효율적으로 생성할 수 있음
###### COW에서 페이지 할당 전 0으로 초기화 하는 이유
이전 프로세스가 사용하던 원래 data가 남아있을 수 있기 때문 (보안상 issue)
###### vfork란?
fork() 시스템 호출의 변형으로, 부모는 대기하고 자식은 부모의 copy-on-write 주소 공간을 사용
• 자식이 exec()를 호출하도록 설계되어 효율적이다.
###### Page Replacement 과정
1.	디스크에서 원하는 페이지의 위치를 찾음
2.	빈 프레임을 찾음
	•	빈 프레임이 있다면 그것을 사용
	•	빈 프레임이 없다면, 페이지 교체 알고리즘을 이용해 희생 프레임(victim frame)을 선택
		•	*희생 프레임이 수정된 상태(dirty)라면 디스크에 먼저 기록*
3.	원하는 페이지를 (새로 비워진) 프레임에 불러오고, 페이지 테이블과 프레임 테이블을 갱신
4.	예외(trap)를 발생시킨 명령어를 재시작하며 과정을 계속함
* 페이지 폴트 시 최대 2번의 페이지 전송이 일어날 수 있음 → EAT(유효 접근 시간) 증가
![[Pasted image 20250602153941.png|300]]
###### 페이지 교체 알고리즘인 FIFO에서 페이지 나이 추적하는 방법
FIFO 큐 사용 
###### Belady의 역설이란?
프레임 수를 늘리면 오히려 페이지 폴트가 증가할 수 있음
###### OPT 알고리즘이란?
•	가장 오랫동안 사용되지 않을 페이지 교체
###### LRU란?
•	과거 기록을 기반으로 함
•	가장 오래전에 사용된 페이지를 교체
###### LRU에서 Belady의 역설이 발생하지 않는 이유
 LRU는 stack 알고리즘이므로 frame 개수가 n개일 때, 메모리에 존재하는 page set은 n+1 frame의 부분집합이다
따라서 LRU와 OPT는 Belady의 역설이 없는 스택 알고리즘 사례이다.
###### LRU 구현 방법 두 가지와 교체, 접근 비용
1.	카운터 방식
	•	모든 page entry는 counter를 가짐
	•	page가 참조될 때, counter에 시간을 기록한다.
	•	교체 시 counter에 기록된 값이 가장 작은 값 선택
		•	테이블 전체 탐색 필요 (교체 시 모든 entry clock check)
		•	접근은 특정 entry clock update (페이지가 언제 접근되었는지 적어두는 과정은 O(1) 필요)
2.	스택 방식
	•	페이지 번호를 이중 연결 리스트 형태로 스택에 유지
	•	참조된 페이지는 스택 맨 위로 이동
	•	업데이트 비용이 큼, 그러나 교체 시 탐색 필요 없음
		교체 -> linked list tail 선택 (O(1))
		접근 -> update가 비싸다 (최대 6개의 포인터 변경 필요)
###### LRU Approximations
간단한 clock 알고리즘이라고 생각하자
•	기본 방식: 하드웨어 지원(reference bit) 사용
	•	초기에는 참조 비트(reference bit) = 0
	•	페이지에 접근하면 참조 비트 = 1 (최근에 접근되었다는 뜻)
	•	주기적으로 모든 reference bit을 0으로 한다
	•	참조 비트가 0인 페이지가 존재한다면, 그것 중 아무거나 교체함
		•	그러나 접근된 순서를 알 수는 없음
###### Additional-Reference Bits
•	각 페이지는 참조 비트(reference bit)와 8비트 레지스터를 가짐 (1byte를 더 두자)
	•	이 8비트 레지스터는 “참조 바이트(reference byte)”라고 불림
•	일정한 간격마다, (R-bit, R-byte)를 오른쪽으로 시프트 
•	접근시 가장 왼쪽 값을 1로 쓴다. (따라서 왼쪽이 가장 최근 history가 됨)
•	레지스터 값이 가장 작은 페이지가 LRU 페이지로 간주됨
###### Additional-Reference Bits 장단점
장점:
	•	모든 메모리 접근에 대해 오버헤드를 발생시키지 않음 (접근은 O(1))
	•	인터벌(주기) 속도를 구성할 수 있음
단점:
	•	모든 페이지 프레임을 스캔해야 하므로 여전히 비효율적일 수 있음 (교체가 O(n))
###### Second-Chance Algorithm
•	클럭 알고리즘(clock algorithm)이라고도 불림
•	일반적으로는 FIFO 기반이며, 하드웨어에서 제공하는 참조 비트를 사용
•	교체 대상 페이지의 참조 비트가:
	•	0 → 해당 페이지 교체
	•	1 →
	•	참조 비트를 0으로 설정하고 페이지는 그대로 메모리에 둠 (second-chance를 주는 것, 모두가 1이면 무한 루프를 돌 수 있기 때문)
	•	다음 페이지로 넘어가고 동일한 규칙을 적용
###### Second-Chance Algorithm 장단점
장점:
	•	오버헤드가 매우 낮음
	•	페이지 교체가 필요할 때만 작동함
단점:
	•	정확도가 높지 않음
	•	모든 참조 비트가 1이면, 알고리즘이 FIFO로 퇴화됨
###### Enhanced Clock Algorithm
•	참조 비트(reference bit)와 수정 비트(modify bit 또는 dirty bit)를 함께 사용하여 알고리즘 개선
•	(참조, 수정) 쌍을 기준으로 4가지 상태로 구분
1.	(0, 0): 최근에 사용되지 않았고 수정되지 않음 → 교체 대상 최우선
2.	(0, 1): 최근에 사용되지 않았지만 수정됨 → 좋지는 않음, 교체 전에 디스크에 기록해야 함
3.	(1, 0): 최근에 사용되었고 깨끗함 → 곧 다시 사용될 가능성 높음
4.	(1, 1): 최근에 사용되었고 수정됨 → 곧 다시 사용될 가능성 높고, 디스크에 기록 필요
•	페이지 교체가 필요할 때는 클럭 스킴을 사용하되, 네 가지 상태 중 가장 낮은 우선순위 그룹에서 교체
	•	이때 원형 큐를 여러 번 순회해야 할 수도 있음
###### Counting-Based Algorithm
•	각 페이지에 대해 지금까지의 참조 횟수 카운터를 유지
	•	흔하게 사용되지는 않음
###### Fixed Allocation
•	동등 할당(Equal allocation): 모든 프로세스에 동일한 수의 프레임을 할당
 •	비례 할당(Proportional allocation):  프로세스의 크기에 비례하여 프레임 할당
###### Priority Allocation
•	프로세스의 크기 대신 우선순위에 따라 비례 할당 방식 사용
###### Global Allocation과 장단점
•	프로세스는 시스템 전체의 프레임 중에서 교체 프레임을 선택할 수 있음
•	한 프로세스가 다른 프로세스의 프레임을 가져갈 수 있음
장점: 처리량이 높아짐
단점: 프로세스 실행 시간에 큰 변동이 생길 수 있음 (같이 사용되는 프로세스에 따라 달라지므로)

다른 프로세스가 쓰던 데이터를 빼내도 된다.
###### Local Allocation
•	각 프로세스는 자신에게 할당된 프레임 집합 내에서만 교체 프레임 선택
장점: 프로세스별로 일관된 성능 유지 가능
단점: 메모리 활용도가 떨어질 수 있음
###### 스래싱의 뜻과 스래싱이 발생하는 이유
프로세스가 페이지를 들여오고 내보내는 작업에만 몰두하게 되는 현상

•	지역성들의 전체 크기(∑ 지역성 크기)가 전체 메모리보다 클 때 발생
	•	지역 교체나 우선순위 교체를 통해 영향 완화 가능
###### WSS란?
Δ ≡ working-set window ≡ 고정된 수의 페이지 참조 (예: 10,000개의 명령어)
working set of Process P<sub>i</sub> : 가장 최근 Δ 기간 동안 참조된 페이지 수
###### WSS가 너무 크거나 작으면
•	Δ가 너무 작으면 지역성 전체를 포괄하지 못함
•	Δ가 너무 크면 여러 지역성을 포함함
•	Δ = ∞ 이면 전체 프로그램이 포함됨
###### Working set model에서 스래싱 발생 확인하는 법
D = ∑WSSi ≡ 전체 요구 프레임 수
D > m일 경우, 하나의 프로세스를 중단 또는 스왑 아웃
![[Pasted image 20250602155052.png|300]]
###### WSS보다 더 직접적인 방법
Page-Fault Frequency
###### Buddy System Allocator
•	물리적으로 연속된 페이지들로 구성된 고정 크기 세그먼트에서 메모리 할당
•	2의 거듭제곱 크기(power-of-2) 할당자를 사용해 메모리 할당
	•	요청은 2의 거듭제곱 단위로 처리됨
	•	요청 크기는 다음으로 큰 2의 거듭제곱으로 반올림됨 (ex) 27 -> 32)
	•	더 작은 크기의 할당이 필요한 경우 현재 청크(chunk)를 다음 작은 2의 거듭제곱 크기의 두 청크(버디)로 분할
		•	적절한 크기의 청크가 확보될 때까지 이 과정을 반복
![[Pasted image 20250602155251.png|300]]
###### Buddy System Allocator 장단점
•	장점: 사용되지 않는 청크를 빠르게 병합(coalesce)하여 큰 청크로 만들 수 있음
•	단점: 단편화(fragmentation) 발생 가능성 (내부 단편화)
###### Slap Allocator
•	슬랩(slab)은 하나 이상의 물리적으로 연속된 페이지로 구성됨

•	캐시(cache)는 하나 이상의 슬랩으로 구성됨
•	커널의 각 고유 데이터 구조체마다 하나의 캐시 존재

•	슬랩이 모두 사용된 객체로 꽉 차 있으면:
	•	다음 객체는 비어 있는 슬랩에서 할당됨

일정한 크기로 사용할 객체의 크기만큼 메모리를 잘라놓은 것
###### Slap Allocator 장점
•	단편화 없음
•	빠른 메모리 요청 처리 가능
