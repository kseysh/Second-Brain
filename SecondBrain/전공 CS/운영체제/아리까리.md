###### signal wait 방식의 모니터 wait 구현
```cpp
x_count++; // 현재 스레드가 x를 기다리므로 대기자 수 증가
if (sig_lock_count > 0) // 이미 누군가 x.signal()을 호출한 상태라면,
	signal(sig_lock); // signal을 기다리던 스레드 하나를 깨움
else
	signal(monitor_lock); // 그렇지 않으면 monitor_lock을 넘겨줌
wait(x_sem); // x.signal()이 호출될 때까지 대기
x_count--; // 일어나서 다 기다렸으니 나갈거라서 x_count를 감소
```
x_count++, 다음 프로세스 호출, wait(x_sem), x_count--
###### signal wait 방식의 모니터 signal 구현
```cpp
if (x_count > 0) { // 조건 변수 x를 기다리는 스레드가 있다면
	sig_lock_count++; // signal을 기다리는 스레드 수 증가
	signal(x_sem); // 기다리던 스레드 하나를 깨움
	wait(sig_lock); // signal한 스레드는 sig_lock에서 잠시 대기 (깨운 스레드가 모니터를 먼저 갖고 실행을 계속하게 하기 위함)
	sig_lock_count--; // signal 대기 스레드 수 감소
}
```
sig_lock_count++, signal(s_xem), wait(sig_lock_count), sig_lock_count--
###### Bounded-Buffer Problem에서 mutex, full, empty 세마포어의 초기 값과 역할
•	세마포어 mutex는 1로 초기화됨 (buffer 접근에 대한 mutual exclusion 보장하는 semaphore)
•	세마포어 full은 0으로 초기화됨  (n개 중에 몇 개가 사용되고 있는지)
•	세마포어 empty는 n으로 초기화됨 (n개 중에 비어있는 buffer의 수)
###### Bounded-Buffer Problem에서 생산자 프로세스 구조 (do while 안에서 wait, signal 순서)
```cpp
do {
  …
  /* next_produced에 항목을 생성 */
  …
  wait(empty); // 접근 가능한 빈 semaphore가 있는지 check
  wait(mutex); // buffer는 공유객체이므로 잠그고 들어감
  …
  /* next_produced를 버퍼에 추가 */
  …
  signal(mutex);  
  signal(full);  
} while (true);
```
###### Contiguous Memory Allocation에서 user process를 관리하기 위한 base, limit 레지스터 관리
•	사용자 프로세스를 서로 또는 OS 코드와 데이터로부터 보호하기 위해 relocation register 사용
	• base register는 가장 작은 물리 주소 값을 가짐
	• 리미트 레지스터는 logical address의 범위를 가짐
	• MMU는 논리 주소를 실행 중에 동적으로 매핑함
![[Pasted image 20250520170458.png|300]]
###### Contiguous Allocation 단점
- **단편화(Fragmentation)**
• 외부 단편화(External fragmentation)
	• *요청을 만족시킬 수 있는 전체 메모리 공간은 있으나 연속되지 않아서 사용할 수 없음*
• 내부 단편화(Internal fragmentation)
	• 할당된 메모리가 요청보다 조금 더 클 수 있으며, 이 크기 차이는 파티션 내부에서 사용되지 않아서 사용할 수 없음
- **50% 규칙**
• First-fit 분석 결과, N개의 블록이 할당되면 절반의 블록이 단편화로 손실됨
	• 1/3 정도가 사용 불가능할 수 있음
###### segmentation이란?
프로세스의 주소 공간을 논리적인 단위인 segment로 나누는 메모리 관리 기법
• 각 세그먼트에 대해 개별적인 base, limit register 쌍을 사용하며, two protection bits(읽기 및 쓰기)도 추가
###### segment table에서 저장하는 값
• 세그먼트 테이블은 이차원 물리 주소를 매핑함
	• base - 세그먼트가 메모리 내에 위치하는 시작 물리 주소
	• limit - 세그먼트의 길이
###### STBR, STLR
• 세그먼트 테이블 베이스 레지스터(STBR): 세그먼트 테이블의 물리 메모리 내 위치(시작 주소)를 가리킴
• 세그먼트 테이블 길이 레지스터(STLR): 세그먼트 테이블에 포함된 세그먼트 개수 (즉, segment number의 유효 범위)
	• segment number는 STLR보다 작을 때 유효함
###### segmentation 방식에서 physical address를 얻는 방법
1. STBR에서 segment table의 physical memory 내 위치를 찾는다
2. segment number (s)가 STLR보다 작은지 검사
	- 그렇지 않으면 trap 발생
3. segment number를 이용해 segment table에서 base와 limit 값을 가져옴
4. offset (d)이 limit보다 작은지 검사
	- 그렇지 않으면 trap 발생
5. base + offset을 계산해 physical address 구함
###### Paging에서 작은 page size가 항상 좋은가?
작은 페이지 크기를 사용하면 같은 크기의 주소 공간을 더 많은 페이지로 나눠야 함.
•	이로 인해 페이지 테이블 엔트리 수가 증가하고, 전체 페이지 테이블의 크기도 커짐.
•	페이지 테이블이 너무 커지면 메모리 공간을 많이 차지하고, TLB 미스 시 페이지 테이블 접근 시간이 증가
###### ASID가 필요한 이유
• 일부 TLB는 address-space identifiers(ASID)를 각 항목에 저장 (어떤 process 정보인지)

ASID가 없다면, 다른 프로세스가 실행될 때, 가상 주소 공간도 바뀌므로 기존 TLB 항목이 잘못된 것이 될 수 있어 컨텍스트 스위치마다 TLB를 비워야 하기 때문에 프로세스를 고유하게 식별하여 주소공간을 보호할 수 있도록 한다.
###### 계층적 페이지 테이블이 필요한 이유
단일 프로세스가 너무 많은 페이지 테이블을 관리해야 하므로 이를 계층적으로 분해하여 공간을 절약하기 위함
###### Demand paging이란
페이지가 실제로 필요할 때만 메모리에 로딩하는 페이징 기법 (시점에 관한 개념)
###### Lazy Swapper
•	Lazy Swapper: 실제로 필요한 페이지만 메모리에 적재하는 방식 (데이터의 양에 대한 개념)
	•	페이지를 다루는 swapper는 pager라고 함
###### page fault 직후 Demand paging의 단계
1.	운영체제로 trap 발생
2.	사용자 레지스터와 프로세스 상태 저장 (context switching 진행)
3.	인터럽트가 페이지 폴트인지 확인
4.	참조된 페이지가 합법적인지 검사하고, 디스크 상의 위치를 결정
5.	디스크에서 빈 프레임으로 페이지를 읽기 위한 요청 실행 (swap in)
6.	대기하는 동안 CPU를 다른 사용자(프로세스)에게 할당
7.	디스크 I/O 하위 시스템에서 인터럽트 수신 (I/O 완료)
8.	다른 사용자(프로세스)의 레지스터와 상태 저장
9.	인터럽트가 디스크에서 발생했음을 확인
10. 페이지가 이제 메모리에 있음을 나타내도록 페이지 테이블 및 기타 테이블 갱신
	1. ready queue에 page fault를 야기한 process를 넣어준다
11. 이 프로세스에 다시 CPU가 할당될 때까지 대기
12. 사용자 레지스터, 프로세스 상태, 갱신된 페이지 테이블 복원 후 중단된 명령어 재시작
###### Page Replacement 과정
1.	디스크에서 원하는 페이지의 위치를 찾음
2.	빈 프레임을 찾음
	•	빈 프레임이 있다면 그것을 사용
	•	빈 프레임이 없다면, 페이지 교체 알고리즘을 이용해 희생 프레임(victim frame)을 선택
		•	*희생 프레임이 수정된 상태(dirty)라면 디스크에 먼저 기록*
3.	원하는 페이지를 (새로 비워진) 프레임에 불러오고, 페이지 테이블과 프레임 테이블을 갱신
4.	예외(trap)를 발생시킨 명령어를 재시작하며 과정을 계속함
* 페이지 폴트 시 최대 2번의 페이지 전송이 일어날 수 있음 → EAT(유효 접근 시간) 증가
![[Pasted image 20250602153941.png|300]]
#### one cycle
###### 페이지 교체 알고리즘인 FIFO에서 페이지 나이 추적하는 방법
FIFO 큐 사용 
###### Belady의 역설이란?
프레임 수를 늘려도 오히려 페이지 폴트가 증가할 수 있음
###### OPT 알고리즘이란?
•	가장 오랫동안 사용되지 않을 페이지 교체
###### LRU란?
•	과거 기록을 기반으로 함
•	가장 오래전에 사용된 페이지를 교체
###### LRU에서 Belady의 역설이 발생하지 않는 이유
 LRU는 stack 알고리즘이므로 frame 개수가 n개일 때, 메모리에 존재하는 page set은 n+1 frame의 부분집합이다
따라서 LRU와 OPT는 Belady의 역설이 없는 스택 알고리즘 사례이다.
###### LRU 구현 방법 두 가지와 교체, 접근 비용
1.	카운터 방식
	•	모든 page entry는 counter를 가짐
	•	page가 참조될 때, counter에 시간을 기록한다.
	•	교체 시 counter에 기록된 값이 가장 작은 값 선택
		•	테이블 전체 탐색 필요 (교체 시 모든 entry clock check)
		•	접근은 특정 entry clock update (페이지가 언제 접근되었는지 적어두는 과정은 O(1) 필요)
2.	스택 방식
	•	페이지 번호를 이중 연결 리스트 형태로 스택에 유지
	•	참조된 페이지는 스택 맨 위로 이동
	•	업데이트 비용이 큼, 그러나 교체 시 탐색 필요 없음
		교체 -> linked list tail 선택 (O(1))
		접근 -> update가 비싸다 (최대 6개의 포인터 변경 필요)
###### LRU Approximations
간단한 clock 알고리즘이라고 생각하자
•	기본 방식: 하드웨어 지원(reference bit) 사용
	•	초기에는 참조 비트(reference bit) = 0
	•	페이지에 접근하면 참조 비트 = 1 (최근에 접근되었다는 뜻)
	•	주기적으로 모든 reference bit을 0으로 한다
	•	참조 비트가 0인 페이지가 존재한다면, 그것 중 아무거나 교체함
		•	그러나 접근된 순서를 알 수는 없음
###### Additional-Reference Bits
•	각 페이지는 참조 비트(reference bit)와 8비트 레지스터를 가짐 (1byte를 더 두자)
	•	이 8비트 레지스터는 “참조 바이트(reference byte)”라고 불림
•	일정한 간격마다, (R-bit, R-byte)를 오른쪽으로 시프트 
•	접근시 가장 왼쪽 값을 1로 쓴다. (따라서 왼쪽이 가장 최근 history가 됨)
•	레지스터 값이 가장 작은 페이지가 LRU 페이지로 간주됨
###### Additional-Reference Bits 장단점
장점:
	•	모든 메모리 접근에 대해 오버헤드를 발생시키지 않음 (접근은 O(1))
	•	인터벌(주기) 속도를 구성할 수 있음
단점:
	•	모든 페이지 프레임을 스캔해야 하므로 여전히 비효율적일 수 있음 (교체가 O(n))
###### Second-Chance Algorithm
•	클럭 알고리즘(clock algorithm)이라고도 불림
•	일반적으로는 FIFO 기반이며, 하드웨어에서 제공하는 참조 비트를 사용
•	교체 대상 페이지의 참조 비트가:
	•	0 → 해당 페이지 교체
	•	1 →
	•	참조 비트를 0으로 설정하고 페이지는 그대로 메모리에 둠 (second-chance를 주는 것, 모두가 1이면 무한 루프를 돌 수 있기 때문)
	•	다음 페이지로 넘어가고 동일한 규칙을 적용
###### Second-Chance Algorithm 장단점
장점:
	•	오버헤드가 매우 낮음
	•	페이지 교체가 필요할 때만 작동함
단점:
	•	정확도가 높지 않음
	•	모든 참조 비트가 1이면, 알고리즘이 FIFO로 퇴화됨
###### Enhanced Clock Algorithm
•	참조 비트(reference bit)와 수정 비트(modify bit 또는 dirty bit)를 함께 사용하여 알고리즘 개선
•	(참조, 수정) 쌍을 기준으로 4가지 상태로 구분
1.	(0, 0): 최근에 사용되지 않았고 수정되지 않음 → 교체 대상 최우선
2.	(0, 1): 최근에 사용되지 않았지만 수정됨 → 좋지는 않음, 교체 전에 디스크에 기록해야 함
3.	(1, 0): 최근에 사용되었고 깨끗함 → 곧 다시 사용될 가능성 높음
4.	(1, 1): 최근에 사용되었고 수정됨 → 곧 다시 사용될 가능성 높고, 디스크에 기록 필요
•	페이지 교체가 필요할 때는 클럭 스킴을 사용하되, 네 가지 상태 중 가장 낮은 우선순위 그룹에서 교체
	•	이때 원형 큐를 여러 번 순회해야 할 수도 있음
###### Counting-Based Algorithm
•	각 페이지에 대해 지금까지의 참조 횟수 카운터를 유지
	•	흔하게 사용되지는 않음
###### Fixed Allocation
•	동등 할당(Equal allocation): 모든 프로세스에 동일한 수의 프레임을 할당
 •	비례 할당(Proportional allocation):  프로세스의 크기에 비례하여 프레임 할당
###### Priority Allocation
•	프로세스의 크기 대신 우선순위에 따라 비례 할당 방식 사용
###### Global Allocation과 장단점
•	프로세스는 시스템 전체의 프레임 중에서 교체 프레임을 선택할 수 있음
•	한 프로세스가 다른 프로세스의 프레임을 가져갈 수 있음
장점: 처리량이 높아짐
단점: 프로세스 실행 시간에 큰 변동이 생길 수 있음 (같이 사용되는 프로세스에 따라 달라지므로)

다른 프로세스가 쓰던 데이터를 빼내도 된다.
###### Local Allocation
•	각 프로세스는 자신에게 할당된 프레임 집합 내에서만 교체 프레임 선택
장점: 프로세스별로 일관된 성능 유지 가능
단점: 메모리 활용도가 떨어질 수 있음
###### 스래싱의 뜻과 스래싱이 발생하는 이유
프로세스가 페이지를 들여오고 내보내는 작업에만 몰두하게 되는 현상

•	지역성들의 전체 크기(∑ 지역성 크기)가 전체 메모리보다 클 때 발생
	•	지역 교체나 우선순위 교체를 통해 영향 완화 가능
###### WSS란?
Δ ≡ working-set window ≡ 고정된 수의 페이지 참조 (예: 10,000개의 명령어)
working set of Process P<sub>i</sub> : 가장 최근 Δ 기간 동안 참조된 페이지 수
###### WSS가 너무 크거나 작으면
•	Δ가 너무 작으면 지역성 전체를 포괄하지 못함
•	Δ가 너무 크면 여러 지역성을 포함함
•	Δ = ∞ 이면 전체 프로그램이 포함됨
###### Working set model에서 스래싱 발생 확인하는 법
D = ∑WSSi ≡ 전체 요구 프레임 수
D > m일 경우, 하나의 프로세스를 중단 또는 스왑 아웃
![[Pasted image 20250602155052.png|300]]
###### WSS보다 더 직접적인 방법
Page-Fault Frequency
###### Buddy System Allocator
•	물리적으로 연속된 페이지들로 구성된 고정 크기 세그먼트에서 메모리 할당
•	2의 거듭제곱 크기(power-of-2) 할당자를 사용해 메모리 할당
	•	요청은 2의 거듭제곱 단위로 처리됨
	•	요청 크기는 다음으로 큰 2의 거듭제곱으로 반올림됨 (ex) 27 -> 32)
	•	더 작은 크기의 할당이 필요한 경우 현재 청크(chunk)를 다음 작은 2의 거듭제곱 크기의 두 청크(버디)로 분할
		•	적절한 크기의 청크가 확보될 때까지 이 과정을 반복
![[Pasted image 20250602155251.png|300]]
###### Buddy System Allocator 장단점
•	장점: 사용되지 않는 청크를 빠르게 병합(coalesce)하여 큰 청크로 만들 수 있음
•	단점: 단편화(fragmentation) 발생 가능성 (내부 단편화)
###### Slap Allocator
•	슬랩(slab)은 하나 이상의 물리적으로 연속된 페이지로 구성됨
•	캐시(cache)는 하나 이상의 슬랩으로 구성됨
•	커널의 각 고유 데이터 구조체마다 하나의 캐시 존재
	•	각 캐시는 객체(object)로 채워짐 → 해당 데이터 구조체의 실체(instantiation)
•	캐시가 생성되면, 객체는 사용 가능 상태(free)로 표시되어 있음
•	구조체가 저장되면, 해당 객체는 사용 중(used)으로 표시
•	슬랩이 모두 사용된 객체로 꽉 차 있으면:
	•	다음 객체는 비어 있는 슬랩에서 할당됨
•	비어 있는 슬랩이 없으면, 새 슬랩이 할당됨
###### Slap Allocator 장점
•	단편화 없음
•	빠른 메모리 요청 처리 가능




