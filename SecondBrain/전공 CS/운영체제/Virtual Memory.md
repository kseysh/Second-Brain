## MMU 종류
- Contiguous Allocation
	- MMU: base register + limit register
- segmentation
	- MMU: segment table에서 base와 limit
- paging
	- MMU: page table에서 frame number + offset
- virtual memory
	- MMU: page table에서 frame number + offset
## 가상 메모리의 동기
•	코드와 데이터를 실행하려면 메모리에 있어야 하지만, 전체 프로그램이 항상 사용되는 것은 아니다
	•	오류 처리 코드, 특이한 루틴, 큰 데이터 구조 등은 드물게 사용됨
•	partially-loaded program을 실행할 수 있다면 좋음
	•	프로그램이 물리적 메모리 용량의 제약을 받지 않게 됨
	•	실행 중인 각 프로그램이 적은 메모리를 차지함 → 동시에 더 많은 프로그램 실행 가능
		•	응답 시간이나 반환 시간의 증가 없이 CPU 활용률과 처리량이 향상됨
	•	프로그램을 메모리에 적재하거나 교체(swap)하는 데 필요한 I/O가 줄어듦(필요한 것만 가져다 두기 때문) → 사용자 프로그램이 더 빠르게 실행됨
## 가상 메모리
•	사용자 논리 메모리와 물리 메모리의 분리
	•	실행을 위해 프로그램의 일부만 메모리에 존재하면 됨
	•	논리 주소 공간이 물리 주소 공간보다 훨씬 클 수 있음
	•	여러 프로세스가 주소 공간을 공유 가능 (프로그램마다 주소에 똑같은 규칙을 적용해도 되기 때문)
		•	프로세스 생성이 더 효율적임
		•	더 많은 프로그램을 동시에 실행 가능
		•	프로세스를 적재하거나 교체하는 데 필요한 I/O 감소
•	가상 주소 공간: 프로세스가 메모리에 저장된 방식에 대한 논리적 관점
	•	일반적으로 주소 0부터 시작해서 연속된 주소를 가짐
	•	물리 메모리는 페이지 프레임 단위로 구성됨
	•	MMU가 논리 주소를 물리 주소로 매핑해야 함
•	가상 메모리는 다음 방식으로 구현 가능
	•	Demand Paging
	•	Demand Segmentation
•	가상 메모리는 물리 메모리보다 크다
![[Pasted image 20250529165423.png|200]]

•	가상 주소 공간
	•	코드에서 스택까지 0에서 최대까지의 연속된 메모리 공간
	•	스택과 힙 사이에 사용되지 않는 주소 공간 존재
	•	시스템 라이브러리는 가상 주소 공간에 매핑하여 공유됨
	•	페이지를 읽기-쓰기 형태로 가상 주소 공간에 매핑하여 공유 메모리 구현 가능
	•	fork() 시 페이지 공유를 통해 프로세스 생성 속도 향상
•	가상 메모리를 이용한 공유 라이브러리
![[Pasted image 20250529165445.png|200]]
## Demand Paging
paging과 virtual memory가 다른 점인, 일부 데이터만 올리기 위한, 기본적인 방법
## Demand Paging의 기본 개념
![[Pasted image 20250529165803.png|200]]
•	필요한 페이지만 메모리에 불러옴
	•	불필요한 I/O 없음 → 더 적은 I/O
	•	더 적은 메모리 사용
	•	응답 시간 단축 (거대한 데이터를 가져오지 않아도 되니까)
	•	더 많은 사용자 수용 (메모리 공간이 줄어드니까)
•	스와핑을 사용하는 페이징 시스템과 유사함
	•	스와핑은 전부 빼고 전부 가져왔는데, 이건 페이지 단위로 빼고 가져온다.
•	페이지가 필요함 → 참조 발생 (해당 page에 접근할 때, 가져오면 된다.)
	•	잘못된 참조 → 중단 (얘가 사용하는 메모리 공간인지 체크)
	•	메모리에 없으면 → 메모리로 불러오기 (유효한 메모리라면, 그 페이지만 메모리로 가져온다)
•	Lazy Swapper: 실제로 필요한 페이지만 메모리에 적재
	•	페이지를 다루는 swapper는 pager라고 함
•	Demand Paging을 구현하려면 MMU에 새로운 기능이 필요
•	필요한 페이지가 이미 메모리에 있다면
	•	일반 페이징과 차이 없음
•	필요한 페이지가 메모리에 없다면
	•	저장 장치에서 해당 페이지를 감지하고 불러와야 함
		•	프로그램 동작을 바꾸지 않아야 함
		•	프로그래머가 코드를 변경할 필요 없음
## Valid-Invalid Bit
•	각 페이지 테이블 항목마다 유효-무효 비트를 둔다
	•	v → 메모리에 존재 (유효)
	•	i → 메모리에 없음 (무효)
•	처음에는 모든 항목의 비트를 i로 설정
•	예시: 페이지 테이블 스냅샷
![[Pasted image 20250529170510.png|150]]
•	MMU가 주소 변환 시 해당 비트가 i이면 → 페이지 폴트 발생
## Page Table Example
![[Pasted image 20250529170535.png|300]]
logical memory에는 다 메모리에 적재된 것으로 보이지만, 실제로 physical memory에는 필요한 메모리인 A,C,F만 적재되어 있어 page table에 0,2,5만 매핑되고 v로 표시되어 있다.
## Page Fault
•	페이지 참조가 발생하면, 해당 페이지에 대한 첫 참조 시 운영체제로 trap 발생 (page fault)
1.	운영체제가 다른 테이블을 확인함
	•	잘못된 참조 → 중단
	•	단지 메모리에 없을 경우 다음 step
2.	빈 프레임 찾기
3.	disk operation을 통해 해당 페이지를 프레임에 스와핑 (swap in)
4.	페이지가 메모리에 있다고 테이블 갱신, valid-invalid bit를 v로 세팅
5.	페이지 폴트를 유발한 명령어를 재시작
큰 흐름은 이렇게 됨

![[Pasted image 20250529171418.png|400]]
## Demand Paging의 특징
•	*pure demand paging*: 처음에는 아무 페이지도 메모리에 없이 프로세스 시작
	•	OS는 프로세스의 첫 명령어 위치로  instruction pointer를 설정 → 메모리에 없음 → 페이지 폴트
	•	다른 모든 페이지들도 처음 접근 시 페이지 폴트
•	실제로는 하나의 명령어가 여러 페이지를 접근할 수도 있음 → multiple page faults
	•	예시: 메모리에서 두 수를 더하고 결과를 저장하는 명령어의 fetch/decode 과정
	•	지역성(locality of reference) 때문에 이러한 비용이 완화됨
•	Demand Paging을 위한 하드웨어 지원 필요
	•	유효/무효 비트를 갖는 페이지 테이블 (MMU)
	•	secondary memory (swap device) - backing store
	•	Instruction restart
## 명령어 재시작
•	page fault가 명령어 중간에서 발생할 수 있기 때문에 프로세스를 계속 실행시키는 것은 매우 까다롭다
	•	사용자 프로세스는 페이지 폴트가 발생한 사실조차 몰라야 함
	•	해당 명령어를 건너뛰는 것은 불가능
		•	프로세스에 투명하지 않음
	•	명령어는 처음부터 다시 실행되어야 함
		•	자동 증가/감소 같은 명령어는 어떻게 처리할까?
	•	명령어 재시작을 위한 하드웨어 지원이 필요함
## TLB 오류 vs. 페이지 폴트
•	메모리 관련 오류는 두 가지가 있다:
	•	TLB 오류 (Miss) (메모리에 있는지 없는지는 모르겠고, 최근 힌트를 적어놓은 TLB에 번역결과가 없다는 뜻)
		•	가상 주소를 물리 주소로 변환하는 정보가 TLB에 없음
	•	페이지 폴트
		•	해당 가상 페이지의 내용이 초기화되지 않았거나 메모리에 없음
•	중요한 사실
	•	*모든 페이지 폴트는 TLB 오류가 선행된다*
		•	가상 페이지의 내용이 메모리에 없다면, 해당 주소에 대한 변환 정보가 존재할 수 없음
	•	모든 TLB 오류가 페이지 폴트를 유발하지는 않는다
		•	페이지가 이미 메모리에 있고, 변환 정보가 페이지 테이블에 존재한다면, 페이지 폴트 없이 TLB 오류만 처리 가능
## Demand paging의 단계
1.	운영체제로 trap 발생
2.	사용자 레지스터와 프로세스 상태 저장 (context switching 진행)
3.	인터럽트가 페이지 폴트인지 확인
4.	참조된 페이지가 합법적인지 검사하고, 디스크 상의 위치를 결정
5.	디스크에서 빈 프레임으로 페이지를 읽기 위한 요청 실행
6.	대기하는 동안 CPU를 다른 사용자(프로세스)에게 할당
7.	디스크 I/O 하위 시스템에서 인터럽트 수신 (I/O 완료)
8.	다른 사용자(프로세스)의 레지스터와 상태 저장
9.	인터럽트가 디스크에서 발생했음을 확인
10. 페이지가 이제 메모리에 있음을 나타내도록 페이지 테이블 및 기타 테이블 갱신
	1. ready queue에 page fault를 야기한 process를 넣어준다
11. 이 프로세스에 다시 CPU가 할당될 때까지 대기
12. 사용자 레지스터, 프로세스 상태, 갱신된 페이지 테이블 복원 후 중단된 명령어 재시작
## 요청 페이징 성능
•	세 가지 주요 작업
	•	인터럽트 처리: 신중한 코딩 시 수백 개의 명령어로 처리 가능
	•	페이지 읽기 및 희생 페이지 쓰기 (스왑): 많은 시간 소요
	•	프로세스 재시작: 다시 소량의 시간 소요
•	페이지 폴트율 p: 0 ≤ p ≤ 1 (메모리 접근당 page fault 횟수)
	•	p = 0: 페이지 폴트 없음
	•	p = 1: 모든 접근이 페이지 폴트 발생
•	유효 접근 시간 (Effective Access Time, EAT)
	•	EAT = (1 - p) * memory access time + p * (page fault overhead + swap page out + swap page in)
수식을 막 외울 필요는 X
#### 예시
•	메모리 접근 시간 = 100ns
•	평균 페이지 폴트 처리 시간 = 8ms (페이지 폴트 오버헤드 + 스왑 시간)
•	EAT = (1 - p) * 100 + p * 8,000,000 = 100 + p * 7,999,900
•	만약 1,000번 중 1번이 페이지 폴트라면 (p = 0.001)
	•	EAT = 8.1μs (평균 80배가 커져버림)
•	성능 저하를 10% 미만으로 제한하고 싶다면 (EAT < 110ns)
	•	110 > 100 + p * 7,999,900
	•	10 > p * 7,999,900
	•	p < 0.00000125
	→ 약 80만 번의 메모리 접근당 1번만 페이지 폴트가 발생해야 함
그냥 page fault는 이정도로 영향이 크다 정도로 생각하면 된다.
# Page selection
수요 페이징의 핵심 이슈
• 페이지 선택
	• 언제 어떤 페이지를 메모리에 가져올 것인가?
• 페이지 교체
	• 어떤 페이지를 언제 버릴 것인가?
• 페이지 프레임 할당
	• 각 프로세스에 몇 개의 프레임을 할당할 것인가?
## 페이지 선택 (1)
### 페이지 선택 정책
• Demand paging
	• 프로세스를 시작할 때 아무 페이지도 로드하지 않음
	• 해당 페이지에 대한 페이지 폴트가 발생하면 그때 로드
		• 반드시 메모리에 있어야 할 때까지 기다림
	• 거의 모든 페이징 시스템이 이 방식 사용
• 사전 페이징(Prepaging)
	• 참조되기 전에 페이지를 미리 메모리에 불러옴
	• 한 페이지가 참조되면, 혹시 몰라 다음 페이지도 불러옴
	• 예측 능력자 없이 효과적으로 하기 어려움
	• 가끔 효과적임: 순차적 읽기 예측(read-ahead)
• 요청 페이징(Request paging)
	• 사용자가 필요한 페이지를 직접 지정
	• 이 방식의 문제점은?
		• 사용자가 항상 최선의 선택을 하는 것은 아님
		• 사용자가 객관적이지 않음 (필요 이상으로 과대 평가)
### Copy-on-Write
• Copy-on-Write(COW)는 부모와 자식 프로세스가 처음에는 동일한 페이지를 메모리에서 공유하도록 허용함
	• 둘 중 어느 쪽이 공유된 페이지를 수정하면, 그때 비로소 해당 페이지를 복사함
• COW는 수정된 페이지만 복사하므로 프로세스를 보다 효율적으로 생성할 수 있음
• 일반적으로, 빈 페이지는 ‘요청 시 0으로 채워지는(zero-fill-on-demand)’ 페이지 풀에서 할당됨 (COW에서 주는 페이지가 zero-fill-on-demand page임)
	• 빠른 수요 페이징 처리를 위해 이 풀에는 항상 여유 프레임이 있어야 함
		• 페이지 폴트 발생 시 프레임을 해제하고 다른 처리를 동시에 하지 않도록 하기 위함
	• 페이지를 할당하기 전에 왜 0으로 초기화하는가?
		이전 프로세스가 사용하던 원래 data가 남아있을 수 있기 때문 (보안상 issue)
• vfork()는 fork() 시스템 호출의 변형으로, 부모는 대기하고 자식은 부모의 copy-on-write 주소 공간을 사용
	• 자식이 exec()를 호출하도록 설계됨 (copy-on-write을 위해 관리하는 것을 많이 덜어내도 된다)
	• 매우 효율적임

• Copy-on-Write 예시: 프로세스 1이 페이지 C를 수정하기 전
![[Pasted image 20250602121921.png|300]]
• Copy-on-Write 예시: 프로세스 1이 페이지 C를 수정한 후
![[Pasted image 20250602121935.png|300]]
공유된 페이지를 수정하면 그제서야 해당 페이지를 복사해서 사용하는 예제
## Page Replacement
페이지 교체 (Page Replacement): 메모리에 있지만 실제로 사용되지 않는 페이지를 찾아 디스크로 내보냄
1.	디스크에서 원하는 페이지의 위치를 찾음
2.	빈 프레임을 찾음
	•	빈 프레임이 있다면 그것을 사용
	•	빈 프레임이 없다면, 페이지 교체 알고리즘을 이용해 희생 프레임(victim frame)을 선택
		•	희생 프레임이 수정된 상태(dirty)라면 디스크에 먼저 기록
3.	원하는 페이지를 (새로 비워진) 프레임에 불러오고, 페이지 테이블과 프레임 테이블을 갱신
4.	예외(trap)를 발생시킨 명령어를 재시작하며 과정을 계속함
* 페이지 폴트 시 최대 2번의 페이지 전송이 일어날 수 있음 → EAT(유효 접근 시간) 증가
![[Pasted image 20250602153941.png|300]]
## 페이지 교체 알고리즘
•	목표: 첫 접근과 재접근 시 페이지 폴트율을 최소화
•	평가 방법: 특정 메모리 접근 문자열(reference string)에 대해 알고리즘을 실행하고 폴트 수 계산
	•	문자열은 페이지 번호만 포함 (전체 주소 아님)
	•	동일 페이지 반복 접근은 폴트를 발생시키지 않음
	•	결과는 사용 가능한 프레임 수에 따라 달라짐
•	예시 reference string: 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1

•	Random: 아무 페이지나 무작위로 선택
	•	의외로 잘 동작함
•	FIFO: 가장 오래된 페이지를 제거
	•	공정함을 추구, 모든 페이지에 동일한 거주 시간 부여
•	Optimal (OPT): 가장 오랫동안 앞으로 사용되지 않을 페이지 제거
	•	미래 예측이 필요하므로 실현 불가하지만 비교 기준으로 좋음
•	LRU (Least Recently Used): 가장 오랫동안 사용되지 않은 페이지 제거
	•	과거 사용 이력을 바탕으로 미래를 예측
	•	지역성(locality)이 있는 경우 OPT와 비슷한 성능
## FIFO 알고리즘 
•	Reference string: 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1
•	프레임 수: 3개 (프로세스당 최대 3개의 페이지 메모리에 존재 가능)
![[Pasted image 20250602154110.png|300]]
•	페이지의 나이를 어떻게 추적할까?
	•	FIFO 큐 사용 
#### Belady의 역설 (Belady’s Anomaly)
•	프레임 수를 늘리면 오히려 페이지 폴트가 증가할 수 있음
•	예: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5
![[Pasted image 20250602154141.png|300]]
## OPT (Optimal) 알고리즘
•	가장 오랫동안 사용되지 않을 페이지 교체
•	알고리즘의 성능 측정용 기준
•	Reference string: 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1
![[Pasted image 20250602154205.png|300]]
## LRU (가장 오래전에 사용된 페이지 교체)
•	과거 기록을 기반으로 함
•	가장 오래전에 사용된 페이지를 교체
•	Reference string: 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1
![[Pasted image 20250602154228.png|300]]
•	일반적으로 좋은 알고리즘이며 자주 사용됨
스택 알고리즘 (Stack Algorithm)
	•	프레임 수 n일 때 메모리에 존재하는 페이지 집합은, n+1 프레임에서의 집합의 부분집합
•	LRU와 OPT는 Belady의 역설이 없는 스택 알고리즘 사례
•	하지만 구현은 어려움

#### 구현 방법
1.	카운터 방식
	•	각 페이지 항목에 카운터 부착
	•	참조 시 시스템 시계(clock)를 기록
	•	교체 시 가장 작은 값 선택
		•	테이블 전체 탐색 필요
2.	스택 방식
	•	페이지 번호를 이중 연결 리스트 형태로 스택에 유지
	•	참조된 페이지는 스택 맨 위로 이동
	•	최대 6개의 포인터 변경 필요
	•	업데이트 비용이 큼, 그러나 교체 시 탐색 필요 없음
#### stack implementation example
![[Pasted image 20250602154355.png|200]]
## LRU 근사 알고리즘 (LRU Approximations)
•	기본 방식: 하드웨어 지원(reference bit) 사용
	•	초기에는 참조 비트(reference bit) = 0
	•	페이지에 접근하면 참조 비트 = 1
	•	참조 비트가 0인 페이지가 존재한다면, 그것 중 아무거나 교체함
		•	그러나 접근된 순서를 알 수는 없음

• Additional-Reference Bits Algorithm
• Second-Chance Algorithm (Clock Algorithm)
• Enhanced Clock Algorithm
• Counting-Based Algorithm
## LRU 근사 기법: 추가 참조 비트 (Additional-Reference Bits)
•	각 페이지는 참조 비트(reference bit)와 8비트 레지스터를 가짐
	•	이 8비트 레지스터는 “참조 바이트(reference byte)”라고 불림
•	일정한 간격마다, (R-bit, R-byte)를 오른쪽으로 시프트
•	레지스터 값이 가장 작은 페이지가 LRU 페이지로 간주됨
장점:
	•	모든 메모리 접근에 대해 오버헤드를 발생시키지 않음
	•	인터벌(주기) 속도를 구성할 수 있음
단점:
	•	모든 페이지 프레임을 스캔해야 하므로 여전히 비효율적일 수 있음
	•	예: 4GB 메모리, 4KB 페이지 → 100만 개의 페이지 프레임
## LRU 근사 기법: 세컨드 찬스 알고리즘 (Second-Chance Algorithm)
•	클럭 알고리즘(clock algorithm)이라고도 불림
•	일반적으로는 FIFO 기반이며, 하드웨어에서 제공하는 참조 비트를 사용
•	교체 대상 페이지의 참조 비트가:
	•	0이면 → 해당 페이지 교체
	•	1이면 →
	•	참조 비트를 0으로 설정하고 페이지는 그대로 메모리에 둠
	•	다음 페이지로 넘어가고 동일한 규칙을 적용
장점:
	•	오버헤드가 매우 낮음
	•	페이지 교체가 필요할 때만 작동함
단점:
	•	정확도가 높지 않음
	•	모든 참조 비트가 1이면, 알고리즘이 FIFO로 퇴화됨
## LRU 근사 기법: 향상된 클럭 알고리즘 (Enhanced Clock Algorithm)
•	참조 비트(reference bit)와 수정 비트(modify bit 또는 dirty bit)를 함께 사용하여 알고리즘 개선
•	(참조, 수정) 쌍을 기준으로 4가지 상태로 구분
1.	(0, 0): 최근에 사용되지 않았고 수정되지 않음 → 교체 대상 최우선
2.	(0, 1): 최근에 사용되지 않았지만 수정됨 → 좋지는 않음, 교체 전에 디스크에 기록해야 함
3.	(1, 0): 최근에 사용되었고 깨끗함 → 곧 다시 사용될 가능성 높음
4.	(1, 1): 최근에 사용되었고 수정됨 → 곧 다시 사용될 가능성 높고, 디스크에 기록 필요
•	페이지 교체가 필요할 때는 클럭 스킴을 사용하되, 네 가지 상태 중 가장 낮은 우선순위 그룹에서 교체
	•	이때 원형 큐를 여러 번 순회해야 할 수도 있음
## LRU 근사 기법: 카운트 기반 알고리즘 (Counting-Based Algorithm)
•	각 페이지에 대해 지금까지의 참조 횟수 카운터를 유지
	•	흔하게 사용되지는 않음
알고리즘 예시:
	•	LFU (Least Frequently Used): 참조 횟수가 가장 적은 페이지를 교체
	•	MFU (Most Frequently Used): 가장 적게 참조된 페이지는 방금 메모리에 올라왔을 가능성이 높고, 아직 사용되지 않았을 수도 있음이라는 가정에 기반하여, 참조 횟수가 가장 많은 페이지를 교체하지 않음
# 페이지 프레임 할당 
•	각 프로세스는 최소한의 프레임 수가 필요함
•	최대 프레임 수는 시스템의 전체 프레임 수
•	그렇다면 각 프로세스에 몇 개의 프레임을 할당해야 할까?
•	두 가지 주요 할당 방식
	•	고정 할당(Fixed allocation) vs. 우선순위 할당(Priority allocation)
•	다양한 기준으로 나누기도 함
	•	전역 할당(Global allocation) vs. 지역 할당(Local allocation)
### 고정 할당 (Fixed Allocation)
•	동등 할당(Equal allocation): 모든 프로세스에 동일한 수의 프레임을 할당
 •	비례 할당(Proportional allocation):  프로세스의 크기에 비례하여 프레임 할당
### 우선순위 할당 (Priority Allocation)
•	프로세스의 크기 대신 우선순위에 따라 비례 할당 방식 사용
### 전역 할당 (Global Allocation)
•	프로세스는 시스템 전체의 프레임 중에서 교체 프레임을 선택할 수 있음
•	한 프로세스가 다른 프로세스의 프레임을 가져갈 수 있음
•	이 경우, 프로세스 실행 시간에 큰 변동이 생길 수 있음
•	하지만 처리량이 높아지므로 일반적으로 더 많이 사용됨
### 지역 할당 (Local Allocation)
•	각 프로세스는 자신에게 할당된 프레임 집합 내에서만 교체 프레임 선택
•	프로세스별로 일관된 성능 유지 가능
•	그러나 메모리 활용도가 떨어질 수 있음
## Thrashing
•	프로세스가 충분한 수의 페이지(프레임)를 가지지 못하면, 페이지 폴트율이 매우 높아짐
	•	필요한 페이지를 가져오기 위해 페이지 폴트 발생
	•	기존 프레임을 교체함
	•	그런데 교체한 프레임이 곧 다시 필요해짐
	•	이로 인해 다음과 같은 결과 발생:
		•	CPU 사용률 저하
		•	운영체제는 다중 프로그래밍 정도를 늘려야 한다고 판단
		•	새로운 프로세스를 시스템에 추가
•	스래싱(thrashing): 프로세스가 페이지를 들락날락하는 데에만 바빠짐
![[Pasted image 20250602155000.png|300]]

요구 페이징이 작동하는 이유?
	•	지역성 모델(Locality model)
		•	프로세스는 한 지역성(locality)에서 다른 지역성으로 이동
		•	지역성은 겹칠 수도 있음
스래싱이 발생하는 이유?
	•	지역성들의 전체 크기(∑ 지역성 크기)가 전체 메모리보다 클 때 발생
		•	지역 교체나 우선순위 교체를 통해 영향 완화 가능
스래싱을 방지하는 방법?
	•	워킹 셋 모델(Working-set model)
	•	페이지 폴트 빈도(Page-fault frequency, PFF) 사용
## 워킹 셋 모델 (Working-Set Model) (1)
•	Δ ≡ 워킹 셋 윈도우 ≡ 고정된 수의 페이지 참조 (예: 10,000개의 명령어)
•	WSSi (프로세스 Pi의 워킹 셋) = 가장 최근 Δ 기간 동안 참조된 페이지 수
	•	Δ가 너무 작으면 지역성 전체를 포괄하지 못함
	•	Δ가 너무 크면 여러 지역성을 포함함
	•	Δ = ∞ 이면 전체 프로그램이 포함됨
•	D = ∑WSSi ≡ 전체 요구 프레임 수
	•	이는 지역성의 근사치
•	D > m이면 ⇒ 스래싱 발생
•	정책: D > m일 경우, 하나의 프로세스를 중단 또는 스왑 아웃
![[Pasted image 20250602155052.png|300]]
워킹 셋 추적 방법
	•	인터벌 타이머 + 참조 비트 조합으로 근사
	•	예: Δ = 10,000
		•	5000 타임 유닛마다 타이머 인터럽트 발생
		•	각 페이지마다 2개의 비트를 메모리에 유지 (첫 번째 참조 비트, 두 번째 참조 비트)
		•	페이지가 참조되면 첫 번째 참조 비트를 1로 설정
		•	타이머 인터럽트 발생 시, 첫 번째 비트를 두 번째로 복사하고 첫 번째는 0으로 초기화
		•	두 비트 중 하나라도 1이면 해당 페이지는 워킹 셋에 포함
	•	단, 완전히 정확한 방법은 아님
	•	개선 방안: 10비트 사용 + 1000 타임 유닛마다 인터럽트 발생
## 페이지 폴트 빈도 (Page-Fault Frequency)
•	WSS보다 더 직접적인 방법
•	허용 가능한 페이지 폴트 빈도(PFF) 기준을 정하고, 지역 교체 정책 사용
	•	실제 폴트율이 너무 낮으면 → 프로세스는 프레임을 반납
	•	실제 폴트율이 너무 높으면 → 프로세스는 프레임을 추가로 할당받음
![[Pasted image 20250602155125.png|300]]
## 워킹 셋과 페이지 폴트율
•	프로세스의 워킹 셋과 페이지 폴트율은 직접적인 관계가 있음
•	워킹 셋은 시간에 따라 변화
•	시간에 따라 피크와 골이 생김
![[Pasted image 20250602155148.png|300]]
•	근본적인 해결책은 더 많은 주기억장치(main memory)를 도입하는 것임
## 커널 메모리 할당 (Allocating Kernel Memory)
•	커널 메모리는 사용자 메모리와는 다르게 처리됨
•	보통 자유 메모리 풀(free-memory pool)에서 할당됨
	•	커널은 다양한 크기의 구조체를 위해 메모리를 요청함
	•	일부 커널 메모리는 연속적인 메모리가 필요함
		•	예: 장치 I/O를 위한 메모리
•	커널 메모리를 할당하는 대표적인 방법들:
	•	버디 시스템 할당자(Buddy system allocator)
	•	슬랩 할당자(Slab allocator)
## 버디 시스템 할당자 (Buddy System Allocator) (1)
•	물리적으로 연속된 페이지들로 구성된 고정 크기 세그먼트에서 메모리 할당
•	2의 거듭제곱 크기(power-of-2) 할당자를 사용해 메모리 할당
	•	요청은 2의 거듭제곱 단위로 처리됨
	•	요청 크기는 다음으로 큰 2의 거듭제곱으로 반올림됨
	•	더 작은 크기의 할당이 필요한 경우:
	•	현재 청크(chunk)를 다음 작은 2의 거듭제곱 크기의 두 청크(버디)로 분할
		•	적절한 크기의 청크가 확보될 때까지 이 과정을 반복
•	장점: 사용되지 않는 청크를 빠르게 병합(coalesce)하여 큰 청크로 만들 수 있음
•	단점: 단편화(fragmentation) 발생 가능성
![[Pasted image 20250602155251.png|300]]
## 슬랩 할당자 (Slab Allocator) (1)
•	슬랩(slab)은 하나 이상의 물리적으로 연속된 페이지로 구성됨
•	캐시(cache)는 하나 이상의 슬랩으로 구성됨
•	커널의 각 고유 데이터 구조체마다 하나의 캐시 존재
	•	각 캐시는 객체(object)로 채워짐 → 해당 데이터 구조체의 실체(instantiation)
•	캐시가 생성되면, 객체는 사용 가능 상태(free)로 표시되어 있음
•	구조체가 저장되면, 해당 객체는 사용 중(used)으로 표시
•	슬랩이 모두 사용된 객체로 꽉 차 있으면:
	•	다음 객체는 비어 있는 슬랩에서 할당됨
•	비어 있는 슬랩이 없으면, 새 슬랩이 할당됨
	•	장점:
	•	단편화 없음
	•	빠른 메모리 요청 처리 가능
![[Pasted image 20250602155344.png|300]]