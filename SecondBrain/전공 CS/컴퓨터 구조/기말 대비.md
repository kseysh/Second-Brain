###### R, lw, sw, beq rs, rt, rd 어떻게 되는지
R rd rs rt
lw rt N(rs)
sw rt N(rs)
beq rs rt N
그래서 rs-> always read
rt -> load 빼고 read
###### Jump 구현 방법
target PC = Top 4 bits of old PC +26-bit jump address + 00
PC+4의 위 4개 bit
가져온 값을 위로 두 칸 올려서 00을 맨 뒤로 만듬 (4를 더해줘야 하므로)
###### pipeline과 throughput, latency
throughput 증가하지만, 각 명령어의 실행시간인 latency는 감소하지 않는다.
###### 모든 단계가 똑같을 때 pipeline의 성능향상률
![[Pasted image 20250501152016.png|200]]
즉, stage 수만큼 증가한다.
###### Hazard 3가지
•	Structural Hazard
	•	필요한 자원이 사용 중일 때
•	data Hazard
	현재 명령어에서 사용하고자 하는 데이터가 이전 명령어의 결과에 의존할 때
	MEM hazard, Load-Use hazard
•	Control Hazard
	•	제어 흐름 결정이 이전 명령어에 의존할 때
		Branch hazard
###### MIPS 파이프라인에서 메모리가 하나일 경우
Structural Hazard 발생
•	Load/Store 명령은 데이터 접근 필요
•	명령어 가져오기(fetch)는 해당 사이클 동안 **stall**해야 함
	•	결과적으로 파이프라인에 “**bubble**” 발생
•	따라서 파이프라인 데이터 경로에는
	•	명령어/데이터 메모리를 분리하거나
	•	명령어/데이터 캐시를 별도로 구성해야 함
###### add 과정에 MEM이 포함되어 있는 이유
사용하지는 않더라도, 모든 stage를 균등하게 하기 위해 포함함 (그렇게 안하면 structure hazard 발생 가능성이 있기 때문)
###### stall을 피하기 위한 코드 스케쥴링 방법 (Forwarding으로 해결되지 않는 stall)
Load 명령의 결과를 바로 다음 명령에서 사용하지 않도록 코드 재배치
###### EX data hazard 확인법
R-format의 rd가 다음이나 다다음의 rs, rt와 같으면 EX data hazard임 (하지만 forwarding으로 해결 가능)
###### Load-Use data hazard란?
lw의 rd를 다음 명령에서 읽으려고 할 때 생기는 hazard (forwarding 불가능)
##### 그림이 틀린 그림인 이유
![[IMG_62942C41B2DC-1.jpeg|500]]
###### A
Load 명령어를 사용할 때, WB단계에서 Register 메모리에 Write register에 있는 값을 저장하게 되는데, 위 그림처럼 수행하면 ID 단계에서 읽었던 잘못된 write register 값을 가져오는 문제가 발생할 수 있다. 따라서 write register는 아래와 같이 저장되어야 한다.
![[IMG_12CF0663B16C-1.jpeg|500]]
###### 메모리와 레지스터 차이점
메모리: 읽기 or 쓰기만
레지스터: 읽기, 쓰기 동시에 가능
###### Control signal 생성 시점
Instruction Decode (ID) 단계 
Control Signal도 넘겨줘야 한다.
###### forwarding시 확인해야 하는 조건
1. 이전 instruction이 R-format인가? (forwarding 명령어가 register에 값을 쓸 경우에만 해당되므로)
2. 이전 instruction이 RegWrite를 하는가? (해야함)
3. 이전 instruction의 destination(rd)가 0인가? (0가 아니어야 함)
###### Double Data Hazard가 발생하면?
가장 최근 값만 forwarding 해준다.
###### lw에서 stall이 발생하는 경우, 판단 장소
ID stage의 rs, rt가 EX stage의 dst(rt)와 같고 EX stage에 있는 instruction이 lw
ID stage에서 Load-Use Data Hazard 판단
lw의 dst와 뒤 instruction의 rs,rt가 겹칠 때
###### 파이프라인 멈추는 방법
•	ID/EX 레지스터의 제어 값을 0으로 설정
	•	EX, MEM, WB 단계는 nop(무연산)을 수행
•	PC와 IF/ID 레지스터의 업데이트를 방지
	•	사용하는 명령어는 다시 decode되고
	•	다음 명령어는 다시 fetch됩니다
	•	1 사이클의 stall로 MEM이 lw 명령어의 데이터를 읽을 수 있도록 함
		•	이후 EX 단계로 forwarding이 가능함
![[Pasted image 20250520154500.png|400]]
###### Hazard Detection Unit의 역할
load-use hazard를 주로 탐지하는데, PCWrite와 IF/ID Write를 0으로 만들어 PC와 IF/ID 레지스터 를 stall한다
또한, Control 신호를 0으로 만들고 , bubble 삽입
###### 분기 지연을 줄이기 위한 방법
•	분기 결과를 ID 단계에서 판단하도록 하드웨어 이동
	•	Target address adder
	•	register comparator
이를 통해 원래는 비교를 EX stage에서 했는데, ID 과정으로 옮겼다.
branch prediction이 틀릴 때마다의 bubble을 3->1로 bubble을 줄였다.
###### 1 bit predictor의 한계
실제 동작이 TTTTNTTTTNTT...이라면
예측을 TTTTTNTTTTNT...으로 하여 총 4번의 예측이 틀리게 되어 패턴 변화에 취약하다
###### branch prediction만으로 부족한 이유
branch predicor가 taken이라고 예측하더라도, 실제 target address를 계산해야하기 때문
###### Branch Target Buffer의 역할
branch 명령어의 target address를 미리 저장해두는 역할
예측이 taken이고, 해당 target address가 BTB에 있으면 바로 target address로 fetching이 가능하여 지연을 제거할 수 있다.
“이 분기 명령어가 taken이라면 어디로 갈 것인가”를 저장
###### Prediction table과 Target buffer의 차이
- **Prediction table**: “이 분기 명령어가 taken일 확률이 높음”을 저장
- **Target buffer**: “이 분기 명령어가 taken이라면 어디로 갈 것인가”를 저장
![[Pasted image 20250525134054.png|200]]
###### ILP를 하기 위한 방법 두 가지
Instruction Level Parallelism
•	더 깊은 파이프라인
	•	각 단계 작업을 줄여 clock cycle 단축
•	Multiple Issue (여러 instruction을 동시에 발행)
	•	파이프라인 단계를 복제해 여러 개의 파이프라인 구성
###### IPC 계산
(CPI<sup>-1</sup> = IPC)
###### Multiple Issue 두 가지 종류
•	Static multiple issue (PC와 PC+4를 항상 같이 fetch)
	•	컴파일러가 함께 발행될 명령어를 그룹화 (sw가 수행)
	•	이를 “issue slot”에 패키징
	•	해저드를 감지하고 피함
•	Dynamic multiple issue 
	•	CPU가 instruction을 여러개 미리 fetch -> 그 중 상관없는 것들을 모아서 같이 issue
	•	CPU가 명령어 스트림을 분석해 각 사이클마다 발행할 명령어 선택
	•	컴파일러는 명령어 순서를 재배열해 도움 줄 수 있음
###### static muliple issue 하는 법
•	컴파일러는 일부 또는 모든 해저드를 제거해야 함
	•	명령어를 issue packet으로 재배열
	•	하나의 packet 안에는 의존성이 없어야 함
	•	packet 간에는 의존성이 있을 수 있음
		•	ISA마다 다르며, 컴파일러가 이를 알아야 함
	•	필요 시 nop(no operation)으로 채움
###### static Dual Issue 묶는 방법
ALU/branch와 load/store로 묶는다.
64비트 정렬 -> PC가 8씩 증가함
사용되지 않는 명령어는 nop으로 채운다
###### static Dual Issue로 인해 회로가 달라진 점
- 두 배의 읽기/쓰기가 수행되어야 하기 때문에 register로 들어가는 input/output port가 두 배로 늘어남
- EX 단계에서 ALU용 ALU, lw/sw용 ALU로 하나 더 늘어남
###### Dual-Issue MIPS에서 발생하는 Hazard
•	EX data 해저드
	•	단일 발행에서는 forwarding으로 stall을 피함
	•	이제는 동일 packet 안에서 ALU 결과를 load/store에서 사용할 수 없음
		`add $t0, $s0, $s1  `
		`load $s2, 0($t0)`
	•	두 개의 packet으로 분리해야 하며, 사실상 stall 발생
•	Load-use 해저드
	•	여전히 1사이클 사용 지연 (nop으로 채워보낸다면)
	•	하지만 이제 두 개의 명령어가 관련됨
###### Loop unrolling의 효과
•	루프 본문을 복제하여 더 많은 병렬성 노출 (loop 내부의 크기를 늘려 병렬성을 크게 한다.)
•	루프 제어 오버헤드 감소 (beq instruction 비중을 줄인다) 
###### register renaming이란?
Loop unrolling시 복제마다 다른 레지스터를 사용하는 것으로 루프에 전달되는 anti-dependency를 회피한다.
###### Superscalar processor
CPU가 structural/data hazard를 회피하기 위해 매 사이클마다 0~n개의 명령어를 발행할 지 결정한다.
•	컴파일러의 스케줄링 필요 없음
	•	하지만 여전히 도움이 될 수 있음
	•	코드 의미는 CPU가 보장
###### Dynamic Pipeline Scheduling이란?
CPU가 Instruction을 미리 여러 개 읽어놓고 명령어를 out-of-order로 실행해 stall을 피할 수 있도록 한다
결과는 반드시 순서대로 레지스터에 기록한다.
###### Dynamic Pipeline Scheduling 하는 법
1. CPU가 Instruction을 미리 여러개 읽어놓고 Reservation station에 저장한다
2. CPU는 Reservation staion을 보면서 명령어 순서를 re-order한다
3. Reservation station에 저장된 명령어를 out-of-order로 실행한다
4. 결과는 Commit unit에 저장되고 commit unit에 저장된 결과는 in-order commit 진행
###### register renaming
- register renaming은 reservation station과 reorder buffer를 통해 구현되며,
- 명령어 실행 전에 필요한 피연산자 값을 미리 확보하거나,
- 아직 준비되지 않은 피연산자는 나중에 직접 제공받도록 함으로써 
- 레지스터 충돌 없이 병렬 실행을 가능하게 해준다.
###### 동적 스케쥴링을 하는 이유
모든 stall이 예측가능한 것은 아니기 때문
분기 결과가 런타임에 결정되기 때문에 branch를 피해 스케쥴링하기 어렵다
동일한 ISA라도 구현에 따라 지연과 해저드가 다르기 때문
###### Mulitple Issue가 예상보다 적은 효과를 보이는 이유
- 프로그램에는 실제 의존성이 존재
- 제거하기 어려운 의존성 존재
- 노출되기 어려운 병렬성 존재
###### 전력 효율성의 추세
처음: pipeline도 적고, Issue width도 1개이고, speculation도 안한다
점차 multiple Issue를 늘리고 pipeline stage를 올리고 speculation도 한다
어느순간 pipeline 개수를 14로 고정하고 issue width도 4로 고정한다, 대신, cpu core가 늘어남
###### 지역성의 종류
• 시간 지역성
	• 최근에 접근한 항목은 곧 다시 접근될 가능성이 높음
	• 예: 반복문 안의 명령어, 유도 변수
• 공간 지역성
	• 최근에 접근한 항목 근처에 있는 항목도 곧 접근될 가능성이 높음
	• 예: 순차적인 명령어 접근, 배열 데이터
###### 캐시에서 복사의 단위
블록
###### Direct Mapped Cache
위치는 주소에 따라 결정됨
(블록 주소) modulo (캐시 블록 수)
주소의 하위 비트를 사용하는 방식
![[Pasted image 20250525200334.png|200]]
###### Direct Mapped Cache에서 어떤 블록이 저장되어 있는지 확인하는 방법
 데이터뿐 아니라 상위 비트도 함께 저장
	• 이를 태그(tag)라고 함
• 해당 위치에 데이터가 없으면?
	• 유효 비트(valid bit): 1 = 존재, 0 = 없음
주소의 하위 bits -> 위치를 찾기 (index)
주소의 상위 bits -> 맞는지 확인 (Tag)
valid bit -> 유효한지 확인
###### Direct Mapped **Cache**에서 주소 분할 법
1. CPU가 메모리 주소를 발생시키면, 그 주소는 Tag / Index / Offset으로 분할됨
2. Index bit를 이용해 캐시 메모리의 특정 슬롯에 접근함
3. 접근한 캐시 슬롯에 저장된 Tag와 주소의 Tag를 비교함
	1. Tag 일치 && Valid = 1 => Hit
	2. else, Miss
###### 64개의 블록, 블록당 16바이트 주소 1200은 어떤 블록 번호에 대응되는가?
• 블록 주소 = ⌊1200 ÷ 16⌋ = 75
• 블록 번호 = 75 mod 64 = 11
###### 64개의 블록, 블록당 16바이트 주소면 cache size는?
block 갯수: 2<sup>6</sup> blocks
한 block의 크기 2<sup>4</sup>byte
Direct mapped cache의 경우 => cache size: 2<sup>10</sup>byte
###### 블록 크기가 클 때 장단점
장점
• *공간 지역성에 의해* 더 큰 블록은 cache miss 비율을 줄일 수 있음
단점
• 블록이 클수록 블록 수는 줄어들어 블록 간 경쟁이 심해져 miss 비율 증가
• 더 큰 블록은 캐시 오염(pollution) 가능성 증가 (pollution = 값을 가져왔지만 쓰지 않는 공간)
• miss penalty도 더 커짐 (miss일 때, data를 main memory로부터 가져오는데 걸리는 시간)
	• 이로 인해 miss 비율 감소의 이점이 상쇄될 수 있음
###### 캐시 미스시 과정
• CPU 파이프라인 정지
• 다음 계층에서 블록을 가져옴
• 명령어 캐시 미스: 명령어 fetch 재시작
• 데이터 캐시 미스: 데이터 접근 완료 후 진행
###### Write Through 방식
데이터 쓰기 hit 시 캐시와 메모리를 함께 업데이트 하는 방법
• 예: base CPI = 1, 명령의 10%가 store, 메모리 쓰기 = 100 사이클
		• 유효 CPI = 1 + 0.1 × 100 = 11
###### write Through 방식의 단점과 해결책
쓰기 시간이 길어질 수 있음
• 해결책: write buffer
	• 메모리에 쓰기 대기 중인 데이터를 임시 저장
	• CPU는 즉시 다음 명령 수행 가능
		• write buffer가 가득 찼을 때만 stall 발생
###### Write Back 방식
데이터 쓰기 hit 시 캐시만 업데이트
	• 각 블록이 변경되었는지(dirty) 추적
		각 cache block마다 dirty bit를 둔다
		원본 데이터와 값이 달라졌다는 뜻
• dirty 블록이 교체될 때만 메모리에 쓰기
	• write buffer를 사용해 교체 전 블록 읽기를 먼저 수행 가능
###### write allocation vs. write around
write allocation: cache write miss일 때 캐시에 데이터를 가져온다 (fetch한다)
write around: cache write miss일 때  캐시에 데이터를 가져오지 않는다 (fetch하지 않는다).
###### write-back의 경우 
일반적으로 block을 fetch하는 write allocation 방식을 사용한다.
###### I-cache miss율 = 2%• D-cache miss율 = 4%• miss penalty = 100 사이클• 기본 CPI (이상적 캐시) = 2• load & store 비율 = 36%에서 실제 CPI
• 명령어당 miss 사이클
	• I-cache: 0.02 × 100 = 2
	• D-cache: 0.36 × 0.04 × 100 = 1.44
• 실제 CPI = 2 + 2 + 1.44 = 5.44 (*기본 CPI를 더해줘야 한다는 사실을 잊지 말자*)
###### CPU 클럭 1ns, hit time = 1 사이클, miss penalty = 20 사이클, I-cache miss율 = 5%에서 AMAT
• AMAT = 1 + 0.05 × 20 = 2ns          
###### Fully associative cache란?
• Fully associative(완전 연관) - 모든 주소가 아무 block이나 사용가능
	• 특정 블록을 어떤 캐시 엔트리에도 저장 가능
	• 모든 엔트리를 동시에 비교해야 함
	• 엔트리마다 비교기 필요 → 비용 큼
###### n-way set associative cache란?
- **후보지가 n개**
	• **각 집합이 n개의 엔트리 포함**
	• 특정 집합 내 모든 엔트리 동시에 검색
	• 비교기 n개만 필요 → 비용 절감
![[Pasted image 20250529153439.png|400]]
###### 1024 block에서 Direct mapped의 index
index: 10bit
###### 1024 block에서 4-way set associative의 set, index
256 set
index: 8bit
###### 교체 정책 2가지
• 최소 최근 사용(LRU): 가장 오랫동안 사용되지 않은 블록 선택
	• 2-way는 간단, 4-way는 가능하지만 복잡, 그 이상은 너무 어려움
• 랜덤(Random):
	• 연관도가 높을 때는 LRU와 거의 유사한 성능 제공
###### 다단계 캐시의 역할
• 1차 캐시(L1): CPU에 직접 연결됨
	• 작지만 매우 빠름
	• hit time을 줄이기 위해 사용
• 2차 캐시(L2): L1 miss를 처리
	• 더 크고 느리지만 메인 메모리보다는 빠름
	• miss penalty를 줄이기 위해 사용
###### DGEMM가 성능이 안 좋을 수 있는 이유
matrix 크기가 cache보다 크다면, 반복 접근하는 부분이 돌아왔을 때 이미 cache에서 쫒겨난 상태가 되어 cache miss가 발생할 수 있기 때문이다
###### DGEMM의 성능 하락 해결책
Matrix multiplication을 한 번에 처음부터 끝까지 수행하는 것이 아니라 matrix block이 cache보다 작도록 **Block 단위로 Matrix multiplication을 나눠서 수행하여** 대부분을 cache hit으로 처리할 수 있도록 한다.
따라 Blocking을 통해 cache를 고려해서 성능을 향상시킬 수 있다.
###### 가용성 향상 방법
• **MTTF(Mean Time To Failure) 증가**: 결함 회피, 결함 허용, 결함 예측
• **MTTR(Mean Time To Repair) 감소**: 진단 및 수리 도구와 프로세스 향상
###### hamming distance란?
• 해밍 거리
	• 두 비트 패턴 간에서 서로 다른 비트의 개수
###### single error detection과 single Error Correction
• 최소 거리 = 2 → 단일 비트 오류 검출 가능
	• 예: 패리티 코드
• 최소 거리 = 3 → 단일 오류 수정, 2비트 오류 검출 가능
###### SEC Encoding 하는 법
• 해밍 코드 계산 방법: (최소한의 parity bit으로 SEC를 하는 방법)
	• 왼쪽부터 비트 번호를 1번부터 매김
	• 2의 거듭제곱 위치의 비트는 패리티 비트 (1,2,4,8)
	• 각 패리티 비트는 특정 데이터 비트를 검사함
![[Pasted image 20250603140208.png|300]]
p1은 LSB가 1인 자리들의 parity
p2는 LSB에서 두 번째 자리가 1인 자리들의 parity
###### 10011010을 Hamming code로 변환
![[Pasted image 20250603140540.png|200]]
=> minimum distance가 3이 된다.
011100101010
###### SEC Decoding하는 방법
• 패리티 비트의 값은 어떤 비트에 오류가 있는지를 알려줌
	• 인코딩 시 사용한 비트 번호 매김 그대로 사용
	• 예:
		• 패리티 비트 = 0000 → 오류 없음 일때,
		• 패리티 비트 = 1010 → 10번 비트가 뒤바뀜
###### DED code의 장점
• 전체 워드에 대한 추가 패리티 비트(pn) 추가
• 해밍 거리 = 4로 만듦
• 디코딩:
	• H = SEC 패리티 비트
		• H 짝수, pn 짝수 → 오류 없음
		• H 홀수, pn 홀수 → 수정 가능한 단일 비트 오류
		• H 짝수, pn 홀수 → pn 비트에 오류
		• H 홀수, pn 짝수 → 이중 오류 발생
double error detection도 가능하게 된다,.
###### 미스의 원인 3가지
• 강제 미스(Compulsory miss / cold start miss)
	• **해당 블록에 처음 접근**할 때 발생
• 용량 미스(Capacity miss)
	• **캐시 크기가 제한**되어 발생
	• 교체된 블록에 다시 접근
• 충돌 미스(Conflict miss / collision miss)
	• 완전 연관이 아닌 캐시에서 발생
	• **집합 내 항목 간 충돌**
	• 동일한 크기의 완전 연관 캐시에서는 발생하지 않음
###### 캐시 크기 증가시 미스의 원인과 성능 저하 요인
Decrease capacity misses
접근 시간이 증가할 수 있음
###### 연관도 증가시 미스의 원인과 성능 저하 요인
Decrease conflict misses
접근 시간이 증가할 수 있음
###### 블록 크기 증가시 미스의 원인과 성능 저하 요인
Decrease compulsory misses
미스 패널티 증가. 블록 크기가 매우 크면, 오염으로 인해 미스율이 증가할 수 있음
###### Fine-grain multithreading이란
• 매 사이클마다 스레드를 전환
• 명령어 실행을 교차(interleave)하여 수행
• 하나의 스레드가 멈추면 다른 스레드가 실행됨
###### Coarse-grain multithreading이란
• 긴 지연이 있을 때만 스레드 전환 (예: L2 캐시 미스)
• 하드웨어는 단순해지지만 짧은 지연(예: 데이터 해저드)을 숨기지는 못함
###### Simultaneous multithreading이란
• 다중 발행 동적 스케줄링 프로세서에서
	• 여러 스레드의 명령어를 스케줄
	• 독립적인 스레드의 명령어는 기능 유닛이 사용 가능할 때 실행
	• 스레드 내의 의존성은 스케줄링과 레지스터 리네이밍으로 처리
