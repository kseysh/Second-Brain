###### Armstrong의 공리
•	만약 β ⊆ α 이면, α → β (반사성 reflexivity) (화살표 부분이 같다..)
•	만약 α → β 이고 γ가 존재하면, γα → γβ (확장성 augmentation)
•	만약 α → β이고, β → γ이면, α → γ (추이성 transitivity)
###### Armstrong의 공리 성질
•	sound (실제로 성립하는 함수적 종속성만 생성함)
•	complete (성립하는 모든 함수적 종속성을 생성할 수 있음)
###### Closure of Functional Dependencies
•	α → β이고 α → γ이면, α → βγ이다 (union)
•	α → βγ이면, α → β이고 α → γ이다 (decomposition)
•	α → β이고 γβ → δ이면, αγ → δ이다 (pseudotransitivity)
###### Attribute Closure의 활용
•	슈퍼키(superkey) 테스트:
	•	α⁺를 계산해서, α⁺가 R의 모든 속성을 포함하는지 확인
•	함수 종속성 테스트:
	•	α → β가 *F⁺에 포함되는지 확인하려면*, α⁺를 계산하고 β ⊆ α⁺인지 확인
	•	이 방법은 간단하고 효율적
•	F의 Closure 계산:
	•	R의 모든 부분집합 γ에 대해 γ⁺를 계산하고, γ⁺의 모든 부분집합 S에 대해 γ → S 형태의 함수 종속성을 출력
###### Lossless join Decomposition하는 법
•	R = (R₁, R₂)인 경우, 가능한 모든 관계 r에 대해	![[IMG_5818D9CDA980-1.jpeg|100]]가 되어야 한다.
•	R을 R₁과 R₂로 분해했을 때 다음 중 하나라도 F⁺에 포함되면 Lossless-join Decomposition이다:
	•	R₁ ∩ R₂ → R₁
	•	R₁ ∩ R₂ → R₂
•	즉, *R₁ ∩ R₂가 R₁ 또는 R₂의 슈퍼키이면 Lossless-join Decomposition*가 된다.
###### decomposition이 dependency preserving이면
(F₁ ∪ F₂ ∪ … ∪ Fn)⁺ = F⁺
###### Lossless join에서 3NF와 BCNF의 차이
•	항상 3NF로 *Lossless-join*, 종속성 보존이 가능하다.
•	항상 BCNF로 Lossless-join은 가능하지만, Dependency Preservation은 항상 가능하지는 않다.
###### EM 모델에서의 Linear I/O
O(N/B) -> N개의 데이터를 B 블록 단위로 가져올 때의 시간 복잡도
###### Fixed-Length Records에서 레코드 i의 삭제 개선 방식
- 이동하지 않고 삭제된 레코드들을 free list로 연결
- O(1) I/O 발생
###### Free List 관리 방법
사용되지 않는 레코드의 속성 공간을 포인터 저장에 사용한다
###### null bitmap 표현 방법
0000으로 1byte로 표현
###### 가변 길이 레코드 표현 방법
두 부분으로 구성
	•	고정 길이 속성을 저장하는 초기 부분
	•	가변 길이 속성 데이터
•	가변 속성은 (offset, length) 쌍으로 표현하고 실제 데이터는 고정 속성 뒤에 저장
•	null 값은 null-value 비트맵으로 표현
![[Pasted image 20250501144031.png|300]]
dept_name인 Comp. Sci를 알고 싶다면, dept_name은 세 번째 필드이므로 8로 가서 좌표값을 확인하고, 36부터 10만큼 읽는다. (가변 길이만 이렇게 하고, fixed length는 그냥 저장함)
null bitmap은 fixed length와 variable length사이에 넣어둔다.
###### Slotted Page Header에 저장되는 정보
record entry 수
block 내 free space의 끝 위치
각 레코드의 위치와 크기
###### 레코드 삭제시 블록 내에서 일어나는 일
레코드들은 페이지 내에서 이동 가능하며, 빈 공간 없이 연속되도록 유지되어야 하므로 한 레코드가 삭제되면 빈공간을 채우기 위해 block 안의 레코드를 모두 민다
이 때, 헤더의 항목은 반드시 갱신되어야 한다.
###### 포인터는 실제 레코드를 가리켜야 한다
**아니다.**
포인터는 항상 Slotted Page Header에 있는 레코드에 대한 entry를 가리켜야 한다.
레코드가 재정렬되면 다른 곳에서 저장해두던 포인터의 값이 유효하지 않을 수 있으므로
###### 파일 내 레코드 구성 방법 힙/순차/해싱 특징
•	힙(Heap): 레코드를 공간이 있는 아무 곳에나 배치
	삽입이 빠름
	검색 느림
•	순차(Sequential): 레코드를 검색 키 값(보통 pk)에 따라 순서대로 저장
	- binary search로 빠른 검색 가능
	- 삽입 삭제 시 정렬 유지 비용있음
•	해싱(Hashing): 특정 속성에 대해 해시 함수를 적용하여 결과에 따라 파일의 블록 결정
	매우 빠른 검색/삽입
	해시 충돌 처리 필요
###### 버퍼와 버퍼 관리자
•	버퍼: 디스크 블록 복사본을 저장할 수 있는 메인 메모리 일부
•	버퍼 관리자: 메인 메모리의 버퍼 공간 할당을 담당하는 하위 시스템
###### 디스크 블록이 필요할 때 버퍼 관리자
프로그램은 디스크 블록이 필요할 때 버퍼 관리자에게 요청
1.	요청한 블록이 버퍼에 있으면 해당 메모리 주소 반환
2.	없으면 버퍼 공간을 할당함
•	공간 부족 시 다른 블록을 교체
•	교체되는 블록은 변경된 경우에만 디스크에 다시 기록
•	디스크에서 블록을 읽어 버퍼에 저장 후 메모리 주소 반환
###### LRU가 비효율적인 경우
반복 스캔이 많은 패턴에는 LRU가 비효율적
	예: 중첩 루프 방식으로 두 릴레이션 r, s를 조인할 때
###### pinned block 
디스크에 다시 기록되는 것이 허용되지 않는 메모리 블록
###### LRU vs. MRU
LRU: 가장 오래전에 사용된 블록을 가장 먼저 교체함
대부분의 운영체제에서 사용하는 기본적인 버퍼 교체 전략
과거의 접근 패턴을 바탕으로 미래 접근을 예측.
데이터베이스 쿼리는 종종 순차적 접근 패턴을 가지므로, 이러한 패턴을 활용해 예측 가능.

MRU: 가장 최근에 사용된 블록을 가장 먼저 교체함
- 현재 처리 중인 블록은 “pinned” 상태로 고정되며, 사용이 끝나면 고정이 해제되고 MRU 블록이 됨.
•	통계 기반 힌트 사용:
	•	버퍼 매니저는 통계 데이터를 활용해 어떤 블록이 자주 접근되는지를 판단 가능.
	•	예시: 데이터 딕셔너리는 자주 참조되므로, 메모리에 상주시켜두는 것이 좋음.
###### LRU 단점 해결방안
- 쿼리 옵티마이저가 접근 패턴에 대한 힌트를 제공하고, 이를 기반으로 **혼합 전략(mixed strategy)** 사용이 바람직.
#### 한 사이클
###### index 파일 구성
인덱스 파일이 구성되는 항목
![[Pasted image 20250603231752.png|100]]
###### 인덱스의 기본 유형 두 가지
1. Ordered indices (정렬 인덱스): 검색 키가 정렬된 순서로 저장됨
2. Hash indices (해시 인덱스): 해시 함수를 이용해 키가 “버킷”에 균일하게 분산됨
###### ordered index 종류
*ordered index*는 검색 키 값을 기준으로 정렬된 순서로 index 항목을 저장합니다. 예: 도서관 저자 색인

•	Primary index (기본 인덱스): 파일이 정렬된 순서대로 저장되어 있으며, 이 순서를 결정하는 검색 키를 가진 인덱스 (*clustering index*라고도 함)
	•	보통 기본 키가 검색 키지만, 반드시 그렇지는 않음
•	*Secondary index* (보조 인덱스): 파일의 순서와는 다른 순서로 검색 키를 정렬한 인덱스 (non-clustering index라고도 함)
###### Index-sequential file이란
ordered sequential file with a primary index.
###### Dense Index Files
파일 내 *모든 검색 키 값에 대해* index record가 존재 (모든 레코드가 아님)
###### Sparse Index Files
*일부 검색 키 값에 대해서만* 인덱스 레코드를 포함함
검색 키를 기준으로 레코드가 순차적으로 정렬되어 있을 때 사용 가능
###### Sparse Index File에서 키 값이 K인 레코드를 찾기 위해서는
– K보다 작거나 같은 검색 키 값 중 가장 큰 값을 가진 인덱스 레코드를 찾음
– 해당 인덱스 레코드가 가리키는 레코드부터 파일을 순차적으로 검색함
###### Sparse Index vs. Dense Index
Sparse Index: 공간을 덜 차지함 삽입/삭제 비용이 적다
Dense Index: 레코드 검색 속도가 빠르다
###### Sparse Index와 Dense Index의 좋은 절충안
해당 블록에서 가장 작은 검색 키 값에 대응하는, 파일의 각 블록마다 하나의 인덱스 항목을 가지는 Sparse Index
=> 어차피 DB는 block단위로 data를 가져오기 때문
###### dense index와 sparse index의 leaf node 순차 탐색 시간 복잡도
dense Index: N 개 항목, 블록당 B개 :O(N/B) blocks
sparse Index: N/B 개 항목, 블록당 B개: O(N/B<sup>2</sup>)
###### N<sub>data</sub> = 20,000,000 (20 M) B<sub>data</sub> = 20, B<sub>index</sub> = 100 이라 가정하고 sparse, dense 검색 시간 복잡도 구하기
N<sub>index</sub> = 1,000,000 (1M) 개의 block 존재 (data block마다 하나씩 있으므로)
index block = N<sub>index</sub>/B<sub>index</sub> = 10000
이분 탐색을 이용한 cost: O(log n) = 13.xxx = 14번 I/O
N이 data를 저장한 block의 개수일 때, 
N<sub>index</sub>/2<sup>i</sup> = B<sub>index</sub>
O(log<sub>2</sub>(N<sub>index</sub>/B<sub>index</sub>))

dense라면,O(log<sub>2</sub>(N<sub>data</sub>/B<sub>index</sub>))
###### primary Index의 문제와 해결책
- primary index가 메모리에 fit하지 않으면 접근 비용이 증가
- 해결책:
	•	디스크상의 Primary index를 정렬된 파일로 보고, 그 위에 sparse index를 구축
	outer index – a sparse index of primary index
	inner index – the primary index file

- outer index도 메모리에 안 들어갈 경우, 더 상위 단계 인덱스를 생성 가능
- 삽입/삭제 시 모든 수준의 인덱스를 갱신해야 함
###### Multilevel Index에서 h는?
h = O(log<sub>B</sub>N)
###### multilevel index의 문제
인덱스에 레코드가 하나씩만 들어가게 되면 인덱스의 장점을 활용하지 못한다. (update하다보면 그럴 수도 있음)
###### Single-level index entry deletion에서 Dense-Index vs. Sparse Index
•	Dense Index: 파일 레코드 삭제와 유사
•	Sparse Index:
	• 인덱스에 검색 키에 대한 항목이 존재하면, 해당 항목은 파일에서 다음 검색 키 값(검색 키 순서)을 인덱스에 대신 넣어 삭제된다.
	• 만약 다음 검색 키 값이 이미 인덱스에 존재한다면, 항목은 교체되는 대신 삭제된다.
###### Single level index 삽입에서 Dense-Index vs. Sparse Index
Dense 인덱스 – 검색 키 값이 인덱스에 없다면 삽입한다.
Sparse 인덱스 – 인덱스가 파일의 각 블록에 대한 항목만 저장하는 경우, 새로운 블록이 생성되지 않는 한 인덱스를 변경할 필요가 없다.
	• 새로운 블록이 생성되는 경우, 해당 블록에 나타나는 첫 번째 검색 키 값을 인덱스에 삽입한다.
###### 보조 인덱스를 이용한 순차 스캔
보조 인덱스를 이용한 순차 스캔은 비효율적
•	각 레코드 접근 시 디스크에서 블록을 새로 불러올 수 있음
###### 순차 스캔 시간 복잡도 Primary vs Secondary
보조 인덱스를 이용한 순차 스캔: O(N/Blog<sub>B</sub>N/B)
그냥 순차 스캔: O(N/B)이므로
###### indexed-sequential files의 단점
인덱스 순차 파일의 단점:
	•	파일이 커질수록 성능이 저하됩니다. 이는 많은 오버플로 블록이 생성되기 때문입니다.
	•	전체 파일을 주기적으로 재구성해야 합니다.
###### B+ Tree 의 장단점
B+ 트리 인덱스 파일의 장점:
	•	삽입과 삭제가 발생하더라도 소규모의 국소적인 변경만으로 자동으로 스스로를 재구성합니다.
	•	성능을 유지하기 위해 전체 파일을 재구성할 필요가 없습니다.
B+ 트리의 (작은) 단점:
	•	삽입 및 삭제 시 추가적인 오버헤드와 공간 사용이 발생합니다.
###### DB에서 B+ Tree를 B Tree 대신 사용하는 이유
모든 레코드가 리프 노드에만 저장되어 리프 노드에 데이터가 정렬된 상태로 모여 있어 범위 검색이나 순차 접근에 최적화됨.
###### **B+ Tree 노드 개수**
- root node:
	- ptrs ∈ `[2, B]`
	- root가 leaf: 
		- ptrs ∈ `[1, B]`
- leaf node: 
	- search keys ∈ `[⌈(B–1)/2⌉, B-1]`
	- ptrs ∈ `[⌈(B–1)/2⌉ + 1, B]`
- non-leaf node: 
	- keys ∈ `[⌈B/2⌉-1, B-1]`
	- ptrs ∈ `[⌈B/2⌉, B]` (= 자식 개수)
B: 하나의 노드에 들어가는 entry 개수 (즉, 포인터)
최대는 다 B, root leaf non-leaf 각각 최소가 2, ⌈(B–1)/2⌉ + 1, ⌈B/2⌉
###### B+ Tree 특징
루트에서 리프까지의 모든 경로의 길이는 동일합니다.
###### leaf노드에서 P<sub>B</sub>는?
P<sub>B</sub>은 다음 리프 노드를 가리킴 (검색 키 순서로)
###### non-leaf node의 특성
•	non-leaf node는 leaf node에 대한 다단계 sparse index를 형성함
###### 포인터가 m개인 non-leaf node에서 P₁이 가리키는 서브트리의 모든 키
K₁보다 작음
###### 포인터가 m개인 non-leaf node에서 P<sub>B</sub>이 가리키는 서브트리의 키
K<sub>B-1</sub> 이상
###### n이 6이면 root, leaf, non-leaf 노드 개수
•	리프 노드는 3~5개의 값을 가짐 (⌈(n–1)/2⌉ = 3, n–1 = 5)
•	루트를 제외한 비리프 노드는 3~6개의 자식 (⌈n/2⌉ = 3, n = 6)
•	루트는 최소 2개의 자식을 가져야 함
###### B+ Tree 검색(eq, range), 삽입 시간 복잡도
eq 검색: O(log<sub>B</sub>N)
range 검색: O(log<sub>B</sub>N + T/B)
###### leaf node 분할
- **처음 ⌈n/2⌉개의 쌍은 원래 노드에 저장하고, 나머지는 새 노드에 저장**한다. 
- **새 노드에 있는 가장 작은 키 값을 분할된 노드의 부모 노드에 삽입**한다.
- **부모 노드가 가득 차 있으면, 부모 노드도 분할하고 분할을 위쪽으로 전파**한다. 

- 이 작업은 가득 차지 않은 노드를 만날 때까지 위로 진행된다. 
	- 최악의 경우 루트 노드까지 분할되어 트리의 높이가 1 증가할 수 있다.
###### leaf node와 non leaf node의 분할 차이
leaf node는 value를 기준으로 `⌈B/2⌉`개와 나머지로 분할
non-leaf node는 ptr을 기준으로 `⌈(B+1)/2⌉`개와 나머지로 분할 (leaf에서는 유지하고 올라가던 애가 non-leaf에서는 없어지고 올라감)
###### find_leaf, split, 삽입 시간 복잡도
find_leaf 시간복잡도: O(log<sub>B</sub>N)
split 시간 복잡도: O(1) => 해봤자 노드 하나를 가져와서 나누는 것 뿐이므로 
splits => h번 = O(log<sub>B</sub>N)
따라서 삽입 시간 복잡도: O(log<sub>B</sub>N)
###### 삭제시 알아야 할 것
**머지를 하고, Re-Distribution을 한다 정도만 알자**
삭제로 인해 노드에 항목이 너무 적어졌고, 해당 노드와 형제 노드의 항목을 하나의 노드에 넣을 수 있다면, *형제 노드를 병합한다*:
그렇지 않고, 삭제로 인해 노드에 항목이 너무 적어졌지만 형제 노드와 병합할 수 없는 경우에는 *포인터를 재분배*한다:
###### 인덱스 파일 성능 저하 문제와 데이터 파일 성능 저하 문제의 해결
- 인덱스 파일 성능 저하 문제는 B+ 트리 인덱스를 사용하여 해결할 수 있다.
- 데이터 파일 성능 저하 문제는 B+ 트리 파일 구성 방식을 통해 해결된다.
###### B+ 트리 파일 구성
- B+ 트리 파일 구성에서는 리프 노드에 포인터 대신 실제 레코드를 저장한다.
- 리프 노드도 여전히 절반 이상 차 있어야 한다.
	- 레코드는 포인터보다 크기 때문에, 리프 노드에 저장할 수 있는 최대 레코드 수는 비리프 노드에서 포인터를 저장할 수 있는 수보다 적다.
###### B+ Tree 파일 구성에서 공간 활용을 개선하기 위해 하는 방법
•	공간 활용을 개선하기 위해 분할 및 병합 시 더 많은 형제 노드를 재분배에 참여시킨다.
•	가능한 한 분할/병합을 피하기 위해 2개의 형제 노드를 재분배에 포함시키는 방식은, 각 노드가 최소 ⌊2B/3⌋개의 항목을 갖도록 한다. (원래 2B가 꽉차있는 것을 3개로 나누었으므로)
###### B+ Tree 파일 구성에서 노드 분할의 비용 문제의 해결책, 장단점
secondary index에서 레코드 포인터 대신 primary index의 검색 키를 사용한다.
•	레코드를 찾기 위해 기본 인덱스를 한 번 더 탐색해야 한다.
	•	쿼리 비용은 증가하지만, 노드 분할 비용은 낮다.
•	primary index의 search key가 유일하지 않다면 record ID를 추가한다.
###### B Tree 인덱스 장점
•	동일한 B+-트리보다 적은 수의 트리 노드를 사용할 수 있다.
•	리프 노드에 도달하기 전에 검색 키 값을 찾는 것이 가능할 수 있다.
###### B Tree 인덱스 단점
•	전체 검색 키 값 중 일부만 조기 탐색 가능하다.
•	non leaf node가 더 커서 fan-out(가지 수)이 줄어들어 B+ 트리보다 깊이가 더 크다.
	•	삽입과 삭제가 B+-트리보다 더 복잡하다.
	•	구현이 B+-트리보다 더 어렵다.
###### 단일 속성에 대한 인덱스를 사용하여 질의를 처리할 수 있는 가능한 전략들:
1.	dept_name에 대한 인덱스를 사용하여 부서 이름이 “Finance”인 강사를 찾고, 이후 salary = 80000인지 검사한다. (Fincance인 강사가 적을 때 유리)
2.	salary에 대한 인덱스를 사용하여 급여가 80000인 강사를 찾고, 이후 dept_name = “Finance”인지 검사한다. (급여가 80000인 강사가 적을 때 유리)
3.	dept_name 인덱스를 사용하여 “Finance” 부서에 해당하는 모든 레코드 포인터를 찾고, salary 인덱스를 사용하여 급여가 80000인 레코드 포인터를 찾은 후, 두 포인터 집합의 교집합을 구한다.
###### composite search key란?
둘 이상의 속성을 포함하는 검색 키
###### Basic Steps in Query Processing
1. Parsing and translation
2. Optimization
3. Evaluation
![[Pasted image 20250529135105.png|300]]
###### 질의 비용의 측정
비용은 일반적으로 질의에 응답하는 데 걸리는 total elapsed time으로 측정된다.
###### 질의 비용의 predominant cost
disk access
###### disk access 측정 방법
•	읽은 블록 수 × 평균 블록 읽기 비용
•	쓴 블록 수 × 평균 블록 쓰기 비용
	• 블록 쓰기 비용은 블록 읽기 비용보다 크다.
		– 데이터가 성공적으로 쓰였는지 확인하기 위해 다시 읽기 때문이다.
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
