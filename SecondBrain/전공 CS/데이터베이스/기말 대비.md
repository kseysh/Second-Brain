###### Armstrong의 공리
•	만약 β ⊆ α 이면, α → β (반사성 reflexivity)
•	만약 α → β 이고 γ가 존재하면, γα → γβ (확장성 augmentation)
•	만약 α → β이고, β → γ이면, α → γ (추이성 transitivity)
•	이 규칙들은 다음과 같은 성질을 가진다:
•	sound (실제로 성립하는 함수적 종속성만 생성함)
•	complete (성립하는 모든 함수적 종속성을 생성할 수 있음)
###### Closure of Functional Dependencies
•	α → β이고 α → γ이면, α → βγ이다 (union)
•	α → βγ이면, α → β이고 α → γ이다 (decomposition)
•	α → β이고 γβ → δ이면, αγ → δ이다 (pseudotransitivity)
###### Attribute Closure의 활용
•	슈퍼키(superkey) 테스트:
	•	α⁺를 계산해서, α⁺가 R의 모든 속성을 포함하는지 확인
•	함수 종속성 테스트:
	•	α → β가 F⁺에 포함되는지 확인하려면, α⁺를 계산하고 β ⊆ α⁺인지 확인
	•	이 방법은 간단하고 효율적
•	F의 Closure 계산:
	•	R의 모든 부분집합 γ에 대해 γ⁺를 계산하고, γ⁺의 모든 부분집합 S에 대해 γ → S 형태의 함수 종속성을 출력
###### Lossless join Decomposition하는 법
•	R = (R₁, R₂)인 경우, 가능한 모든 관계 r에 대해
	•	![[IMG_5818D9CDA980-1.jpeg|100]]가 되어야 한다.
•	R을 R₁과 R₂로 분해했을 때 다음 중 하나라도 F⁺에 포함되면 Lossless-join Decomposition이다:
	•	R₁ ∩ R₂ → R₁
	•	R₁ ∩ R₂ → R₂
•	즉, R₁ ∩ R₂가 R₁ 또는 R₂의 슈퍼키이면 Lossless-join Decomposition가 된다.
###### decomposition이 dependency preserving이면
(F₁ ∪ F₂ ∪ … ∪ Fn)⁺ = F⁺
###### Lossless join에서 3NF와 BCNF의 차이
•	항상 3NF로 Lossless-join, 종속성 보존이 가능하다.
•	항상 BCNF로 Lossless-join은 가능하지만, Dependency Preservation은 항상 가능하지는 않다.
###### EM 모델에서의 Linear I/O
O(N/B) -> N개의 데이터를 B 블록 단위로 가져올 때의 시간 복잡도
###### Fixed-Length Records에서 레코드 i의 삭제 개선 방식
- 레코드 n을 i에 이동
- 이동하지 않고 삭제된 레코드들을 free list로 연결
- O(1) I/O 발생
###### Free List 관리 방법
사용되지 않는 레코드의 속성 공간을 포인터 저장에 사용한다
###### null bitmap 표현 방법
0000으로 1byte로 표현
###### 가변 길이 레코드 표현 방법
두 부분으로 구성
	•	고정 길이 속성을 저장하는 초기 부분
	•	가변 길이 속성 데이터
•	가변 속성은 (offset, length) 쌍으로 표현하고 실제 데이터는 고정 속성 뒤에 저장
•	null 값은 null-value 비트맵으로 표현
![[Pasted image 20250501144031.png|300]]
dept_name인 Comp. Sci를 알고 싶다면, dept_name은 세 번째 필드이므로 8로 가서 좌표값을 확인하고, 36부터 10만큼 읽는다. (가변 길이만 이렇게 하고, fixed length는 그냥 저장함)
null bitmap은 fixed length와 variable length사이에 넣어둔다.
###### Slotted Page Header에 저장되는 정보
record entry 수
block 내 free space의 끝 위치
각 레코드의 위치와 크기
###### 레코드 삭제시 블록 내에서 일어나는 일
레코드들은 페이지 내에서 이동 가능하며, 빈 공간 없이 연속되도록 유지되어야 하므로 한 레코드가 삭제되면 빈공간을 채우기 위해 block 안의 레코드를 모두 민다
이 때, 헤더의 항목은 반드시 갱신되어야 한다.
###### 포인터가 항상 Slotted Page Header에 있는 레코드에 대한 entry를 가리켜야 하는 이유
레코드가 재정렬되면 다른 곳에서 저장해두던 포인터의 값이 유효하지 않을 수 있으므로
###### 파일 내 레코드 구성 방법 힙/순차/해싱 특징
•	힙(Heap): 레코드를 공간이 있는 아무 곳에나 배치
	삽입이 빠름
	검색 느림
•	순차(Sequential): 레코드를 검색 키 값(보통 pk)에 따라 순서대로 저장
	- binary search로 빠른 검색 가능
	- 삽입 삭제 시 정렬 유지 비용있음
•	해싱(Hashing): 특정 속성에 대해 해시 함수를 적용하여 결과에 따라 파일의 블록 결정
	매우 빠른 검색/삽입
	해시 충돌 처리 필요
###### 버퍼와 버퍼 관리자
•	버퍼: 디스크 블록 복사본을 저장할 수 있는 메인 메모리 일부
•	버퍼 관리자: 메인 메모리의 버퍼 공간 할당을 담당하는 하위 시스템
###### 디스크 블록이 필요할 때 버퍼 관리자
프로그램은 디스크 블록이 필요할 때 버퍼 관리자에게 요청
1.	요청한 블록이 버퍼에 있으면 해당 메모리 주소 반환
2.	없으면 버퍼 공간을 할당함
•	공간 부족 시 다른 블록을 교체
•	교체되는 블록은 변경된 경우에만 디스크에 다시 기록
•	디스크에서 블록을 읽어 버퍼에 저장 후 메모리 주소 반환
###### LRU가 비효율적인 경우
반복 스캔이 많은 패턴에는 LRU가 비효율적
	예: 중첩 루프 방식으로 두 릴레이션 r, s를 조인할 때
###### pinned block 
디스크에 다시 기록되는 것이 허용되지 않는 메모리 블록
###### LRU vs. MRU
LRU: 가장 오래전에 사용된 블록을 가장 먼저 교체함
대부분의 운영체제에서 사용하는 기본적인 버퍼 교체 전략
과거의 접근 패턴을 바탕으로 미래 접근을 예측.
데이터베이스 쿼리는 종종 순차적 접근 패턴을 가지므로, 이러한 패턴을 활용해 예측 가능.

MRU: 가장 최근에 사용된 블록을 가장 먼저 교체함
- 현재 처리 중인 블록은 “pinned” 상태로 고정되며, 사용이 끝나면 고정이 해제되고 MRU 블록이 됨.
•	통계 기반 힌트 사용:
	•	버퍼 매니저는 통계 데이터를 활용해 어떤 블록이 자주 접근되는지를 판단 가능.
	•	예시: 데이터 딕셔너리는 자주 참조되므로, 메모리에 상주시켜두는 것이 좋음.
###### LRU 단점 해결방안
- 쿼리 옵티마이저가 접근 패턴에 대한 힌트를 제공하고, 이를 기반으로 **혼합 전략(mixed strategy)** 사용이 바람직.
###### 인덱스의 기본 유형 두 가지
1. Ordered indices (정렬 인덱스): 검색 키가 정렬된 순서로 저장됨
2. Hash indices (해시 인덱스): 해시 함수를 이용해 키가 “버킷”에 균일하게 분산됨
###### ordered index 종류
*ordered index*는 검색 키 값을 기준으로 정렬된 순서로 index 항목을 저장합니다. 예: 도서관 저자 색인

•	Primary index (기본 인덱스): 파일이 정렬된 순서대로 저장되어 있으며, 이 순서를 결정하는 검색 키를 가진 인덱스 (*clustering index*라고도 함)
	•	보통 기본 키가 검색 키지만, 반드시 그렇지는 않음
•	*Secondary index* (보조 인덱스): 파일의 순서와는 다른 순서로 검색 키를 정렬한 인덱스 (non-clustering index라고도 함)
•	*Index-sequential file*: 파일 자체는 특정 키 값 기준으로 정렬되어 있고, 그 키에 대한 인덱스가 존재하는 파일
###### Dense Index Files
파일 내 모든 검색 키 값에 대해 index record가 존재
###### Sparse Index Files
일부 검색 키 값에 대해서만 인덱스 레코드를 포함함
검색 키를 기준으로 레코드가 순차적으로 정렬되어 있을 때 사용 가능
###### Sparse Index File에서 키 값이 K인 레코드를 찾기 위해서는
– K보다 작은 검색 키 값 중 가장 큰 값을 가진 인덱스 레코드를 찾음
– 해당 인덱스 레코드가 가리키는 레코드부터 파일을 순차적으로 검색함
###### Sparse Index vs. Dense Index
Sparse Index: 공간을 덜 차지함 삽입/삭제 비용이 적다
Dense Index: 레코드 검색 속도가 빠르다
###### Sparse Index와 Dense Index의 좋은 절충안
해당 블록에서 가장 작은 검색 키 값에 대응하는, 파일의 각 블록마다 하나의 인덱스 항목을 가지는 Sparse Index
=> 어차피 DB는 block단위로 data를 가져오기 때문
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
###### Q
A
