## Basic Steps in Query Processing
1. Parsing and translation
2. Optimization
3. Evaluation
![[Pasted image 20250529135105.png|300]]
## 기본 단계: 최적화
질의 최적화(Query Optimization): 동일한 의미를 가지는 모든 평가 계획들 중에서 가장 비용이 적은 것을 선택한다.
비용은 데이터베이스 카탈로그의 통계 정보를 사용하여 추정한다.
• 예: 각 릴레이션의 튜플 수, 튜플 크기 등

이 장에서는 다음을 다룬다:
	•	질의 비용 측정 방법
	•	관계 대수 연산을 평가하는 알고리즘들
## 질의 비용의 측정
비용은 일반적으로 질의에 응답하는 데 걸리는 total elapsed time으로 측정된다.
	많은 요인들이 시간 비용에 기여한다:
		• 디스크 접근, CPU, 심지어 네트워크 통신 등
일반적으로 disk access가 predominant cost이며, 상대적으로 추정하기 쉽다.
다음 요소를 고려하여 측정한다:
	•	읽은 블록 수 × 평균 블록 읽기 비용
	•	쓴 블록 수 × 평균 블록 쓰기 비용
		• 블록 쓰기 비용은 블록 읽기 비용보다 크다.
			– 데이터가 성공적으로 쓰였는지 확인하기 위해 다시 읽기 때문이다.

여러 알고리즘들은 추가 버퍼 공간을 사용하여 디스크 I/O를 줄일 수 있다.
	사용 가능한 실질 메모리 양은 실행 중인 다른 질의 및 OS 프로세스에 따라 달라지며, 실행 시에만 알 수 있다.
		• 일반적으로는 최악의 경우를 가정하여, 연산에 필요한 최소 메모리만 사용 가능하다고 본다.
필요한 데이터가 이미 버퍼에 있을 수 있어 디스크 I/O를 피할 수 있다.
## 요약: I/O 복잡도 모델
간단하게 하기 위해 디스크에서 전송된 블록 수만 사용한다.
	•	M: 메모리 크기, 즉 주 메모리에 적재할 수 있는 튜플 수
	•	B: 블록 크기, 즉 블록 하나에 들어갈 수 있는 튜플 수
	•	N: 릴레이션 내 튜플 수 (예: Ns, Nr 등)
	•	선형 I/O: O(N/B)
	•	로그 I/O: O(log<sub>B</sub> N)
CPU 비용과 탐색 비용은 단순화를 위해 무시한다.
	실제 시스템은 CPU 비용도 고려한다.
## 선택 연산(Selection Operation)
파일 스캔
알고리즘 A1 (선형 검색): 각 파일 블록을 스캔하고 모든 레코드가 선택 조건을 만족하는지 검사
	•	I/O 비용 = O(N/B), 자명함
	•	선형 검색은 다음과 무관하게 적용 가능
		• 선택 조건
		• 파일 내 레코드 정렬 여부
		• 인덱스 존재 여부
메모리가 커서 M > N인 경우에도,
	•	여전히 N개의 튜플(즉, N/B 블록)을 메모리로 적재해야 한다.
## 인덱스를 사용하는 선택
인덱스 스캔 – 인덱스를 사용하는 탐색 알고리즘
	•	선택 조건은 인덱스의 검색 키여야 함
A2 (primary B+ tree index, equality on key)
	•	해당 등치 조건을 만족하는 단일 레코드 검색
	•	정확한 탐색
	•	I/O 비용 = O(log<sub>B</sub> N)
A3 (primary B+ tree index, equality on non-key)
	•	같은 검색 키 값을 가진 다수 레코드 검색
	•	T = 검색 키 값을 가진 레코드 수 (연속된 공간에 위치해 있으므로 Block 단위로 가져오면 T/B)
	•	I/O 비용 = O(log<sub>B</sub> N + T/B)
## 보조 인덱스를 사용하는 선택
A4 (보조 인덱스, 비키 속성의 등치 조건)
	•	검색 키가 후보 키일 경우: <u>단일 레코드</u> 검색
		• I/O 비용 = O(logB N)
	•	검색 키가 후보 키가 아닐 경우: <u>다수 레코드</u> 검색
		• T개의 레코드가 각각 다른 블록에 있을 수 있음
		• 비용 = I/O 비용 = O(logB N + T) 
			– 매우 비쌀 수 있다!
## 비교 연산이 포함된 선택
σA≤V(r) 또는 σA≥V(r) 형태의 선택은 선형 파일 스캔 또는 인덱스를 사용하여 구현 가능하다.

A5 (기본 인덱스, 비교) – 릴레이션이 A 속성 기준으로 정렬된 경우
	• σA≥V(r): 인덱스로 v 이상인 첫 튜플 찾고, 그 지점부터 릴레이션을 순차 스캔, O(log<sub>B</sub>N + T/B)
	• σA≤V(r): v보다 큰 첫 튜플 전까지 순차 스캔; 인덱스 사용 안 함  O(T/B)

A6 (보조 인덱스, 비교)
	• σA≥V(r): 인덱스에서 v 이상인 첫 항목 찾고, 그 지점부터 인덱스를 순차 스캔하여 레코드 포인터 획득
		• O(log<sub>B</sub>N + T)
	• σA≤V(r): 인덱스 리프 페이지를 스캔하여 포인터 획득; 첫 항목이 v보다 클 때까지
		• O(T) of O(N/B)
	• 두 경우 모두 포인터가 가리키는 레코드를 검색
		– 레코드마다 I/O 발생
		– 선형 스캔이 더 쌀 수 있음 → 왜일까?
## 정렬(Sorting)

정렬을 하는 이유?
	• 조인과 같은 많은 관계 연산은 입력 릴레이션이 정렬되어 있을 때 효율적으로 수행 가능하다.
• 인덱스를 만든다고 해도 (보통 보조 인덱스), 실제 릴레이션이 물리적으로 정렬된 것은 아님
• M > N이라면 메모리에 적합하므로, 퀵소트 같은 기술 사용 가능
• 그렇지 않은 경우, 외부 병합 정렬(external merge sort)이 적합
## 외부 병합 정렬(External Merge Sort)
M/B는 블록 단위로 본 메모리 크기라 하자.
1.	정렬 런(run) 생성. i = 0부터 시작
	반복:
		(a) M/B 블록을 읽어 메모리에 적재
		(b) 메모리 내 데이터를 정렬
		(c) 정렬된 데이터를 Ri로 출력 후 i 증가
	최종적으로 i = N이 될 때까지
2.	런 병합
→ 런 수 = O(N/M)

런 수를 K라고 하자 (즉, O(N/M))
2. 런을 병합(K-way merge), 가정: K < M/B
	1.	입력 런마다 하나씩 K개의 블록을 메모리에 버퍼로 할당하고, 출력용 버퍼 1개 사용
	2.	반복
		① 모든 버퍼 페이지 중 가장 작은 레코드 선택
		② 출력 버퍼에 기록. 버퍼가 가득 차면 디스크에 기록
		③ 해당 입력 버퍼에서 레코드 삭제
			•	버퍼가 비면 해당 런의 다음 블록 로드
	3.	모든 입력 버퍼가 빌 때까지 반복
K ≥ M/B이면 병합을 여러 번 해야 함
	• 매번 M/B - 1개의 런을 병합
	• 병합 시 런 개수는 M/B - 1만큼 줄고, 길이는 그만큼 길어짐
		예: M/B=11, 런이 90개 → 병합 1회 후 9개의 런, 각 런은 기존보다 10배 김
→ 모든 런이 하나로 병합될 때까지 반복
![[Pasted image 20250602155811.png|300]]

최악의 경우 비용 분석
	•	정렬 런 생성
		• 런 수 = O(N/M)
		• 각 런의 블록 수 = O(M/B)
		• I/O 비용 = O(N/B), 선형
	•	병합 1단계
		• 병합할 런 수 = O(N/M)
		• 각 런의 블록 수 = O(M/B)
		• I/O 비용 = O(N/B)
	•	병합 2단계
		• 병합할 런 수 = O((N/M)/(M/B)) = O(BN/M²)
		• 각 런의 블록 수 = O((M/B)²) = O(M²/B²)
		• I/O 비용 = O(N/B)
	•	병합 i단계
		• 여전히 선형 I/O

최악의 경우 비용 분석
	따라서 각 단계(pass)는 O(N/B), 즉 선형적인 입출력을 필요로 한다.
	총 I/O 양은 단계 수에 O(N/B)를 곱한 값으로 결정된다.
병합 단계(merging pass)의 수:
	• O(logM/B(N/M)) 왜 그런가?
전체 I/O는 다음과 같이 표현된다:
	• O((N/B) logM/B(N/B))
이는 사실 메모리 내 정렬의 O(n log n) 복잡도에 해당하는 것으로,
	즉 최적의 복잡도를 의미한다.
#### 여기까지 정리
## 조인(Join)
조인 질의를 어떻게 처리하고 각 조인 알고리즘의 비용을 어떻게 측정하는가
## 조인 연산
조인을 구현하는 여러 가지 알고리즘이 존재한다:
	•	중첩 루프 조인(Nested-loop join)
	•	블록 중첩 루프 조인(Block nested-loop join)
	•	인덱스 중첩 루프 조인(Indexed nested-loop join)
	•	병합 조인(Merge-join)
	•	해시 조인(Hash-join)

선택은 비용 추정에 따라 이루어진다.

예제에서는 다음 정보를 사용:
	•	student 릴레이션: 레코드 수 5,000 (Nr), 블록 수 100 (Nr/B)
	•	takes 릴레이션: 레코드 수 10,000 (Ns), 블록 수 400 (Ns/B)
## Nested Loop Join
θ 조인을 계산하려면:

```
for each tuple tr in r do
  for each tuple ts in s do
    조건 θ를 만족하는지 검사
    만족하면 tr ⋈ ts를 결과에 추가
  end
end
```
r은 외부 릴레이션(outer relation), s는 내부 릴레이션(inner relation)이다.
인덱스 없이 사용할 수 있으며, 어떤 조인 조건에서도 사용 가능하다.
모든 튜플 쌍을 검사하므로 비용이 크다.

최악의 경우, 각 릴레이션의 블록 하나만 메모리에 적재 가능할 때 I/O 비용은
	•	O(Nr/B + Nr × Ns/B) ≈ O(N²/B)

작은 릴레이션이 메모리에 전부 적재 가능하면 그것을 내부 릴레이션으로 사용:
	•	비용: O(Nr/B + Ns/B) ≈ O(N/B)

메모리가 제한된 경우 실제 비용 추정은 다음과 같다:
	•	student를 외부 릴레이션으로: 5,000 × 400 + 100 = 2,000,100 블록 전송
	•	takes를 외부 릴레이션으로: 10,000 × 100 + 400 = 1,000,400 블록 전송
	•	작은 릴레이션(student)이 전부 메모리에 적재 가능하다면 비용은 500 블록 전송

→ 블록 중첩 루프 조인이 더 나음.

⸻

블록 중첩 루프 조인
내부 릴레이션의 모든 블록이 외부 릴레이션의 모든 블록과 조인되는 중첩 루프 변형
```
for each block Br in r do
  for each block Bs in s do
    for each tuple tr in Br do
      for each tuple ts in Bs do
        조건 만족 시 tr ⋈ ts를 결과에 추가
      end
    end
  end
end
```
•	최악의 경우: O(Nr/B + Nr/B × Ns/B) ≈ O(N²/B²)
	→ 내부 릴레이션의 각 블록은 외부 블록 수만큼 읽힘
•	최상의 경우: O(Nr/B + Ns/B) ≈ O(N/B)
개선 사항:
	•	외부 릴레이션을 M/B - 2 블록 단위로 묶고, 나머지 2블록은 내부 릴레이션 및 출력 버퍼로 사용
→ 비용: O(Nr/B + Nr/M × Ns/B) ≈ O(N²/BM)
	•	equi-join에서 내부 릴레이션 속성이 키이면, 첫 번째 매칭 시 루프 종료
	•	버퍼에 남은 블록을 최대한 활용하기 위해 내부 루프를 앞뒤로 번갈아 스캔
	•	내부 릴레이션에 인덱스가 있다면 활용 (다음 설명)
## 인덱스 중첩 루프 조인 (Indexed Nested-Loop Join)
(B+-트리) 인덱스 조회는, 조인이 등가 조인(equi-join) 또는 자연 조인(natural join)이고
내부 릴레이션(inner relation)의 조인 속성에 인덱스가 존재하는 경우, 파일 스캔을 대체할 수 있다.
• 조인을 수행하기 위해 인덱스를 새로 구축할 수도 있다.
외부 릴레이션 r의 각 튜플 tr에 대해, 인덱스를 이용하여 튜플 tr과 조인 조건을 만족하는 s의 튜플들을 조회한다.

최악의 경우: 버퍼에 r의 페이지 한 개만 적재 가능하고, r의 각 튜플마다 s에 대해 인덱스 조회를 수행해야 한다.
조인의 비용: O(Nr/B + Nr logB Ns) = O(Nr logB Ns) ≈ O(N logB N)

조인 속성에 대해 r과 s 모두 인덱스를 가지고 있는 경우, 튜플 수가 더 적은 릴레이션을 외부 릴레이션으로 사용하는 것이 좋다.
	즉, O(Nr logB Ns)와 O(Ns logB Nr) 중 더 나은 쪽을 선택.
## 중첩 루프 조인 비용 예시
student와 takes 릴레이션 간 조인을 수행하고, student를 외부 릴레이션으로 사용한다고 가정한다.
takes 릴레이션은 ID 속성에 대해 B+-트리 기본 인덱스를 갖고 있으며, 인덱스 노드마다 20개의 엔트리를 포함한다고 하자.
takes는 총 10,000개의 튜플을 가지고 있으며, 이에 따라 트리의 높이는 4이고, 실제 데이터를 찾기 위해 추가로 한 번 더 접근이 필요하다.
student는 총 5,000개의 튜플을 가지고 있다.

Block Nested Loops Join 비용
	400 * 100 + 100 = 40,100 블록 전송
		• 메모리가 최악의 경우라고 가정
		• 메모리가 더 많으면 비용은 크게 감소할 수 있음
Indexed Nested Loops Join 비용
	100 + 5000 * 5 = 25,100 블록 전송
	CPU 비용도 block nested loops join보다 적을 가능성이 높다.
## 병합 조인 (Merge-Join)
Merge-Join (병합 조인)
1.	두 릴레이션을 조인 속성에 대해 정렬한다 (이미 정렬되어 있다면 생략 가능).
2.	정렬된 두 릴레이션을 병합하여 조인을 수행한다.
	1.	조인 단계는 정렬-병합(sort-merge) 알고리즘의 병합 단계와 유사하다.
	2.	주요 차이점은 조인 속성에 중복 값이 있는 경우의 처리 — 동일한 값이 있는 모든 튜플 쌍을 매칭해야 한다.
	3.	자세한 알고리즘은 교재 참조.
•	등가 조인(equi-join)과 자연 조인(natural join)에만 사용 가능
•	조인 속성 값이 같은 모든 튜플이 메모리에 적재될 수 있다고 가정하면, 각 블록은 한 번만 읽으면 된다.
•	따라서 merge-join의 I/O 비용은 O(Nr/B + Ns/B) ≈ O(N/B)
	•	단, 릴레이션이 정렬되어 있지 않다면 정렬 비용이 추가된다. (이 정렬 비용은 앞서 설명된 바 있음)

하이브리드 병합 조인 (Hybrid Merge-Join)
•	한 릴레이션은 정렬되어 있고, 다른 릴레이션은 조인 속성에 대한 보조 B+-트리 인덱스를 가진 경우
1.	정렬된 릴레이션과 인덱스의 리프 노드 항목을 병합한다.
2.	그 결과를 비정렬 릴레이션 튜플의 주소로 정렬한다.
3.	비정렬 릴레이션을 실제 물리적 주소 순서로 스캔하면서 병합하고, 주소를 실제 튜플로 대체한다.
→ 순차적 스캔이 랜덤 접근보다 훨씬 효율적이다.
## Hash-Join (해시 조인)
![[Pasted image 20250602160719.png|200]]
•	등가 조인(equi-join) 및 자연 조인(natural join)에 적용 가능
•	해시 함수 h는 두 릴레이션의 튜플들을 파티션하는 데 사용됨
•	h는 조인 속성(JoinAttrs)의 값을 {0, 1, …, H}로 매핑함
	•	여기서 JoinAttrs는 r과 s에서 자연 조인에 사용되는 공통 속성들을 의미함
		•	r₀, r₁, …, rᴴ는 r 릴레이션 튜플들의 파티션을 나타냄
			•	각 튜플 tᵣ ∈ r은 조인 속성에 대해 h(tᵣ[JoinAttrs]) = i인 rᵢ 파티션에 배치됨
		•	s₀, s₁, …, sᴴ는 s 릴레이션 튜플들의 파티션을 나타냄
			•	각 튜플 tₛ ∈ s는 조인 속성에 대해 h(tₛ[JoinAttrs]) = i인 sᵢ 파티션에 배치됨
r 릴레이션의 ri에 있는 튜플들은 si에 있는 s 튜플들과만 비교하면 된다.
다른 파티션에 있는 s 튜플들과는 비교할 필요가 없다. 그 이유는 다음과 같다:
	•	조인 조건을 만족하는 r 튜플과 s 튜플은 조인 속성 값이 같아야 한다.
	•	이 값이 해시되어 어떤 값 i가 되었다면, 그 r 튜플은 반드시 ri에 있어야 하고, 해당 s 튜플은 반드시 si에 있어야 한다.
## 해시 조인 알고리즘
r과 s의 해시 조인은 다음과 같이 계산된다.
1.	해시 함수 h를 사용하여 릴레이션 s를 파티션한다.
릴레이션을 파티션할 때, 각 파티션에 대해 하나의 메모리 블록이 출력 버퍼로 예약된다.
2.	릴레이션 r도 같은 방식으로 파티션한다.
3.	각 i에 대해 다음을 수행한다:
		(a) si를 메모리에 적재하고, 조인 속성을 이용해 인메모리 해시 인덱스를 생성한다.
		이 인덱스는 앞서 사용한 h와는 다른 해시 함수를 사용한다.
		(b) ri의 튜플들을 디스크에서 하나씩 읽는다. 각 튜플 tr에 대해, 인메모리 해시 인덱스를 사용하여 si에서 일치하는 튜플 ts를 찾는다.
		이들의 속성을 연결하여 출력한다.

릴레이션 s는 빌드 입력(build input), r은 프로브 입력(probe input)이라 부른다.

H와 해시 함수 h의 설정 조건
	각 si가 메모리에 적재 가능하도록 H와 h를 선택한다.
	일반적으로 H는 Θ(Ns/M)로 설정한다.
	프로브 릴레이션의 각 ri는 메모리에 적재될 필요는 없다.
재귀적 파티셔닝이 필요한 경우
	만약 파티션 수 H가 메모리 페이지 수 M/B보다 크다면 재귀적 파티셔닝이 필요하다.
	이 경우 H-way 파티셔닝 대신, s를 M/B – 1개의 파티션으로 나누고, 이를 다시 다른 해시 함수로 파티셔닝한다.
	r도 동일한 방식으로 파티셔닝한다.

※ 이 방식은 드물게 필요하다. 예를 들어, 블록 크기가 4KB이고 메모리가 2MB일 경우
1GB 이하의 릴레이션은 재귀 파티셔닝 없이 처리 가능하다.
메모리가 12MB이면 36GB 이하의 릴레이션도 처리 가능하다.
## 오버플로우 처리
어떤 파티션이 다른 파티션들보다 훨씬 많은 튜플을 포함하고 있다면, 이를 skewed 되었다고 한다.

si가 메모리에 적재되지 못하는 경우 해시 테이블 오버플로우가 발생한다.
원인은 다음과 같다:
	•	조인 속성 값이 같은 s 튜플이 많을 경우
	•	나쁜 해시 함수 사용

오버플로우 해결 방법은 빌드 단계에서 수행할 수 있다:
	•	si를 다시 다른 해시 함수로 파티셔닝한다.
	•	ri도 동일하게 파티셔닝해야 한다.

오버플로우 회피는 빌드 단계에서 오버플로우가 발생하지 않도록 신중하게 파티셔닝을 수행하는 것이다.
예: 빌드 릴레이션을 더 많은 파티션으로 나누고, 나중에 다시 결합하는 방식

※ 그러나 이 두 방법 모두 중복 튜플이 많은 경우에는 잘 작동하지 않는다.
대안: 오버플로우된 파티션에 대해서는 블록 중첩 루프 조인을 사용한다.
## 해시 조인의 비용
•	재귀 파티셔닝이 필요 없는 경우:
	•	한 번의 파티셔닝 비용: O(Nr/B + Ns/B)
	•	조인 비용: O(Nr/B + Ns/B + H), 여기서 H는 파티션(버킷)의 수
	•	왜 H개의 블록 전송이 필요한가?
		→ 일부 파티션이 부분적으로만 채워질 수 있고, 각 파티션당 최대 하나의 부분 블록이 생긴다.
따라서 최대 H개의 부분 블록이 생길 수 있다.
	•	하지만 일반적으로 H는 Nr/B + Ns/B보다 훨씬 작기 때문에,
전체 비용은 O(Nr/B + Ns/B) ≈ O(N/B)로 본다.
•	재귀 파티셔닝이 필요한 경우:
	•	빌드 릴레이션 s의 각 파티션이 M/B 블록 미만이 되도록 만들기 위해 필요한 파티셔닝 단계 수는
O(logM/B(Ns/B))
		•	외부 병합 정렬(External Merge Sort)과 유사
	•	빌드 릴레이션으로는 더 작은 릴레이션을 선택하는 것이 좋다
	•	총 비용 추정: O((Nr/B + Ns/B) * logM/B(Ns/B)) ≈ O(N/B logM/B(N/B))
•	만약 빌드 입력 전체가 메모리에 적재 가능하다면, 파티셔닝이 필요 없다.
	•	이 경우 비용 추정은 O(Nr/B + Ns/B) ≈ O(N/B)
## 해시 조인의 비용 예시
릴레이션: instructor, teaches
메모리 크기: 20 블록
instructor는 100 블록, teaches는 400 블록

instructor를 빌드 입력으로 사용. 이를 5개의 파티션으로 나누고 각 파티션은 20 블록.
→ 한 번의 패스로 파티셔닝 가능

teaches도 마찬가지로 5개의 파티션, 각 파티션은 80 블록.
→ 역시 한 번의 패스로 파티셔닝 가능

따라서 부분적으로 채워진 블록을 무시하고 계산할 경우, 총 비용:
3 × (100 + 400) = 1500 블록 전송
	•	즉, 실제로는 3회의 선형 입출력이 필요함:
	1.	두 릴레이션을 완전히 읽는 것
	2.	읽은 것을 다시 쓰는 것 (→ 이 두 번은 파티셔닝을 위한 작업)
	3.	빌드와 프로빙을 위한 마지막 작업
## 복합 조인

합성 조건을 가지는 조인:
r θ1 ∧ θ2 ∧ ... ∧ θn s
	•	중첩 루프나 블록 중첩 루프 사용
	•	또는 간단한 조인 r θi s를 수행하고
중간 결과에서 나머지 조건 θ1 ∧ ... ∧ θi–1 ∧ θi+1 ∧ ... ∧ θn을 만족하는 튜플만 선택

선택 조건이 OR인 경우:
r θ1 ∨ θ2 ∨ ... ∨ θn s
	•	중첩 루프/블록 중첩 루프 사용 가능
	•	또는 각각의 조인 결과를 구해서 합집합으로 계산
(r θ1 s) ∪ (r θ2 s) ∪ ... ∪ (r θn s)

⸻

기타 연산들

중복 제거는 정렬 또는 해싱을 통해 구현 가능
	•	정렬 시 중복 튜플은 연속되므로 하나만 남기고 나머지 삭제
	•	최적화: 외부 정렬 병합 중간 단계나 정렬 실행 시 중복 제거 가능
	•	해싱도 유사하게 동작 → 같은 버킷에 들어오므로 중복 처리 가능

프로젝션 (Projection):
	•	각 튜플에 대해 프로젝션 수행 후
	•	중복 제거 수행

⸻

집계 연산 (Aggregation)
	•	중복 제거와 유사하게 구현 가능
	•	정렬 또는 해싱을 통해 동일 그룹 튜플들을 모은 뒤 집계 함수 적용
	•	최적화: 실행 중 또는 병합 단계에서 부분 집계 값을 누적
	•	count, min, max, sum: 현재까지 튜플들을 기반으로 집계 유지
	•	avg: sum과 count 유지 → 마지막에 sum / count

⸻

집합 연산 (Set Operations)

(합집합 ∪, 교집합 ∩, 차집합 –)
→ 정렬 후 merge-join 변형 또는 해시 조인 변형 사용 가능

예: 해시를 사용한 집합 연산
	1.	동일한 해시 함수로 r, s를 파티션
	2.	각 파티션 i에 대해:

	•	∪ 연산
	1.	ri에 해시 인덱스 생성
	2.	si의 튜플을 인덱스에 추가 (이미 없는 경우만)
	3.	인덱스에 있는 튜플을 결과에 추가
	•	∩ 연산
	1.	ri에 해시 인덱스 생성
	2.	si의 튜플이 인덱스에 있으면 결과에 추가
	•	– 연산
	1.	si의 튜플이 인덱스에 있으면 제거
	2.	인덱스에 남은 튜플들을 결과에 추가

⸻

식(expression) 평가

지금까지는 개별 연산 알고리즘만 살펴보았음
전체 **식 트리(expression tree)**를 평가하기 위한 대안:
	1.	구현 저장 방식(Materialization)

	•	각 연산의 결과를 디스크에 저장한 뒤 다음 연산에 사용

	2.	파이프라이닝(Pipelining)

	•	한 연산이 실행되는 중에도 결과 튜플을 상위 연산에 바로 전달

⸻

Materialization (저장 기반 평가)
	•	가장 하위 연산부터 하나씩 평가
	•	중간 결과를 임시 릴레이션에 저장
예: 아래 식에 대해

σbuilding = "Watson"(department)
⋈ instructor
→ name 프로젝션

	•	부서 필터 결과 저장 → instructor와 조인 결과 저장 → 최종 결과 저장

항상 적용 가능하지만,
→ 디스크 쓰기/읽기 비용이 매우 클 수 있음
	•	우리의 연산 비용 공식은 디스크 쓰기 비용을 무시함
→ 전체 비용 = 개별 연산의 비용 합 + 디스크에 중간 결과 쓰는 비용

더블 버퍼링:
	•	각 연산에 2개의 출력 버퍼 사용
	•	한쪽이 가득 차면 디스크에 쓰는 동안 다른 쪽은 계속 사용
→ 쓰기와 계산을 겹쳐서 실행 시간 단축

⸻

Pipelining (파이프라이닝 평가)
	•	여러 연산을 동시에 수행
	•	한 연산의 결과를 바로 다음 연산에 전달
예:

σbuilding = "Watson"(department)
→ join
→ projection

→ 중간 결과 저장 없이 바로 상위 연산에 전달
	•	Materialization보다 훨씬 효율적: 디스크에 임시 릴레이션 저장 불필요
	•	단, 정렬이나 해시 조인과 같은 연산은 중간 결과 없이는 불가능

효과적 파이프라이닝 조건:
	•	연산 알고리즘이 입력 튜플을 받는 즉시 결과 튜플을 생성할 수 있어야 함

⸻

파이프라이닝 실행 방식
	1.	수요 기반 (demand driven / lazy evaluation)
	•	시스템이 최상위 연산에서 다음 튜플을 요청
	•	각 연산이 자식 연산에 요청
	•	중간 상태를 유지해 다음 호출 시 어디까지 진행했는지 기억해야 함
	2.	생산자 기반 (producer-driven / eager pipelining)
	•	연산이 결과 튜플을 생성하여 부모에게 전달
	•	연산 간 버퍼 유지
	•	자식 연산이 버퍼에 결과 저장
	•	부모 연산이 버퍼에서 가져감
	•	버퍼가 가득 차면 자식은 대기
	•	시스템은 출력 버퍼에 공간이 있는 연산을 우선 실행

다른 이름: Pull (수요 기반), Push (생산자 기반) 모델

⸻

수요 기반 파이프라이닝 구현

각 연산은 **이터레이터(iterator)**로 구현되며 다음 연산 제공:
	•	open()
	•	예: 파일 스캔 → 파일 시작 위치로 초기화
	•	예: 병합 조인 → 릴레이션 정렬, 정렬 시작점 저장
	•	next()
	•	예: 파일 스캔 → 다음 튜플 출력, 포인터 이동
	•	예: 병합 조인 → 이전 상태에서 이어서 결과 찾고 포인터 상태 저장
	•	close()

⸻

파이프라이닝 연산 알고리즘

일부 연산은 블로킹 연산(blocking operation)
→ 모든 입력 튜플이 준비될 때까지 결과 생성 불가
예: 정렬, 해시 조인
→ 입력을 받는 도중에는 결과를 생성할 수 없음
→ 중간 결과를 디스크에 써야 함

예:
	•	병합 조인 (입력이 정렬되지 않은 경우)
	•	해시 조인

→ 이들 연산은 파이프라이닝에 적합하지 않음.