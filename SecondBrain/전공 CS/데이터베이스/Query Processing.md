## Basic Steps in Query Processing
1. Parsing and translation
2. Optimization
3. Evaluation
![[Pasted image 20250529135105.png|300]]
## 기본 단계: 최적화
질의 최적화(Query Optimization): 동일한 의미를 가지는 모든 평가 계획들 중에서 가장 비용이 적은 것을 선택한다.
비용은 데이터베이스 카탈로그의 통계 정보를 사용하여 추정한다.
• 예: 각 릴레이션의 튜플 수, 튜플 크기 등

이 장에서는 다음을 다룬다:
	•	질의 비용 측정 방법
	•	관계 대수 연산을 평가하는 알고리즘들
## 질의 비용의 측정
비용은 일반적으로 질의에 응답하는 데 걸리는 전체 경과 시간으로 측정된다.
	많은 요인들이 시간 비용에 기여한다:
		• 디스크 접근, CPU, 심지어 네트워크 통신 등
일반적으로 디스크 접근이 주요 비용 요소이며, 상대적으로 추정하기 쉽다.
다음 요소를 고려하여 측정한다:
	•	읽은 블록 수 × 평균 블록 읽기 비용
	•	쓴 블록 수 × 평균 블록 쓰기 비용
		• 블록 쓰기 비용은 블록 읽기 비용보다 크다.
			– 데이터가 성공적으로 쓰였는지 확인하기 위해 다시 읽기 때문이다.
여러 알고리즘들은 추가 버퍼 공간을 사용하여 디스크 I/O를 줄일 수 있다.
	사용 가능한 실질 메모리 양은 실행 중인 다른 질의 및 OS 프로세스에 따라 달라지며, 실행 시에만 알 수 있다.
		• 일반적으로는 최악의 경우를 가정하여, 연산에 필요한 최소 메모리만 사용 가능하다고 본다.
필요한 데이터가 이미 버퍼에 있을 수 있어 디스크 I/O를 피할 수 있다.
## 요약: I/O 복잡도 모델
간단하게 하기 위해 디스크에서 전송된 블록 수만 사용한다.
	•	M: 메모리 크기, 즉 주 메모리에 적재할 수 있는 튜플 수
	•	B: 블록 크기, 즉 블록 하나에 들어갈 수 있는 튜플 수
	•	N: 릴레이션 내 튜플 수 (예: Ns, Nr 등)
	•	선형 I/O: O(N/B)
	•	로그 I/O: O(logB N)
CPU 비용과 탐색 비용은 단순화를 위해 무시한다.
	실제 시스템은 CPU 비용도 고려한다.
## 선택 연산(Selection Operation)
파일 스캔
알고리즘 A1 (선형 검색): 각 파일 블록을 스캔하고 모든 레코드가 선택 조건을 만족하는지 검사
	•	I/O 비용 = O(N/B), 자명함
	•	선형 검색은 다음과 무관하게 적용 가능
		• 선택 조건
		• 파일 내 레코드 정렬 여부
		• 인덱스 존재 여부
메모리가 커서 M > N인 경우에도,
	•	여전히 N개의 튜플(즉, N/B 블록)을 메모리로 적재해야 한다.
## 인덱스를 사용하는 선택
인덱스 스캔 – 인덱스를 사용하는 탐색 알고리즘
	•	선택 조건은 인덱스의 검색 키여야 함
A2 (기본 B+트리 인덱스, 키에 대한 등치 조건)
	•	해당 등치 조건을 만족하는 단일 레코드 검색
	•	정확한 탐색
	•	I/O 비용 = O(logB N)
A3 (기본 B+트리 인덱스, 비키 속성의 등치 조건)
	•	같은 검색 키 값을 가진 다수 레코드 검색
	•	T = 검색 키 값을 가진 레코드 수
	•	I/O 비용 = O(logB N + T/B)
## 보조 인덱스를 사용하는 선택
A4 (보조 인덱스, 비키 속성의 등치 조건)
	•	검색 키가 후보 키일 경우: 단일 레코드 검색
		• I/O 비용 = O(logB N)
	•	검색 키가 후보 키가 아닐 경우: 다수 레코드 검색
		• T개의 레코드가 각각 다른 블록에 있을 수 있음
		• 비용 = I/O 비용 = O(logB N + T)
			– 매우 비쌀 수 있다!
## 비교 연산이 포함된 선택
σA≤V(r) 또는 σA≥V(r) 형태의 선택은 선형 파일 스캔 또는 인덱스를 사용하여 구현 가능하다.

A5 (기본 인덱스, 비교) – 릴레이션이 A 속성 기준으로 정렬된 경우
	• σA≥V(r): 인덱스로 v 이상인 첫 튜플 찾고, 그 지점부터 릴레이션을 순차 스캔
	• σA≤V(r): v보다 큰 첫 튜플 전까지 순차 스캔; 인덱스 사용 안 함

A6 (보조 인덱스, 비교)
	• σA≥V(r): 인덱스에서 v 이상인 첫 항목 찾고, 그 지점부터 인덱스를 순차 스캔하여 레코드 포인터 획득
	• σA≤V(r): 인덱스 리프 페이지를 스캔하여 포인터 획득; 첫 항목이 v보다 클 때까지
	• 두 경우 모두 포인터가 가리키는 레코드를 검색
		– 레코드마다 I/O 발생
		– 선형 스캔이 더 쌀 수 있음 → 왜일까?
## 정렬(Sorting)

정렬을 하는 이유?
	• 조인과 같은 많은 관계 연산은 입력 릴레이션이 정렬되어 있을 때 효율적으로 수행 가능하다.
• 인덱스를 만든다고 해도 (보통 보조 인덱스), 실제 릴레이션이 물리적으로 정렬된 것은 아님
• M > N이라면 메모리에 적합하므로, 퀵소트 같은 기술 사용 가능
• 그렇지 않은 경우, 외부 병합 정렬(external merge sort)이 적합
## 외부 병합 정렬(External Merge Sort)
M/B는 블록 단위로 본 메모리 크기라 하자.
1.	정렬 런(run) 생성. i = 0부터 시작
	반복:
		(a) M/B 블록을 읽어 메모리에 적재
		(b) 메모리 내 데이터를 정렬
		(c) 정렬된 데이터를 Ri로 출력 후 i 증가
	최종적으로 i = N이 될 때까지
2.	런 병합
→ 런 수 = O(N/M)

런 수를 K라고 하자 (즉, O(N/M))
2. 런을 병합(K-way merge), 가정: K < M/B
	1.	입력 런마다 하나씩 K개의 블록을 메모리에 버퍼로 할당하고, 출력용 버퍼 1개 사용
	2.	반복
		① 모든 버퍼 페이지 중 가장 작은 레코드 선택
		② 출력 버퍼에 기록. 버퍼가 가득 차면 디스크에 기록
		③ 해당 입력 버퍼에서 레코드 삭제
			•	버퍼가 비면 해당 런의 다음 블록 로드
	3.	모든 입력 버퍼가 빌 때까지 반복
K ≥ M/B이면 병합을 여러 번 해야 함
	• 매번 M/B - 1개의 런을 병합
	• 병합 시 런 개수는 M/B - 1만큼 줄고, 길이는 그만큼 길어짐
		예: M/B=11, 런이 90개 → 병합 1회 후 9개의 런, 각 런은 기존보다 10배 김
→ 모든 런이 하나로 병합될 때까지 반복
![[Pasted image 20250602155811.png|300]]

최악의 경우 비용 분석
	•	정렬 런 생성
		• 런 수 = O(N/M)
		• 각 런의 블록 수 = O(M/B)
		• I/O 비용 = O(N/B), 선형
	•	병합 1단계
		• 병합할 런 수 = O(N/M)
		• 각 런의 블록 수 = O(M/B)
		• I/O 비용 = O(N/B)
	•	병합 2단계
		• 병합할 런 수 = O((N/M)/(M/B)) = O(BN/M²)
		• 각 런의 블록 수 = O((M/B)²) = O(M²/B²)
		• I/O 비용 = O(N/B)
	•	병합 i단계
		• 여전히 선형 I/O

⸻

최악의 경우 비용 분석 요약
각 병합 단계마다 O(N/B)의 선형 I/O
총 I/O = 병합 횟수 × O(N/B)
병합 횟수 = O(logM/B(N/M)) → 왜일까?
결국 총 I/O = O((N/B) × logM/B(N/B))
→ 이는 메모리 내 정렬에서의 O(n log n)에 대응하는 외부 정렬의 최적 복잡도로 간주됨.

다음은 요청하신 글의 요약 없는 한글 번역입니다:

⸻

조인(Join)
조인 질의를 어떻게 처리하고 각 조인 알고리즘의 비용을 어떻게 측정하는가

⸻

조인 연산
조인을 구현하는 여러 가지 알고리즘이 존재한다:
	•	중첩 루프 조인(Nested-loop join)
	•	블록 중첩 루프 조인(Block nested-loop join)
	•	인덱스 중첩 루프 조인(Indexed nested-loop join)
	•	병합 조인(Merge-join)
	•	해시 조인(Hash-join)

선택은 비용 추정에 따라 이루어진다.

예제에서는 다음 정보를 사용:
	•	student 릴레이션: 레코드 수 5,000 (Nr), 블록 수 100 (Nr/B)
	•	takes 릴레이션: 레코드 수 10,000 (Ns), 블록 수 400 (Ns/B)

⸻

중첩 루프 조인
θ 조인을 계산하려면:

for each tuple tr in r do
  for each tuple ts in s do
    조건 θ를 만족하는지 검사
    만족하면 tr ⋈ ts를 결과에 추가

r은 외부 릴레이션(outer relation), s는 내부 릴레이션(inner relation)이다.
인덱스 없이 사용할 수 있으며, 어떤 조인 조건에서도 사용 가능하다.
모든 튜플 쌍을 검사하므로 비용이 크다.

최악의 경우, 각 릴레이션의 블록 하나만 메모리에 적재 가능할 때 I/O 비용은
	•	O(Nr/B + Nr × Ns/B) ≈ O(N²/B)

작은 릴레이션이 메모리에 전부 적재 가능하면 그것을 내부 릴레이션으로 사용:
	•	비용: O(Nr/B + Ns/B) ≈ O(N/B)

메모리가 제한된 경우 실제 비용 추정은 다음과 같다:
	•	student를 외부 릴레이션으로: 5,000 × 400 + 100 = 2,000,100 블록 전송
	•	takes를 외부 릴레이션으로: 10,000 × 100 + 400 = 1,000,400 블록 전송
	•	작은 릴레이션(student)이 전부 메모리에 적재 가능하다면 비용은 500 블록 전송

→ 블록 중첩 루프 조인이 더 나음.

⸻

블록 중첩 루프 조인
내부 릴레이션의 모든 블록이 외부 릴레이션의 모든 블록과 조인되는 중첩 루프 변형

for each block Br in r do
  for each block Bs in s do
    for each tuple tr in Br do
      for each tuple ts in Bs do
        조건 만족 시 tr ⋈ ts를 결과에 추가

	•	최악의 경우: O(Nr/B + Nr/B × Ns/B) ≈ O(N²/B²)
→ 내부 릴레이션의 각 블록은 외부 블록 수만큼 읽힘
	•	최상의 경우: O(Nr/B + Ns/B) ≈ O(N/B)

개선 사항:
	•	외부 릴레이션을 M/B - 2 블록 단위로 묶고, 나머지 2블록은 내부 릴레이션 및 출력 버퍼로 사용
→ 비용: O(Nr/B + Nr/M × Ns/B) ≈ O(N²/BM)
	•	equi-join에서 내부 릴레이션 속성이 키이면, 첫 번째 매칭 시 루프 종료
	•	버퍼에 남은 블록을 최대한 활용하기 위해 내부 루프를 앞뒤로 번갈아 스캔
	•	내부 릴레이션에 인덱스가 있다면 활용 (다음 설명)

⸻

인덱스 중첩 루프 조인
	•	(B+트리) 인덱스가 있고 조인이 equi-join 또는 자연 조인일 때
	•	내부 릴레이션의 조인 속성에 인덱스가 있어야 함
→ 조인 수행을 위해 인덱스를 생성할 수도 있음

외부 릴레이션의 각 튜플 tr에 대해
  인덱스를 사용해 조건을 만족하는 내부 릴레이션 튜플 ts를 검색

최악의 경우:
	•	r의 페이지 1개만 버퍼에 유지 가능
	•	r의 각 튜플마다 s에서 인덱스 조회
	•	비용: O(Nr/B + Nr × logB Ns) = O(Nr logB Ns) ≈ O(N logB N)

양쪽 조인 속성에 인덱스가 있다면, 튜플 수가 적은 릴레이션을 외부로 선택
→ O(Nr logB Ns) vs O(Ns logB Nr) 중 더 작은 것 선택

예: student ⋈ takes (student가 외부 릴레이션)
	•	takes는 ID 속성에 B+트리 기본 인덱스를 가짐 (노드당 20 엔트리)
	•	takes의 튜플 수 10,000 → 트리 높이 4, 실제 데이터 접근까지 1회 추가
	•	student는 튜플 수 5,000

비용 비교:
	•	블록 중첩 루프: 400×100 + 100 = 40,100 블록 전송
	•	인덱스 중첩 루프: 100 + 5,000×5 = 25,100 블록 전송
→ CPU 비용도 블록 중첩 루프보다 적음

⸻

병합 조인 (Merge-Join)
	1.	두 릴레이션을 조인 속성으로 정렬 (정렬되어 있다면 생략)
	2.	정렬된 릴레이션들을 병합하여 조인
	•	조인 단계는 정렬-병합 알고리즘의 병합 단계와 유사
	•	조인 속성 값이 중복일 경우 모든 쌍을 매칭해야 함

	•	equi-join 또는 자연 조인에만 사용 가능
	•	조인 속성 값이 같은 튜플이 메모리에 적재 가능하다면 각 블록은 한 번만 읽으면 됨
	•	I/O 비용: O(Nr/B + Ns/B) ≈ O(N/B) + 정렬 비용(정렬되지 않은 경우)

하이브리드 병합 조인
	•	한 릴레이션은 정렬되어 있고, 다른 하나는 조인 속성에 보조 B+트리 인덱스를 가짐

	1.	정렬된 릴레이션과 인덱스 리프 노드를 병합
	2.	정렬되지 않은 릴레이션의 튜플 주소 순서로 정렬
	3.	해당 주소 순서로 릴레이션을 순차적으로 스캔하며 병합
→ 순차 접근이 랜덤 접근보다 효율적

⸻

해시 조인 (Hash-Join)
	•	equi-join 또는 자연 조인에 적용 가능
	•	해시 함수 h를 사용하여 두 릴레이션을 파티션
	•	h: 조인 속성 값을 {0, 1, …, H}로 매핑
	•	r의 튜플은 ri에, s의 튜플은 si에 할당됨
→ 조인 속성 값이 같은 튜플만 같은 파티션에 존재함 → 불필요한 비교 제거 가능

⸻

해시 조인 알고리즘
	1.	해시 함수 h를 사용하여 s를 파티션
	•	각 파티션마다 출력 버퍼 1개 메모리 블록 사용
	2.	r도 동일한 방식으로 파티션
	3.	각 i에 대해:
a) si를 메모리에 적재하고 조인 속성으로 해시 인덱스를 구성 (다른 해시 함수 사용)
b) ri의 튜플을 하나씩 디스크에서 읽고, 메모리 인덱스를 이용하여 si에서 매칭되는 튜플을 찾음
→ 매칭되면 튜플 속성 연결하여 출력

	•	s는 build input, r은 probe input이라고 함
	•	h와 H는 si가 메모리에 적재되도록 설정
	•	일반적으로 H = Θ(Ns / M)
	•	probe 릴레이션(r)의 파티션은 메모리에 적재될 필요 없음
	•	H가 메모리 블록 수 M/B보다 크면 재귀적 파티셔닝 필요

→ 일반적으로는 필요 없음
예:
	•	블록 크기 4KB, 메모리 2MB이면 1GB 이하 릴레이션에선 재귀 파티셔닝 불필요
	•	메모리 12MB면 36GB 이하 릴레이션까지도 가능

⸻
다음은 요청하신 글의 요약 없는 한글 번역입니다:

⸻

오버플로우 처리

어떤 파티션이 다른 파티션보다 훨씬 많은 튜플을 포함하면 파티셔닝이 불균형(skewed) 되었다고 한다.
Hash-table 오버플로우는 파티션 si가 메모리에 적재되지 않을 때 발생한다.
발생 원인:
	•	조인 속성의 동일한 값을 가진 튜플이 많은 경우
	•	좋지 않은 해시 함수 사용

오버플로우 해결은 build 단계에서 수행할 수 있다:
	•	파티션 si를 다른 해시 함수로 다시 파티셔닝
	•	ri도 동일하게 파티셔닝 해야 함

오버플로우 방지는 build 단계에서 오버플로우가 발생하지 않도록 신중하게 파티션을 구성하는 방법
예: build 릴레이션을 많은 파티션으로 나눈 후 다시 병합

이 두 방법 모두 중복 값이 많은 경우에는 실패할 수 있음
대안: 오버플로우된 파티션에 대해 블록 중첩 루프 조인 사용

⸻

해시 조인의 비용

재귀 파티셔닝이 필요 없는 경우:
	•	파티셔닝 비용: O(Nr/B + Ns/B)
	•	조인 비용: O(Nr/B + Ns/B + H), 여기서 H는 파티션 수(버킷 수)
	•	최악의 경우 H 블록 전송이 필요한 이유:
→ 각 파티션마다 부분적으로 채워진 블록이 최대 하나씩 존재할 수 있기 때문

보통 H는 Nr/B + Ns/B보다 훨씬 작기 때문에 총 비용은
O(Nr/B + Ns/B) ≈ O(N/B)

재귀 파티셔닝이 필요한 경우:
	•	build 릴레이션 s를 파티션당 M/B 블록 미만으로 나누기 위한 통과 횟수는
O(logM/B(Ns/B))
→ 왜 그런지는 외부 병합 정렬을 떠올려 보면 됨

→ 작은 릴레이션을 build 릴레이션으로 선택하는 것이 좋음

총 비용 추정:
O((Nr/B + Ns/B) × logM/B(Ns/B)) ≈ O(N/B logM/B N/B)
→ 만약 build 릴레이션 전체가 메모리에 적재 가능하면 파티셔닝 불필요
→ 비용은 다시 O(Nr/B + Ns/B) ≈ O(N/B)로 감소

⸻

해시 조인의 비용 예시

Instructor ⋈ teaches 조인
	•	메모리 크기: 20 블록
	•	instructor: 100 블록, teaches: 400 블록
	•	instructor를 build 입력으로 사용 → 20 블록씩 5개 파티션으로 분할 가능
	•	teaches도 동일하게 80 블록씩 5개 파티션으로 분할 가능

이 파티셔닝은 한 번에 가능 → 총 비용:
3 × (100 + 400) = 1500 블록 전송

→ 3번의 선형 I/O:
	1.	두 릴레이션 전체 읽기
	2.	파티셔닝 후 디스크에 기록
	3.	build와 probe 수행

⸻

복합 조인

합성 조건을 가지는 조인:
r θ1 ∧ θ2 ∧ ... ∧ θn s
	•	중첩 루프나 블록 중첩 루프 사용
	•	또는 간단한 조인 r θi s를 수행하고
중간 결과에서 나머지 조건 θ1 ∧ ... ∧ θi–1 ∧ θi+1 ∧ ... ∧ θn을 만족하는 튜플만 선택

선택 조건이 OR인 경우:
r θ1 ∨ θ2 ∨ ... ∨ θn s
	•	중첩 루프/블록 중첩 루프 사용 가능
	•	또는 각각의 조인 결과를 구해서 합집합으로 계산
(r θ1 s) ∪ (r θ2 s) ∪ ... ∪ (r θn s)

⸻

기타 연산들

중복 제거는 정렬 또는 해싱을 통해 구현 가능
	•	정렬 시 중복 튜플은 연속되므로 하나만 남기고 나머지 삭제
	•	최적화: 외부 정렬 병합 중간 단계나 정렬 실행 시 중복 제거 가능
	•	해싱도 유사하게 동작 → 같은 버킷에 들어오므로 중복 처리 가능

프로젝션 (Projection):
	•	각 튜플에 대해 프로젝션 수행 후
	•	중복 제거 수행

⸻

집계 연산 (Aggregation)
	•	중복 제거와 유사하게 구현 가능
	•	정렬 또는 해싱을 통해 동일 그룹 튜플들을 모은 뒤 집계 함수 적용
	•	최적화: 실행 중 또는 병합 단계에서 부분 집계 값을 누적
	•	count, min, max, sum: 현재까지 튜플들을 기반으로 집계 유지
	•	avg: sum과 count 유지 → 마지막에 sum / count

⸻

집합 연산 (Set Operations)

(합집합 ∪, 교집합 ∩, 차집합 –)
→ 정렬 후 merge-join 변형 또는 해시 조인 변형 사용 가능

예: 해시를 사용한 집합 연산
	1.	동일한 해시 함수로 r, s를 파티션
	2.	각 파티션 i에 대해:

	•	∪ 연산
	1.	ri에 해시 인덱스 생성
	2.	si의 튜플을 인덱스에 추가 (이미 없는 경우만)
	3.	인덱스에 있는 튜플을 결과에 추가
	•	∩ 연산
	1.	ri에 해시 인덱스 생성
	2.	si의 튜플이 인덱스에 있으면 결과에 추가
	•	– 연산
	1.	si의 튜플이 인덱스에 있으면 제거
	2.	인덱스에 남은 튜플들을 결과에 추가

⸻

식(expression) 평가

지금까지는 개별 연산 알고리즘만 살펴보았음
전체 **식 트리(expression tree)**를 평가하기 위한 대안:
	1.	구현 저장 방식(Materialization)

	•	각 연산의 결과를 디스크에 저장한 뒤 다음 연산에 사용

	2.	파이프라이닝(Pipelining)

	•	한 연산이 실행되는 중에도 결과 튜플을 상위 연산에 바로 전달

⸻

Materialization (저장 기반 평가)
	•	가장 하위 연산부터 하나씩 평가
	•	중간 결과를 임시 릴레이션에 저장
예: 아래 식에 대해

σbuilding = "Watson"(department)
⋈ instructor
→ name 프로젝션

	•	부서 필터 결과 저장 → instructor와 조인 결과 저장 → 최종 결과 저장

항상 적용 가능하지만,
→ 디스크 쓰기/읽기 비용이 매우 클 수 있음
	•	우리의 연산 비용 공식은 디스크 쓰기 비용을 무시함
→ 전체 비용 = 개별 연산의 비용 합 + 디스크에 중간 결과 쓰는 비용

더블 버퍼링:
	•	각 연산에 2개의 출력 버퍼 사용
	•	한쪽이 가득 차면 디스크에 쓰는 동안 다른 쪽은 계속 사용
→ 쓰기와 계산을 겹쳐서 실행 시간 단축

⸻

Pipelining (파이프라이닝 평가)
	•	여러 연산을 동시에 수행
	•	한 연산의 결과를 바로 다음 연산에 전달
예:

σbuilding = "Watson"(department)
→ join
→ projection

→ 중간 결과 저장 없이 바로 상위 연산에 전달
	•	Materialization보다 훨씬 효율적: 디스크에 임시 릴레이션 저장 불필요
	•	단, 정렬이나 해시 조인과 같은 연산은 중간 결과 없이는 불가능

효과적 파이프라이닝 조건:
	•	연산 알고리즘이 입력 튜플을 받는 즉시 결과 튜플을 생성할 수 있어야 함

⸻

파이프라이닝 실행 방식
	1.	수요 기반 (demand driven / lazy evaluation)
	•	시스템이 최상위 연산에서 다음 튜플을 요청
	•	각 연산이 자식 연산에 요청
	•	중간 상태를 유지해 다음 호출 시 어디까지 진행했는지 기억해야 함
	2.	생산자 기반 (producer-driven / eager pipelining)
	•	연산이 결과 튜플을 생성하여 부모에게 전달
	•	연산 간 버퍼 유지
	•	자식 연산이 버퍼에 결과 저장
	•	부모 연산이 버퍼에서 가져감
	•	버퍼가 가득 차면 자식은 대기
	•	시스템은 출력 버퍼에 공간이 있는 연산을 우선 실행

다른 이름: Pull (수요 기반), Push (생산자 기반) 모델

⸻

수요 기반 파이프라이닝 구현

각 연산은 **이터레이터(iterator)**로 구현되며 다음 연산 제공:
	•	open()
	•	예: 파일 스캔 → 파일 시작 위치로 초기화
	•	예: 병합 조인 → 릴레이션 정렬, 정렬 시작점 저장
	•	next()
	•	예: 파일 스캔 → 다음 튜플 출력, 포인터 이동
	•	예: 병합 조인 → 이전 상태에서 이어서 결과 찾고 포인터 상태 저장
	•	close()

⸻

파이프라이닝 연산 알고리즘

일부 연산은 블로킹 연산(blocking operation)
→ 모든 입력 튜플이 준비될 때까지 결과 생성 불가
예: 정렬, 해시 조인
→ 입력을 받는 도중에는 결과를 생성할 수 없음
→ 중간 결과를 디스크에 써야 함

예:
	•	병합 조인 (입력이 정렬되지 않은 경우)
	•	해시 조인

→ 이들 연산은 파이프라이닝에 적합하지 않음.