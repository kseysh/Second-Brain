## AI와 보안

◼ AI 보안을 위한 보안 (Security for AI)

|**공격 목표**|**학습 시점 공격 (Training-time attack)**|**추론 시점 공격 (Inference-time attack)**|
|---|---|---|
|**견고성 (무결성)**|데이터 오염 / 백도어 공격⇒ 데이터 정제예: 이상치 탐지|회피 공격 (예: 적대적 예제)⇒ 적대적 학습, 모델 앙상블|
|**모델 기밀성**|-|모델 추출⇒ 모델 워터마킹|
|**데이터 기밀성**|서버에 의한 사용자 데이터 남용⇒ 개인정보 보호 머신러닝 (PPML)예: 동형암호(HE), 안전한 다자간 계산(MPC), 신뢰실행환경(TEE)|모델 역추론 (예: 얼굴 재구성)멤버십 추론⇒ PPML, 차등 프라이버시(DP)|
◼ 보안을 위한 AI (AI for Security)
	•	AI 기반 침입 탐지/방지 시스템 (IDS/IPS)
	•	악성코드 분류
	•	LLM 기반 스팸 필터링, 피싱 탐지
	•	위협 인텔리전스 (보안 로그 분석)

## **Evasion Attack**
데이터셋의 예제에 대해 작지만 의도적으로 최악의 경우를 가정한 작은 변형을 가해 입력을 만든 후, 그 결과로 모델이 높은 확신을 가지고 오답을 출력하도록 함

▣ 적대적 예제에 대한 일부 대응 방안
	■ 적대적 훈련
	■ 입력 변환 (노이즈 제거기)
	■ 모델 앙상블
▣ 데이터 오염(Poisoning) 공격
	■ 악의적인 데이터셋 배포
	■ 백도어 숨기기
▣ 대응 방안
	■ 예: Data sanitization

⸻

▣ 머신러닝에서 데이터 보호의 필요성
■ 보안 침해 사례
	● Strava 피트니스 앱이 전 세계 미군 기지 위치를 노출한 사건
		– “아프가니스탄, 지부티, 시리아 같은 지역에서는 Strava 사용자가 거의 외국 군인뿐이라, 기지 위치가 매우 뚜렷하게 드러남”
■ 가능한 해결책
	● 개인 정보를 클라우드에 업로드하기 전에 암호화하여 접근 제한
	● 전통적인 암호화 방식은 암호화된 데이터 위에서의 연산을 허용하지 않음

▣ Homomorphic Encryption
	■ 연산 가능한 암호화 방식
	■ Homomorphic: 구조를 보존함
	■ 암호화 후 연산 = 연산 후 암호화

⸻

AI 보안을 위한 데이터 보호와 프라이버시 기술

▣ 안전한 다자간 연산 (MPC)
■ 빠르지만 많은 통신 필요

▣ Differential Privacy (DP)
■ 간단한 연산 (노이즈 추가 방식)
■ 모델 반전, 멤버십 추론 방지에 유용
■ 정확도 일부 감소

▣ 하드웨어 기반 신뢰 컴퓨팅
■ 민감한 데이터와 코드를 하드웨어 내부에서 격리 및 보호
■ 신뢰 실행 환경 (TEE)
● Intel SGX, TDX
● AMD SEV, SEV-SNP
● Arm TrustZone, CCA

⸻

보안을 위한 AI: 이상 탐지 (Anomaly Detection, AD)

▣ 정상과 다르면 정의상 이상(anomaly)이므로,
이상들은 서로 유사할 필요가 없음
▣ 이 때문에 지도 학습 또는 반지도 학습 기반 분류는 AD에 부적합함

▣ AD의 주요 두 가지 접근 방식
■ 예측 기반
■ 재구성 기반

⸻

예측 기반 이상 탐지

▣ 예측 모델
■ RNN (순환 신경망)
● LSTM, 시퀀스-투-시퀀스 등
■ 트랜스포머

⸻

재구성 기반 이상 탐지

훈련 과정
압축된 표현 학습 (일종의 압축-복원 알고리즘)
Autoencoder 자주 사용됨

테스트 과정
입력을 인코딩 후 디코딩
입력과 출력이 크게 다르면
이상을 보고함
	•	VAE(Variational Autoencoder)는 생성 모델용
예: Stable Diffusion

⸻

보안을 위한 AI: LLM 기반 분석

▣ 코드 분석 (디스어셈블/디컴파일)
■ Python 바이트코드가 주어지면
■ GPT-4로 디컴파일 → 소스 코드 복원
■ GPT-4가 역공학된 코드를 설명함
■ 꽤 정확한 설명 가능

▣ 버그 탐지
■ 매우 길고 반복적인 코드에서

▣ 스팸 필터링, 피싱 탐지
▣ 악성코드 분류
▣ 위협 인텔리전스 (보안 로그 분석)
▣ LLM은 완벽하진 않지만
정확도 90%만으로도 유용한 활용처가 많음

⸻
